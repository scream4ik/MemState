{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MemState - Transactional Memory for AI Agents","text":"<p>Agents hallucinate because their memory drifts. SQL says one thing, the Vector DB says another. MemState keeps them in sync, always.</p> <p>Mental Model: MemState extends database transactions to your Vector DB. One unit. One commit. One rollback.</p> <p> </p>"},{"location":"#why-memstate-exists","title":"Why MemState exists","text":""},{"location":"#the-problem","title":"The Problem","text":"<p>AI agents usually store memory in two places:</p> <ul> <li>SQL: structured facts (preferences, task history)</li> <li>Vector DB: semantic search (embeddings for RAG)</li> </ul> <p>These two stores drift easily. Even small failures create inconsistency:</p> <pre><code># Step 1: SQL write succeeds\ndb.update(\"user_city\", \"London\")\n\n# Step 2: Vector DB update fails\nvectors.upsert(\"User lives in London\")  # \u274c failed\n\n# Final state:\n# SQL: London\n# Vectors: New York (stale embedding)\n</code></pre> <p>Result: ghost vectors, inconsistent state, unpredictable agent behavior. Drift accumulates silently, agents continue retrieving outdated or mismatched memory.</p>"},{"location":"#why-this-happens","title":"Why this happens","text":"<p>Real-world agent pipelines create drift even with correct code, because:</p> <ul> <li>Vector DB upserts are not atomic</li> <li>Retried writes can produce duplicates or stale embeddings</li> <li>Async ingestion leads to race conditions</li> <li>LLM outputs often contain non-schema JSON</li> <li>Embedding model/version changes create semantic mismatch</li> <li>SQL writes succeed while vector DB fails, partial updates persist</li> </ul> <p>These issues are invisible until retrieval fails, making debugging extremely difficult. MemState prevents this by enforcing atomic memory operations: if any part fails, the whole operation is rolled back.</p>"},{"location":"#the-solution","title":"The Solution","text":"<p>MemState makes memory operations atomic:</p> <pre><code>SQL write + Vector upsert\n\u2192 succeed together or rollback together\n</code></pre>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Atomic commits: SQL and Vector DB stay in sync</li> <li>Rollback: undo N steps across SQL and vectors</li> <li>Type safety: Pydantic validation prevents malformed JSON</li> <li>Append-only Fact Log: full versioned history</li> <li>Crash-safe atomicity: if a vector DB write fails, the entire memory operation (SQL + vector) is rolled back.   No partial writes, no ghost embeddings, no inconsistent checkpoints.</li> <li>Hybrid Search: Search by meaning (Vector), filter by facts (SQL).</li> </ul>"},{"location":"#proof-benchmark-under-failure","title":"Proof: Benchmark under failure","text":"<p>1000 memory updates with 10% random vector DB failures:</p> METRIC MANUAL SYNC MEMSTATE SQL Records 1000 900 Vector Records 910 900 DATA DRIFT 90 0 INCONSISTENCY RATE 9.0% 0.0% <p>Why 900 instead of 1000? MemState refuses partial writes. If vector sync fails, SQL is rolled back automatically.</p> <p>Manual sync produces silent drift. Drift compounds over time, stale embeddings keep being retrieved forever.</p> <p>Full benchmark script: <code>benchmarks/</code></p>"},{"location":"#ideal-for","title":"Ideal for","text":"<ul> <li>Long-running agents</li> <li>LangGraph workflows</li> <li>RAG systems requiring strict DB &lt;-&gt; embedding consistency</li> <li>Local-first / offline-first setups (SQLite/Redis/PostgreSQL + Chroma/Qdrant/FAISS)</li> <li>Deterministic, debuggable agentic pipelines</li> </ul>"},{"location":"#storage-backends","title":"Storage backends","text":"<p>All backends participate in the same atomic commit cycle:</p> <ul> <li>SQLite (JSON1)</li> <li>Redis</li> <li>PostgreSQL</li> <li>In-memory</li> <li>Custom backends via simple interface</li> </ul> <p>Vector sync hooks:</p> <ul> <li>ChromaDB</li> <li>Qdrant</li> <li>Custom hooks via simple interface</li> </ul>"},{"location":"#when-you-dont-need-it","title":"When you don't need it","text":"<ul> <li>Your agent is fully stateless</li> <li>You store everything in a single SQL table</li> <li>You never update embeddings after creation</li> </ul> <p>If your pipelines depend on RAG or long-term state, consistency is required - most teams realize this only when debugging unpredictable retrieval.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#051-2025-12-29","title":"[0.5.1] - 2025-12-29","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>LangGraph Subgraph Support: Previously, <code>MemStateCheckpointer</code> ignored the <code>checkpoint_ns</code> (namespace) parameter. This caused state collisions when using nested graphs (subgraphs) within the same thread. Now, checkpoints are strictly isolated by both <code>thread_id</code> and <code>checkpoint_ns</code>.</li> </ul>"},{"location":"changelog/#performance","title":"Performance","text":"<ul> <li>New Indexes: Added functional indexes for <code>payload.checkpoint_ns</code> in both PostgreSQL (B-Tree on JSONB path) and SQLite. This ensures fast state retrieval for complex agent workflows without full table scans.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Checkpointer Logic: Updated <code>put</code> and <code>aput</code> methods in LangGraph integrations to explicitly persist the <code>checkpoint_ns</code> field within the fact payload.</li> </ul>"},{"location":"changelog/#050-2025-12-23","title":"[0.5.0] - 2025-12-23","text":""},{"location":"changelog/#major-feature-hybrid-structured-semantic-search","title":"Major Feature: Hybrid Structured-Semantic Search","text":"<p>MemState moves beyond just storing data to retrieving it intelligently. This release adds a unified search API that combines Vector Similarity with SQL-like strict filtering.</p> <ul> <li>New <code>store.search()</code> API: Finds relevant IDs in the Vector DB and hydrates them with fresh data from the SQL Storage (Source of Truth).<ul> <li>Supports <code>query</code> (text for embedding).</li> <li>Supports <code>filters</code> (metadata filtering).</li> <li>Supports <code>score_threshold</code> (cutoff for relevance).</li> </ul> </li> <li>Safety First: Search results are cross-referenced with the Storage backend. If a vector index finds a \"ghost\" ID (deleted in SQL), MemState automatically filters it out, preventing hallucinations.</li> </ul>"},{"location":"changelog/#integrations","title":"Integrations","text":"<ul> <li>Qdrant Search: Implemented search using the modern <code>query_points</code> API.<ul> <li>DX Magic: Added automatic translation of simple dictionary filters (<code>{\"role\": \"user\"}</code>) into Qdrant's complex <code>models.Filter</code> syntax.</li> </ul> </li> <li>ChromaDB Search: Implemented semantic search with metadata filtering.</li> </ul>"},{"location":"changelog/#breaking-changes-for-custom-hooks","title":"Breaking Changes (for Custom Hooks)","text":"<ul> <li>The <code>MemoryHook</code> and <code>AsyncMemoryHook</code> protocols now require a <code>search</code> method.<ul> <li>If you have implemented custom hooks, you must add a <code>search</code> method (it can return an empty list <code>[]</code> if retrieval is not supported).</li> </ul> </li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>Added Hybrid Search section to Core Concepts.</li> </ul>"},{"location":"changelog/#040-2025-12-18","title":"[0.4.0] - 2025-12-18","text":""},{"location":"changelog/#major-async-support-beta-release","title":"Major: Async Support &amp; Beta Release","text":"<p>This release marks the transition to Beta. The API is stable, and MemState is now ready for high-concurrency production workloads (FastAPI).</p> <ul> <li>Full Async Support: Added <code>AsyncMemoryStore</code> and async versions of all backends and hooks.</li> <li>New Storage Backends:<ul> <li>PostgreSQL: Native support using <code>SQLAlchemy</code> + <code>psycopg</code> with efficient JSONB querying.</li> <li>Redis: Added <code>AsyncRedisStorage</code>.</li> <li>SQLite: Added <code>AsyncSQLiteStorage</code> (via <code>aiosqlite</code>).</li> </ul> </li> <li>New Vector Integration: Added Qdrant support (Sync &amp; Async) with built-in FastEmbed generation.</li> </ul>"},{"location":"changelog/#changed-architectural-improvements","title":"Changed (Architectural Improvements)","text":"<ul> <li>Surgical Rollback: Completely rewrote <code>rollback</code> logic to be safe in multi-user environments.<ul> <li>Added <code>session_id</code> isolation to transaction logs.</li> <li>Rollback now removes specific transactions by UUID instead of truncating the log tail, preventing \"Groundhog Day\" bugs.</li> </ul> </li> <li>Safe Updates: The <code>update()</code> method now enforces Schema Re-validation. Applying a patch that breaks the Pydantic schema will now raise <code>ValidationFailed</code> instead of corrupting the DB.</li> <li>Session Optimization: Added <code>get_session_facts</code> to backends to utilize DB indexes for session operations (O(1) vs O(N) previously).</li> </ul>"},{"location":"changelog/#added","title":"Added","text":"<ul> <li>LangGraph Async: Added <code>AsyncMemStateCheckpointer</code> for non-blocking graph persistence.</li> <li>DX Improvements: Added <code>session_id</code> argument to <code>query()</code> for easier context filtering.</li> <li>Documentation: Launched comprehensive documentation site.</li> </ul>"},{"location":"changelog/#dependencies","title":"Dependencies","text":"<ul> <li>Added optional dependencies: <code>postgres</code>, <code>qdrant</code>, <code>sqlite-async</code>.</li> </ul>"},{"location":"changelog/#033-2025-12-12","title":"[0.3.3] - 2025-12-12","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>New <code>commit_model</code> API: You can now pass Pydantic instances directly to memory.</li> <li>No more manual dictionary dumping: <code>mem.commit_model(user)</code> instead of <code>mem.commit(Fact(type=\"user\", payload=user.dict()))</code>.</li> <li>Automatically resolves registered schema types.</li> <li>Supports both INSERT (auto ID) and UPDATE (explicit <code>fact_id</code>).</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>README Overhaul: rewritten to focus on the \"Mental Model\" of transactional memory and the physical physics of \"Data Drift\".</li> <li>Refactored Examples: All examples (<code>examples/</code>) updated to use the cleaner <code>commit_model</code> syntax.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Lifecycle Logic: Ensured <code>commit_model</code> correctly handles updates when <code>fact_id</code> is provided (previously defaulted to creating duplicates).</li> </ul>"},{"location":"changelog/#032-2025-12-04","title":"[0.3.2] - 2025-12-04","text":""},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Critical Atomicity Fix: The <code>commit()</code> method now implements a proper \"Compensating Transaction\" pattern.<ul> <li>Previously, if a vector sync hook (e.g., ChromaDB) failed, the SQL data remained committed, breaking the \"ACID-like\" promise.</li> <li>Now, if a hook fails, the SQL transaction is automatically rolled back (or restored to the previous state).</li> </ul> </li> <li>Singleton Logic: Fixed a bug where updating a Singleton fact (e.g., \"One User Profile\") would return early and skip vector synchronization.</li> </ul>"},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li>New Positioning: Updated README to focus on \"Transactional Memory\" and \"Predictability\" rather than generic agent state.</li> <li>Demo: Added a video demonstration (GIF) showing MemState preventing hallucinations vs Manual Sync.</li> </ul>"},{"location":"changelog/#031-2025-12-04","title":"[0.3.1] - 2025-12-04","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>DX Improvement: Exposed main classes (<code>MemoryStore</code>, <code>Fact</code>, <code>Operation</code>, etc.) directly in the top-level package.</li> <li>Now you can use: <code>from memstate import MemoryStore</code> instead of importing from submodules.</li> <li>Internal: Switched to dynamic versioning (single source of truth in <code>pyproject.toml</code>).</li> </ul>"},{"location":"changelog/#030-2025-12-03","title":"[0.3.0] - 2025-12-03","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>RAG Synchronization: Introduced <code>ChromaSyncHook</code> to keep structured state and Vector DBs in perfect sync.</li> <li>Transactional Vector Ops: Vector embeddings are now atomic \u2014 they are only updated/deleted upon <code>COMMIT</code>, preventing \"ghost data\" from draft sessions.</li> <li>Flexible Mapping: Added support for custom <code>text_formatter</code> and <code>metadata_formatter</code> to control how Pydantic models map to vector documents.</li> <li>New installation extras: <code>pip install memstate[chromadb]</code>.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Positioning: Rebranded documentation to focus on ACID-like atomicity for hybrid memory (SQL + Vector), moving away from the generic \"Git for memory\" messaging.</li> </ul>"},{"location":"changelog/#020-2025-11-26","title":"[0.2.0] - 2025-11-26","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>LangGraph Integration: Added <code>MemStateCheckpointer</code> for persisting agent graphs.</li> <li>New installation extras: <code>pip install memstate[langchain]</code> (includes <code>langgraph</code>).</li> </ul>"},{"location":"changelog/#010-2025-11-25","title":"[0.1.0] - 2025-11-25","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Initial release of MemState.</li> <li>Core transactional memory engine (<code>MemoryStore</code>).</li> <li>Strict schema validation using Pydantic (<code>register_schema</code>).</li> <li>Backends: <code>InMemoryStorage</code>, <code>RedisStorage</code>, <code>SQLiteStorage</code> (with JSON1 query support).</li> <li>Feature: Time Travel / Rollback (<code>memory.rollback</code>).</li> <li>Feature: Constraints (<code>Singleton</code>, <code>Immutable</code>).</li> </ul>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>uv (recommended) or pip</li> </ul>"},{"location":"quickstart/#installation","title":"Installation","text":"uvpip <pre><code>uv add memstate\n</code></pre> <pre><code>pip install memstate\n</code></pre>"},{"location":"quickstart/#usage","title":"Usage","text":"<p>Let's build a simple memory for an agent. In this scenario, the user states a preference, then accidentally contradicts themselves, and we use rollback to undo the mistake instantly.</p> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage\n\n# 1. Define schema\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\n# 2. Init memory\nstore = MemoryStore(storage=InMemoryStorage())\nstore.register_schema(\"preference\", UserPref)\n\n# 3. Commit correct data\nfact_id = store.commit_model(\n    model=UserPref(content=\"I am vegetarian\", role=\"preference\"), session_id=\"session_1\"\n)\nprint(\"Current state:\", store.get(fact_id))\n\n# 4. Agent makes a mistake (writes wrong data)\nprint(\"--- Making a mistake... ---\")\nstore.commit_model(\n    model=UserPref(content=\"I love steak\"), fact_id=fact_id, session_id=\"session_1\"\n)\nprint(\"Current state:\", store.get(fact_id))\n\n# 5. Undo!\nstore.rollback(steps=1, session_id=\"session_1\")\nprint(\"--- Rolled back! ---\")\n\n# Verify: The last transaction is the vegetarian one\nprint(\"Restored state:\", store.get(fact_id))\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\n\n# 1. Define schema\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    # 2. Init memory\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n    store.register_schema(\"preference\", UserPref)\n\n    # 3. Commit correct data\n    fact_id = await store.commit_model(\n        model=UserPref(content=\"I am vegetarian\", role=\"preference\"), session_id=\"session_1\"\n    )\n    print(\"Current state:\", await store.get(fact_id))\n\n    # 4. Agent makes a mistake (writes wrong data)\n    print(\"--- Making a mistake... ---\")\n    await store.commit_model(\n        model=UserPref(content=\"I love steak\"), fact_id=fact_id, session_id=\"session_1\"\n    )\n    print(\"Current state:\", await store.get(fact_id))\n\n    # 5. Undo!\n    await store.rollback(steps=1, session_id=\"session_1\")\n    print(\"--- Rolled back! ---\")\n\n    # Verify: The last transaction is the vegetarian one\n    print(\"Restored state:\", await store.get(fact_id))\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"quickstart/#whats-next","title":"What's next?","text":"<p>This example uses in-memory storage. In a real-world agent, you will want to sync this data with a Vector Database (for RAG) and persist it to Postgres/SQLite.</p> <p>Check out the Documentation section to see how to enable Atomic RAG Sync.</p>"},{"location":"api/","title":"API Reference","text":"<p>Here's the reference or code API, the classes, functions, parameters, attributes, and all the MemState parts you can use in your applications.</p>"},{"location":"api/backends/","title":"Backends","text":""},{"location":"api/backends/#memstate.backends","title":"backends","text":"<p>Modules:</p> <ul> <li> <code>base</code>           \u2013            <p>Base storage backend interface.</p> </li> <li> <code>inmemory</code>           \u2013            <p>In-memory storage backend implementation.</p> </li> <li> <code>postgres</code>           \u2013            <p>Postgres storage backend implementation using SQLAlchemy.</p> </li> <li> <code>redis</code>           \u2013            <p>Redis storage backend implementation.</p> </li> <li> <code>sqlite</code>           \u2013            <p>SQLite storage backend implementation.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.base","title":"base","text":"<p>Base storage backend interface.</p> <p>Classes:</p> <ul> <li> <code>AsyncStorageBackend</code>           \u2013            <p>Asynchronous storage interface (non-blocking I/O).</p> </li> <li> <code>StorageBackend</code>           \u2013            <p>Synchronous storage interface (blocking I/O).</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend","title":"AsyncStorageBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Asynchronous storage interface (non-blocking I/O).</p> Subclassed by: <ul> <li> API Reference <code></code>\u00a0backends <ul> <li> <code></code>\u00a0inmemory <code></code>\u00a0AsyncInMemoryStorage </li> <li> <code></code>\u00a0postgres <code></code>\u00a0AsyncPostgresStorage </li> <li> <code></code>\u00a0redis <code></code>\u00a0AsyncRedisStorage </li> <li> <code></code>\u00a0sqlite <code></code>\u00a0AsyncSQLiteStorage </li> </ul> </li> </ul> Used by: <ul> <li> API Reference <code></code>\u00a0storage <code></code>\u00a0AsyncMemoryStore </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Log a transaction asynchronously.</p> </li> <li> <code>close</code>             \u2013              <p>Cleanup resources asynchronously.</p> </li> <li> <code>delete</code>             \u2013              <p>Delete a fact asynchronously.</p> </li> <li> <code>delete_session</code>             \u2013              <p>Bulk delete ephemeral facts asynchronously. Returns deleted IDs.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Delete specific transactions from the log by their UUIDs.</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieve all facts belonging to a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieve transaction history asynchronously.</p> </li> <li> <code>load</code>             \u2013              <p>Load a single fact by ID asynchronously.</p> </li> <li> <code>query</code>             \u2013              <p>Find facts matching criteria asynchronously.</p> </li> <li> <code>save</code>             \u2013              <p>Upsert a fact asynchronously.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.append_tx","title":"append_tx  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Log a transaction asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"Log a transaction asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Cleanup resources asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Cleanup resources asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Delete a fact asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def delete(self, id: str) -&gt; None:\n    \"\"\"Delete a fact asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.delete_session","title":"delete_session  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Bulk delete ephemeral facts asynchronously. Returns deleted IDs.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"Bulk delete ephemeral facts asynchronously. Returns deleted IDs.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.delete_txs","title":"delete_txs  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Delete specific transactions from the log by their UUIDs.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"Delete specific transactions from the log by their UUIDs.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.get_session_facts","title":"get_session_facts  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieve all facts belonging to a specific session.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"Retrieve all facts belonging to a specific session.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.get_tx_log","title":"get_tx_log  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieve transaction history asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"Retrieve transaction history asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.load","title":"load  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Load a single fact by ID asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"Load a single fact by ID asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.query","title":"query  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Find facts matching criteria asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def query(\n    self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Find facts matching criteria asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.AsyncStorageBackend.save","title":"save  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Upsert a fact asynchronously.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\nasync def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"Upsert a fact asynchronously.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend","title":"StorageBackend","text":"<p>               Bases: <code>ABC</code></p> <p>Synchronous storage interface (blocking I/O).</p> Subclassed by: <ul> <li> API Reference <code></code>\u00a0backends <ul> <li> <code></code>\u00a0inmemory <code></code>\u00a0InMemoryStorage </li> <li> <code></code>\u00a0postgres <code></code>\u00a0PostgresStorage </li> <li> <code></code>\u00a0redis <code></code>\u00a0RedisStorage </li> <li> <code></code>\u00a0sqlite <code></code>\u00a0SQLiteStorage </li> </ul> </li> </ul> Used by: <ul> <li> API Reference <code></code>\u00a0storage <code></code>\u00a0MemoryStore </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Log a transaction.</p> </li> <li> <code>close</code>             \u2013              <p>Cleanup resources (optional).</p> </li> <li> <code>delete</code>             \u2013              <p>Delete a fact.</p> </li> <li> <code>delete_session</code>             \u2013              <p>Bulk delete ephemeral facts (Working Memory cleanup). Returns deleted IDs.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Delete specific transactions from the log by their UUIDs.</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieve all facts belonging to a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieve transaction history (newest first typically, or ordered by seq).</p> </li> <li> <code>load</code>             \u2013              <p>Load a single fact by ID.</p> </li> <li> <code>query</code>             \u2013              <p>Find facts matching criteria.</p> </li> <li> <code>save</code>             \u2013              <p>Upsert a fact.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.append_tx","title":"append_tx  <code>abstractmethod</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Log a transaction.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"Log a transaction.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Cleanup resources (optional).</p> Source code in <code>memstate/backends/base.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Cleanup resources (optional).\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.delete","title":"delete  <code>abstractmethod</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Delete a fact.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef delete(self, id: str) -&gt; None:\n    \"\"\"Delete a fact.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.delete_session","title":"delete_session  <code>abstractmethod</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Bulk delete ephemeral facts (Working Memory cleanup). Returns deleted IDs.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"Bulk delete ephemeral facts (Working Memory cleanup). Returns deleted IDs.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.delete_txs","title":"delete_txs  <code>abstractmethod</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Delete specific transactions from the log by their UUIDs.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"Delete specific transactions from the log by their UUIDs.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.get_session_facts","title":"get_session_facts  <code>abstractmethod</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieve all facts belonging to a specific session.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"Retrieve all facts belonging to a specific session.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.get_tx_log","title":"get_tx_log  <code>abstractmethod</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieve transaction history (newest first typically, or ordered by seq).</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"Retrieve transaction history (newest first typically, or ordered by seq).\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.load","title":"load  <code>abstractmethod</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Load a single fact by ID.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"Load a single fact by ID.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.query","title":"query  <code>abstractmethod</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Find facts matching criteria.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef query(self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"Find facts matching criteria.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.base.StorageBackend.save","title":"save  <code>abstractmethod</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Upsert a fact.</p> Source code in <code>memstate/backends/base.py</code> <pre><code>@abstractmethod\ndef save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"Upsert a fact.\"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory","title":"inmemory","text":"<p>In-memory storage backend implementation.</p> <p>Classes:</p> <ul> <li> <code>AsyncInMemoryStorage</code>           \u2013            <p>Class representing an async in-memory storage backend.</p> </li> <li> <code>InMemoryStorage</code>           \u2013            <p>Class representing an in-memory storage backend.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage","title":"AsyncInMemoryStorage","text":"<pre><code>AsyncInMemoryStorage()\n</code></pre> <p>               Bases: <code>AsyncStorageBackend</code></p> <p>Class representing an async in-memory storage backend.</p> <p>Provides methods for storing, retrieving, deleting, querying, and managing session-related and transaction-log data entirely within memory. This class implements thread-safe operations and supports querying with filtering logic using hierarchical paths in JSON-like structures.</p> <p>Attributes:</p> <ul> <li> <code>_store</code>               (<code>dict[str, dict[str, Any]]</code>)           \u2013            <p>Internal storage for facts indexed by their ID.</p> </li> <li> <code>_tx_log</code>               (<code>list[dict[str, Any]]</code>)           \u2013            <p>List of transaction log entries.</p> </li> <li> <code>_lock</code>               (<code>Lock</code>)           \u2013            <p>Asynchronous lock to ensure safe concurrent access to the storage and transaction log.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Asynchronously appends a transaction record to the transaction log in a thread-safe manner.</p> </li> <li> <code>close</code>             \u2013              <p>Asynchronously closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Asynchronously retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Asynchronously loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Asynchronously query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Asynchronously saves the given fact data into the internal store. The save operation is thread-safe</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._store: dict[str, dict[str, Any]] = {}\n    self._tx_log: list[dict[str, Any]] = []\n    self._lock = asyncio.Lock()\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.append_tx","title":"append_tx  <code>async</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously appends a transaction record to the transaction log in a thread-safe manner.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously appends a transaction record to the transaction log in a thread-safe manner.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        self._tx_log.append(tx_data)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Asynchronously closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Asynchronously closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Asynchronously removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        self._store.pop(id, None)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete_session","title":"delete_session  <code>async</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Asynchronously deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    async with self._lock:\n        to_delete = [fid for fid, f in self._store.items() if f.get(\"session_id\") == session_id]\n        for fid in to_delete:\n            del self._store[fid]\n        return to_delete\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete_txs","title":"delete_txs  <code>async</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    async with self._lock:\n        ids_to_delete = set(tx_uuids)\n\n        self._tx_log = [tx for tx in self._tx_log if tx[\"uuid\"] not in ids_to_delete]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_session_facts","title":"get_session_facts  <code>async</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    return [f for f in self._store.values() if f.get(\"session_id\") == session_id]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_tx_log","title":"get_tx_log  <code>async</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    async with self._lock:\n        reversed_log = reversed(self._tx_log)\n        filtered = [tx for tx in reversed_log if tx.get(\"session_id\") == session_id]\n        return filtered[offset : offset + limit]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.load","title":"load  <code>async</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Asynchronously loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Asynchronously loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    async with self._lock:\n        return self._store.get(id)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.query","title":"query  <code>async</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def query(\n    self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    async with self._lock:\n        results = []\n        for fact in self._store.values():\n            if type_filter and fact[\"type\"] != type_filter:\n                continue\n\n            if json_filters:\n                match = True\n                for k, v in json_filters.items():\n                    actual_val = self._get_value_by_path(fact, k)\n                    if actual_val != v:\n                        match = False\n                        break\n                if not match:\n                    continue\n\n            results.append(fact)\n        return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.save","title":"save  <code>async</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously saves the given fact data into the internal store. The save operation is thread-safe and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>async def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously saves the given fact data into the internal store. The save operation is thread-safe\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        self._store[fact_data[\"id\"]] = fact_data\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.AsyncInMemoryStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage","title":"InMemoryStorage","text":"<pre><code>InMemoryStorage()\n</code></pre> <p>               Bases: <code>StorageBackend</code></p> <p>Class representing an in-memory storage backend.</p> <p>Provides methods for storing, retrieving, deleting, querying, and managing session-related and transaction-log data entirely within memory. This class implements thread-safe operations and supports querying with filtering logic using hierarchical paths in JSON-like structures.</p> <p>Attributes:</p> <ul> <li> <code>_store</code>               (<code>dict[str, dict[str, Any]]</code>)           \u2013            <p>Internal storage for facts indexed by their ID.</p> </li> <li> <code>_tx_log</code>               (<code>list[dict[str, Any]]</code>)           \u2013            <p>List of transaction log entries.</p> </li> <li> <code>_lock</code>               (<code>RLock</code>)           \u2013            <p>Reentrant lock for synchronizing access to the storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Appends a transaction record to the transaction log in a thread-safe manner.</p> </li> <li> <code>close</code>             \u2013              <p>Closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Saves the given fact data into the internal store. The save operation is thread-safe</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._store: dict[str, dict[str, Any]] = {}\n    self._tx_log: list[dict[str, Any]] = []\n    self._lock = threading.RLock()\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.append_tx","title":"append_tx","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Appends a transaction record to the transaction log in a thread-safe manner.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Appends a transaction record to the transaction log in a thread-safe manner.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        self._tx_log.append(tx_data)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete","title":"delete","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        self._store.pop(id, None)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete_session","title":"delete_session","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    with self._lock:\n        to_delete = [fid for fid, f in self._store.items() if f.get(\"session_id\") == session_id]\n        for fid in to_delete:\n            del self._store[fid]\n        return to_delete\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete_txs","title":"delete_txs","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    with self._lock:\n        ids_to_delete = set(tx_uuids)\n\n        self._tx_log = [tx for tx in self._tx_log if tx[\"uuid\"] not in ids_to_delete]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_session_facts","title":"get_session_facts","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    return [f for f in self._store.values() if f.get(\"session_id\") == session_id]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_tx_log","title":"get_tx_log","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    with self._lock:\n        reversed_log = reversed(self._tx_log)\n        filtered = [tx for tx in reversed_log if tx.get(\"session_id\") == session_id]\n        return filtered[offset : offset + limit]\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.load","title":"load","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    with self._lock:\n        return self._store.get(id)\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.query","title":"query","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def query(self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    with self._lock:\n        results = []\n        for fact in self._store.values():\n            if type_filter and fact[\"type\"] != type_filter:\n                continue\n            if json_filters:\n                match = True\n                for k, v in json_filters.items():\n                    # The simplest depth-first search payload\n                    actual_val = self._get_value_by_path(fact, k)\n                    if actual_val != v:\n                        match = False\n                        break\n                if not match:\n                    continue\n            results.append(fact)\n        return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.save","title":"save","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Saves the given fact data into the internal store. The save operation is thread-safe and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/inmemory.py</code> <pre><code>def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Saves the given fact data into the internal store. The save operation is thread-safe\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        self._store[fact_data[\"id\"]] = fact_data\n</code></pre>"},{"location":"api/backends/#memstate.backends.inmemory.InMemoryStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.postgres","title":"postgres","text":"<p>Postgres storage backend implementation using SQLAlchemy.</p> <p>Classes:</p> <ul> <li> <code>AsyncPostgresStorage</code>           \u2013            <p>Async storage backend implementation using PostgreSQL and SQLAlchemy.</p> </li> <li> <code>PostgresStorage</code>           \u2013            <p>Storage backend implementation using PostgreSQL and SQLAlchemy.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage","title":"AsyncPostgresStorage","text":"<pre><code>AsyncPostgresStorage(\n    engine_or_url: str | AsyncEngine,\n    table_prefix: str = \"memstate\",\n)\n</code></pre> <p>               Bases: <code>AsyncStorageBackend</code></p> <p>Async storage backend implementation using PostgreSQL and SQLAlchemy.</p> <p>This class provides methods for interacting with a PostgreSQL database to store, retrieve, and manage structured data and logs. It uses SQLAlchemy for ORM capabilities and supports advanced querying and filtering using JSONB.</p> Example <pre><code>store = AsyncPostgresStorage(...)\nawait store.create_tables()\n</code></pre> <p>Attributes     _engine (str | Engine): SQLAlchemy Engine or connection URL for interacting with the PostgreSQL database.     _metadata (MetaData): SQLAlchemy MetaData object for defining table schemas.     _table_prefix (str): Prefix for naming tables to avoid conflicts.     _facts_table (Table): SQLAlchemy Table for storing facts data with JSONB indexing.     _log_table (Table): SQLAlchemy Table for transaction logs.</p> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Asynchronously appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Asynchronously closes the current open resource or connection.</p> </li> <li> <code>create_tables</code>             \u2013              <p>Helper to create tables asynchronously (uses run_sync).</p> </li> <li> <code>delete</code>             \u2013              <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Asynchronously retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Asynchronously loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Asynchronously query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Asynchronously saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def __init__(self, engine_or_url: str | AsyncEngine, table_prefix: str = \"memstate\") -&gt; None:\n    if isinstance(engine_or_url, str):\n        self._engine = create_async_engine(engine_or_url, future=True)\n    else:\n        self._engine = engine_or_url\n\n    self._metadata = MetaData()\n    self._table_prefix = table_prefix\n\n    self._facts_table = Table(\n        f\"{table_prefix}_facts\",\n        self._metadata,\n        Column(\"id\", String, primary_key=True),\n        Column(\"doc\", JSONB, nullable=False),\n    )\n\n    self._log_table = Table(\n        f\"{table_prefix}_log\",\n        self._metadata,\n        Column(\"seq\", Integer, primary_key=True, autoincrement=True),\n        Column(\"session_id\", String, index=True, nullable=True),\n        Column(\"entry\", JSONB, nullable=False),\n        Index(f\"ix_{table_prefix}_log_entry_gin\", \"entry\", postgresql_using=\"gin\"),\n    )\n    Index(f\"ix_{table_prefix}_log_uuid\", self._log_table.c.entry[\"uuid\"].astext, postgresql_using=\"btree\"),\n    Index(\n        f\"ix_{table_prefix}_facts_checkpoint_ns\",\n        self._facts_table.c.doc[\"payload\"][\"checkpoint_ns\"].astext,\n        postgresql_using=\"btree\",\n    )\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.append_tx","title":"append_tx  <code>async</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    session_id = tx_data.get(\"session_id\")\n\n    async with self._engine.begin() as conn:\n        await conn.execute(self._log_table.insert().values(session_id=session_id, entry=tx_data))\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Asynchronously closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Asynchronously closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    await self._engine.dispose()\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.create_tables","title":"create_tables  <code>async</code>","text":"<pre><code>create_tables() -&gt; None\n</code></pre> <p>Helper to create tables asynchronously (uses run_sync).</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def create_tables(self) -&gt; None:\n    \"\"\"\n    Helper to create tables asynchronously (uses run_sync).\n\n    Returns:\n        None\n    \"\"\"\n    async with self._engine.begin() as conn:\n        await conn.run_sync(self._metadata.create_all)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Asynchronously removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._engine.begin() as conn:\n        await conn.execute(delete(self._facts_table).where(self._facts_table.c.id == id))\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete_session","title":"delete_session  <code>async</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Asynchronously deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    del_stmt = (\n        delete(self._facts_table)\n        .where(self._facts_table.c.doc[\"session_id\"].astext == session_id)\n        .returning(self._facts_table.c.id)\n    )\n    async with self._engine.begin() as conn:\n        result = await conn.execute(del_stmt)\n        return [r[0] for r in result.all()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete_txs","title":"delete_txs  <code>async</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    stmt = delete(self._log_table).where(self._log_table.c.entry[\"uuid\"].astext.in_(tx_uuids))\n\n    async with self._engine.begin() as conn:\n        await conn.execute(stmt)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_session_facts","title":"get_session_facts  <code>async</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    stmt = select(self._facts_table.c.doc).where(self._facts_table.c.doc[\"session_id\"].astext == session_id)\n    async with self._engine.connect() as conn:\n        result = await conn.execute(stmt)\n        return [r[0] for r in result.all()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_tx_log","title":"get_tx_log  <code>async</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    stmt = (\n        select(self._log_table.c.entry)\n        .where(self._log_table.c.session_id == session_id)\n        .order_by(desc(self._log_table.c.seq))\n        .limit(limit)\n        .offset(offset)\n    )\n    async with self._engine.connect() as conn:\n        result = await conn.execute(stmt)\n        return [r[0] for r in result.all()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.load","title":"load  <code>async</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Asynchronously loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Asynchronously loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    async with self._engine.connect() as conn:\n        stmt = select(self._facts_table.c.doc).where(self._facts_table.c.id == id)\n        result = await conn.execute(stmt)\n        row = result.first()\n        if row:\n            return row[0]\n        return None\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.query","title":"query  <code>async</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def query(\n    self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    stmt = select(self._facts_table.c.doc)\n\n    if type_filter:\n        stmt = stmt.where(self._facts_table.c.doc[\"type\"].astext == type_filter)\n\n    if json_filters:\n        for key, value in json_filters.items():\n            path_parts = key.split(\".\")\n            json_col: Any = self._facts_table.c.doc\n            for part in path_parts[:-1]:\n                json_col = json_col[part]\n            stmt = stmt.where(json_col[path_parts[-1]] == func.to_jsonb(value))\n\n    async with self._engine.connect() as conn:\n        result = await conn.execute(stmt)\n        return [r[0] for r in result.all()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.save","title":"save  <code>async</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>async def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    stmt = pg_insert(self._facts_table).values(id=fact_data[\"id\"], doc=fact_data)\n    upsert_stmt = stmt.on_conflict_do_update(index_elements=[\"id\"], set_={\"doc\": stmt.excluded.doc})\n    async with self._engine.begin() as conn:\n        await conn.execute(upsert_stmt)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.AsyncPostgresStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage","title":"PostgresStorage","text":"<pre><code>PostgresStorage(\n    engine_or_url: str | Engine,\n    table_prefix: str = \"memstate\",\n)\n</code></pre> <p>               Bases: <code>StorageBackend</code></p> <p>Storage backend implementation using PostgreSQL and SQLAlchemy.</p> <p>This class provides methods for interacting with a PostgreSQL database to store, retrieve, and manage structured data and logs. It uses SQLAlchemy for ORM capabilities and supports advanced querying and filtering using JSONB.</p> <p>Attributes:</p> <ul> <li> <code>_engine</code>               (<code>str | Engine</code>)           \u2013            <p>SQLAlchemy Engine or connection URL for interacting with the PostgreSQL database.</p> </li> <li> <code>_metadata</code>               (<code>MetaData</code>)           \u2013            <p>SQLAlchemy MetaData object for defining table schemas.</p> </li> <li> <code>_table_prefix</code>               (<code>str</code>)           \u2013            <p>Prefix for naming tables to avoid conflicts.</p> </li> <li> <code>_facts_table</code>               (<code>Table</code>)           \u2013            <p>SQLAlchemy Table for storing facts data with JSONB indexing.</p> </li> <li> <code>_log_table</code>               (<code>Table</code>)           \u2013            <p>SQLAlchemy Table for transaction logs.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def __init__(self, engine_or_url: str | Engine, table_prefix: str = \"memstate\") -&gt; None:\n    if isinstance(engine_or_url, str):\n        self._engine = create_engine(engine_or_url, future=True)\n    else:\n        self._engine = engine_or_url\n\n    self._metadata = MetaData()\n    self._table_prefix = table_prefix\n\n    # --- Define Tables ---\n    self._facts_table = Table(\n        f\"{table_prefix}_facts\",\n        self._metadata,\n        Column(\"id\", String, primary_key=True),\n        Column(\"doc\", JSONB, nullable=False),  # \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c JSONB \u0434\u043b\u044f \u0438\u043d\u0434\u0435\u043a\u0441\u0430\u0446\u0438\u0438\n    )\n\n    self._log_table = Table(\n        f\"{table_prefix}_log\",\n        self._metadata,\n        Column(\"seq\", Integer, primary_key=True, autoincrement=True),\n        Column(\"session_id\", String, index=True, nullable=True),\n        Column(\"entry\", JSONB, nullable=False),\n        Index(f\"ix_{table_prefix}_log_entry_gin\", \"entry\", postgresql_using=\"gin\"),\n    )\n    Index(f\"ix_{table_prefix}_log_uuid\", self._log_table.c.entry[\"uuid\"].astext, postgresql_using=\"btree\"),\n    Index(\n        f\"ix_{table_prefix}_facts_checkpoint_ns\",\n        self._facts_table.c.doc[\"payload\"][\"checkpoint_ns\"].astext,\n        postgresql_using=\"btree\",\n    )\n\n    with self._engine.begin() as conn:\n        self._metadata.create_all(conn)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.append_tx","title":"append_tx","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    session_id = tx_data.get(\"session_id\")\n\n    with self._engine.begin() as conn:\n        conn.execute(self._log_table.insert().values(session_id=session_id, entry=tx_data))\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    self._engine.dispose()\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete","title":"delete","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    with self._engine.begin() as conn:\n        conn.execute(delete(self._facts_table).where(self._facts_table.c.id == id))\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete_session","title":"delete_session","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    del_stmt = (\n        delete(self._facts_table)\n        .where(self._facts_table.c.doc[\"session_id\"].astext == session_id)\n        .returning(self._facts_table.c.id)\n    )\n\n    with self._engine.begin() as conn:\n        result = conn.execute(del_stmt)\n        return [r[0] for r in result.all()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete_txs","title":"delete_txs","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    stmt = delete(self._log_table).where(self._log_table.c.entry[\"uuid\"].astext.in_(tx_uuids))\n\n    with self._engine.begin() as conn:\n        conn.execute(stmt)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_session_facts","title":"get_session_facts","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    stmt = select(self._facts_table.c.doc).where(self._facts_table.c.doc[\"session_id\"].astext == session_id)\n    with self._engine.connect() as conn:\n        rows = conn.execute(stmt).all()\n        return [r[0] for r in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_tx_log","title":"get_tx_log","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    stmt = (\n        select(self._log_table.c.entry)\n        .where(self._log_table.c.session_id == session_id)\n        .order_by(desc(self._log_table.c.seq))\n        .limit(limit)\n        .offset(offset)\n    )\n    with self._engine.connect() as conn:\n        rows = conn.execute(stmt).all()\n        return [r[0] for r in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.load","title":"load","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    with self._engine.connect() as conn:\n        stmt = select(self._facts_table.c.doc).where(self._facts_table.c.id == id)\n        row = conn.execute(stmt).first()\n        if row:\n            return row[0]  # SQLAlchemy deserializes JSONB automatically\n        return None\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.query","title":"query","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def query(self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    stmt = select(self._facts_table.c.doc)\n\n    # 1. Filter by type (fact)\n    if type_filter:\n        # Postgres JSONB access: doc-&gt;&gt;'type'\n        stmt = stmt.where(self._facts_table.c.doc[\"type\"].astext == type_filter)\n\n    # 2. JSON filters (the hardest part)\n    # We expect keys of type \"payload.user.id\"\n    if json_filters:\n        for key, value in json_filters.items():\n            # Split the path: payload.role -&gt; ['payload', 'role']\n            path_parts = key.split(\".\")\n\n            # Building a JSONB access chain\n            json_col: ColumnElement[Any] = self._facts_table.c.doc\n\n            # Go deeper to the last key\n            for part in path_parts[:-1]:\n                json_col = json_col[part]\n\n            # Compare the last key\n            # Important: cast value to JSONB so that types (int/bool/str) work\n            # Or use the @&gt; (contains) operator for reliability\n\n            # Simple option (SQLAlchemy automatically casts types when comparing JSONB)\n            stmt = stmt.where(json_col[path_parts[-1]] == func.to_jsonb(value))\n\n    with self._engine.connect() as conn:\n        rows = conn.execute(stmt).all()\n        return [r[0] for r in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.save","title":"save","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/postgres.py</code> <pre><code>def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    # Postgres Native Upsert (INSERT ... ON CONFLICT DO UPDATE)\n    stmt = pg_insert(self._facts_table).values(id=fact_data[\"id\"], doc=fact_data)\n    upsert_stmt = stmt.on_conflict_do_update(\n        index_elements=[\"id\"], set_={\"doc\": stmt.excluded.doc}  # Conflict over PK\n    )\n\n    with self._engine.begin() as conn:\n        conn.execute(upsert_stmt)\n</code></pre>"},{"location":"api/backends/#memstate.backends.postgres.PostgresStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.redis","title":"redis","text":"<p>Redis storage backend implementation.</p> <p>Classes:</p> <ul> <li> <code>AsyncRedisStorage</code>           \u2013            <p>AsyncRedisStorage class provides an async Redis-based implementation for storing and retrieving structured</p> </li> <li> <code>RedisStorage</code>           \u2013            <p>RedisStorage class provides a Redis-based implementation for storing and retrieving structured</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage","title":"AsyncRedisStorage","text":"<pre><code>AsyncRedisStorage(\n    client_or_url: Union[\n        str, Redis\n    ] = \"redis://localhost:6379/0\",\n)\n</code></pre> <p>               Bases: <code>AsyncStorageBackend</code></p> <p>AsyncRedisStorage class provides an async Redis-based implementation for storing and retrieving structured data, facilitating the management of session-based storage, type-based indexing, and transaction logs.</p> <p>This class aims to handle data persistence efficiently using Redis as the backend, enabling features such as loading, saving, querying, and deleting data with support for session-specific and type-specific operations. It includes tools to query and backfill JSON filters and also supports transactional logging.</p> <p>Attributes:</p> <ul> <li> <code>prefix</code>               (<code>str</code>)           \u2013            <p>Prefix used for all Redis keys to avoid collisions with other data in the Redis instance.</p> </li> <li> <code>r</code>               (<code>Redis</code>)           \u2013            <p>Redis client for performing operations against the Redis database.</p> </li> <li> <code>_owns_client</code>               (<code>bool</code>)           \u2013            <p>Flag indicating whether the Redis client was created by the AsyncRedisStorage class.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Asynchronously appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Asynchronously closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Asynchronously retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Asynchronously loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Asynchronously query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Asynchronously saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def __init__(self, client_or_url: Union[str, \"aredis.Redis\"] = \"redis://localhost:6379/0\") -&gt; None:\n    self.prefix = \"mem:\"\n\n    if isinstance(client_or_url, str):\n        self.r = aredis.from_url(client_or_url, decode_responses=True)  # type: ignore[no-untyped-call]\n        self._owns_client = True\n    else:\n        self.r = client_or_url\n        self._owns_client = False\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.append_tx","title":"append_tx  <code>async</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    uuid = tx_data[\"uuid\"]\n    seq = tx_data[\"seq\"]\n    session_id = tx_data.get(\"session_id\")\n\n    async with self.r.pipeline() as pipe:\n        pipe.set(self._tx_key(uuid), json.dumps(tx_data, default=str))\n        pipe.zadd(f\"{self.prefix}tx_log\", {uuid: seq})\n        if session_id:\n            pipe.zadd(f\"{self.prefix}tx_log:session:{session_id}\", {uuid: seq})\n        await pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Asynchronously closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Asynchronously closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    if self._owns_client:\n        await self.r.aclose()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Asynchronously removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    data = await self.load(id)\n    if data:\n        async with self.r.pipeline() as pipe:\n            pipe.delete(self._key(id))\n            pipe.srem(f\"{self.prefix}type:{data['type']}\", id)\n            if data.get(\"session_id\"):\n                pipe.srem(f\"{self.prefix}session:{data['session_id']}\", id)\n            await pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete_session","title":"delete_session  <code>async</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Asynchronously deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    key = f\"{self.prefix}session:{session_id}\"\n    ids = list(await self.r.smembers(key))\n\n    if not ids:\n        return []\n\n    async with self.r.pipeline() as pipe:\n        for i in ids:\n            pipe.delete(self._key(i))\n        pipe.delete(key)\n        await pipe.execute()\n\n    return ids\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete_txs","title":"delete_txs  <code>async</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Asynchronously removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    keys_to_load = [self._tx_key(uid) for uid in tx_uuids]\n    raw_data = await self.r.mget(keys_to_load)\n\n    sessions_to_clean: dict[str, list[str]] = {}  # {session_id: [uuid, uuid]}\n    for raw in raw_data:\n        if raw:\n            tx = json.loads(raw)\n            sid = tx.get(\"session_id\")\n            uuid = tx[\"uuid\"]\n            if sid:\n                if sid not in sessions_to_clean:\n                    sessions_to_clean[sid] = []\n                sessions_to_clean[sid].append(uuid)\n\n    async with self.r.pipeline() as pipe:\n        pipe.delete(*keys_to_load)\n        pipe.zrem(f\"{self.prefix}tx_log\", *tx_uuids)\n        for sid, uuids in sessions_to_clean.items():\n            pipe.zrem(f\"{self.prefix}tx_log:session:{sid}\", *uuids)\n        await pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_session_facts","title":"get_session_facts  <code>async</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    key = f\"{self.prefix}session:{session_id}\"\n    ids = await self.r.smembers(key)\n\n    if not ids:\n        return []\n\n    async with self.r.pipeline() as pipe:\n        for i in ids:\n            pipe.get(self._key(i))\n        raw_docs = await pipe.execute()\n\n    results = []\n    for raw_doc in raw_docs:\n        if raw_doc:\n            results.append(json.loads(raw_doc))\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_tx_log","title":"get_tx_log  <code>async</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    index_key = f\"{self.prefix}tx_log:session:{session_id}\"\n    uuids = await self.r.zrevrange(index_key, offset, offset + limit - 1)\n\n    if not uuids:\n        return []\n\n    tx_keys = [self._tx_key(uuid) for uuid in uuids]\n    raw_data = await self.r.mget(tx_keys)\n\n    results = []\n    for item in raw_data:\n        if item:\n            results.append(json.loads(item))\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.load","title":"load  <code>async</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Asynchronously loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Asynchronously loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    raw_data = await self.r.get(self._key(id))\n    return json.loads(raw_data) if raw_data else None\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.query","title":"query  <code>async</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def query(\n    self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    if type_filter:\n        ids = await self.r.smembers(f\"{self.prefix}type:{type_filter}\")\n    else:\n        keys = await self.r.keys(f\"{self.prefix}fact:*\")\n        ids = [k.split(\":\")[-1] for k in keys]\n\n    if not ids:\n        return []\n\n    async with self.r.pipeline() as pipe:\n        for i in list(ids):\n            pipe.get(self._key(i))\n        raw_docs = await pipe.execute()\n\n    results = []\n    for doc_str in raw_docs:\n        if not doc_str:\n            continue\n        fact = json.loads(doc_str)\n\n        if json_filters:\n            match = True\n            for k, v in json_filters.items():\n                actual_val = self._get_value_by_path(fact, k)\n                if actual_val != v:\n                    match = False\n                    break\n            if not match:\n                continue\n        results.append(fact)\n\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.save","title":"save  <code>async</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>async def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    async with self.r.pipeline() as pipe:\n        pipe.set(self._key(fact_data[\"id\"]), json.dumps(fact_data))\n        pipe.sadd(f\"{self.prefix}type:{fact_data['type']}\", fact_data[\"id\"])\n        if fact_data.get(\"session_id\"):\n            pipe.sadd(f\"{self.prefix}session:{fact_data['session_id']}\", fact_data[\"id\"])\n        await pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.AsyncRedisStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage","title":"RedisStorage","text":"<pre><code>RedisStorage(\n    client_or_url: Union[\n        str, Redis\n    ] = \"redis://localhost:6379/0\",\n)\n</code></pre> <p>               Bases: <code>StorageBackend</code></p> <p>RedisStorage class provides a Redis-based implementation for storing and retrieving structured data, facilitating the management of session-based storage, type-based indexing, and transaction logs.</p> <p>This class aims to handle data persistence efficiently using Redis as the backend, enabling features such as loading, saving, querying, and deleting data with support for session-specific and type-specific operations. It includes tools to query and backfill JSON filters and also supports transactional logging.</p> <p>Attributes:</p> <ul> <li> <code>prefix</code>               (<code>str</code>)           \u2013            <p>Prefix used for all Redis keys to avoid collisions with other data in the Redis instance.</p> </li> <li> <code>r</code>               (<code>Redis</code>)           \u2013            <p>Redis client for performing operations against the Redis database.</p> </li> <li> <code>_owns_client</code>               (<code>bool</code>)           \u2013            <p>Flag indicating whether the Redis client was created by the RedisStorage class.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def __init__(self, client_or_url: Union[str, \"redis.Redis\"] = \"redis://localhost:6379/0\") -&gt; None:\n    self.prefix = \"mem:\"\n\n    if isinstance(client_or_url, str):\n        self.r = redis.from_url(client_or_url, decode_responses=True)  # type: ignore[no-untyped-call]\n        self._owns_client = True\n    else:\n        self.r = client_or_url\n        self._owns_client = False\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.append_tx","title":"append_tx","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    uuid = tx_data[\"uuid\"]\n    seq = tx_data[\"seq\"]\n    session_id = tx_data.get(\"session_id\")\n\n    pipe = self.r.pipeline()\n    pipe.set(self._tx_key(uuid), json.dumps(tx_data, default=str))\n    pipe.zadd(f\"{self.prefix}tx_log\", {uuid: seq})\n    if session_id:\n        pipe.zadd(f\"{self.prefix}tx_log:session:{session_id}\", {uuid: seq})\n    pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    if self._owns_client:\n        self.r.close()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete","title":"delete","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    # Need to load first to clear indexes? For speed we might skip,\n    # but correctly we should clean up sets.\n    # For MVP: just delete key. Indexes might have stale IDs (handled by load check).\n    data = self.load(id)\n    if data:\n        pipe = self.r.pipeline()\n        pipe.delete(self._key(id))\n        pipe.srem(f\"{self.prefix}type:{data['type']}\", id)\n        if data.get(\"session_id\"):\n            pipe.srem(f\"{self.prefix}session:{data['session_id']}\", id)\n        pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete_session","title":"delete_session","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all facts records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Deletes all facts associated with a given session ID from the store.\n\n    This method identifies all facts records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    # Get IDs from session index\n    key = f\"{self.prefix}session:{session_id}\"\n    ids = list(self.r.smembers(key))\n    if not ids:\n        return []\n\n    pipe = self.r.pipeline()\n    for i in ids:\n        pipe.delete(self._key(i))\n        # Note: cleaning type index is expensive here without reading each fact,\n        # acceptable tradeoff for Redis expiration logic later.\n    pipe.delete(key)  # clear index\n    pipe.execute()\n    return ids\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete_txs","title":"delete_txs","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n\n    keys_to_load = [self._tx_key(uid) for uid in tx_uuids]\n    raw_data = self.r.mget(keys_to_load)\n\n    sessions_to_clean: dict[str, list[str]] = {}  # {session_id: [uuid, uuid]}\n\n    for raw in raw_data:\n        s = self._to_str(raw)\n        if s:\n            tx = json.loads(s)\n            sid = tx.get(\"session_id\")\n            uuid = tx[\"uuid\"]\n            if sid:\n                if sid not in sessions_to_clean:\n                    sessions_to_clean[sid] = []\n                sessions_to_clean[sid].append(uuid)\n\n    with self.r.pipeline() as pipe:\n        pipe.delete(*keys_to_load)\n\n        pipe.zrem(f\"{self.prefix}tx_log\", *tx_uuids)\n\n        for sid, uuids in sessions_to_clean.items():\n            pipe.zrem(f\"{self.prefix}tx_log:session:{sid}\", *uuids)\n\n        pipe.execute()\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_session_facts","title":"get_session_facts","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    key = f\"{self.prefix}session:{session_id}\"\n    ids = self.r.smembers(key)\n\n    if not ids:\n        return []\n\n    pipe = self.r.pipeline()\n    for i in ids:\n        pipe.get(self._key(i))\n    raw_docs = pipe.execute()\n\n    results = []\n    for raw_doc in raw_docs:\n        doc_str = self._to_str(raw_doc)\n        if doc_str:\n            results.append(json.loads(doc_str))\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_tx_log","title":"get_tx_log","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    index_key = f\"{self.prefix}tx_log:session:{session_id}\"\n    uuids = self.r.zrevrange(index_key, offset, offset + limit - 1)\n\n    if not uuids:\n        return []\n\n    tx_keys = [self._tx_key(uuid) for uuid in uuids]\n    raw_data = self.r.mget(tx_keys)\n\n    results = []\n    for item in raw_data:\n        s = self._to_str(item)\n        if s is not None:\n            results.append(json.loads(s))\n\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.load","title":"load","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    raw_data = self.r.get(self._key(id))\n    json_str = self._to_str(raw_data)\n    return json.loads(json_str) if json_str else None\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.query","title":"query","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def query(self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    # Optimization: Use Set Intersections if filters allow, otherwise scan\n    # Redis without RediSearch is poor at complex filtering.\n    # Strategy: Get IDs from Type Index -&gt; Load -&gt; Filter in Python\n\n    if type_filter:\n        ids = self.r.smembers(f\"{self.prefix}type:{type_filter}\")\n    else:\n        # Dangerous scan for all keys, acceptable for MVP/Small scale\n        keys = self.r.keys(f\"{self.prefix}fact:*\")\n        ids = [k.split(\":\")[-1] for k in keys]\n\n    results = []\n    # Pipeline loading for speed\n    if not ids:\n        return []\n\n    pipe = self.r.pipeline()\n    id_list = list(ids)\n    for i in id_list:\n        pipe.get(self._key(i))\n    raw_docs = pipe.execute()\n\n    for raw_doc in raw_docs:\n        if not raw_doc:\n            continue\n        doc_str = self._to_str(raw_doc)\n        if doc_str is None:\n            continue\n        fact = json.loads(doc_str)\n\n        # JSON Filter in Python (Backfill for NoSQL)\n        if json_filters:\n            match = True\n            for k, v in json_filters.items():\n                actual_val = self._get_value_by_path(fact, k)\n                if actual_val != v:\n                    match = False\n                    break\n            if not match:\n                continue\n        results.append(fact)\n\n    return results\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.save","title":"save","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/redis.py</code> <pre><code>def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    self.r.set(self._key(fact_data[\"id\"]), json.dumps(fact_data))\n    self.r.sadd(f\"{self.prefix}type:{fact_data['type']}\", fact_data[\"id\"])\n    if fact_data.get(\"session_id\"):\n        self.r.sadd(f\"{self.prefix}session:{fact_data['session_id']}\", fact_data[\"id\"])\n</code></pre>"},{"location":"api/backends/#memstate.backends.redis.RedisStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.sqlite","title":"sqlite","text":"<p>SQLite storage backend implementation.</p> <p>Classes:</p> <ul> <li> <code>AsyncSQLiteStorage</code>           \u2013            <p>Async SQLite-based storage backend for managing structured data and transactional logs.</p> </li> <li> <code>SQLiteStorage</code>           \u2013            <p>SQLite-based storage backend for managing structured data and transactional logs.</p> </li> </ul>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage","title":"AsyncSQLiteStorage","text":"<pre><code>AsyncSQLiteStorage(\n    connection_or_path: str | Connection = \"memory.db\",\n)\n</code></pre> <p>               Bases: <code>AsyncStorageBackend</code></p> <p>Async SQLite-based storage backend for managing structured data and transactional logs.</p> <p>This class provides functionality to persistently store, retrieve, and manipulate data and transaction logs using an SQLite database. It supports thread-safe operations, ensures data integrity, and utilizes SQLite-specific features such as WAL mode and JSON querying.</p> Example <pre><code>storage = AsyncSQLiteStorage(\"agent_async.db\")\nawait storage.connect()\n</code></pre> <p>Attributes:     _conn (str | aiosqlite.Connection): SQLite database connection object.     _owns_connection (bool): Specifies whether the SQLiteStorage instance owns the         connection and is responsible for closing it.     _lock (asyncio.Lock): Threading lock that ensures thread-safe access to the database.     _db (aiosqlite.Connection): Async SQLite connection object.     _path (str | None): Path to the SQLite database file.</p> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Asynchronously appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Asynchronously closes the current open resource or connection.</p> </li> <li> <code>connect</code>             \u2013              <p>Async initialization. Must be called before use.</p> </li> <li> <code>delete</code>             \u2013              <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Asynchronously retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Asynchronously loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Asynchronously query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Asynchronously saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def __init__(self, connection_or_path: str | aiosqlite.Connection = \"memory.db\") -&gt; None:\n    if aiosqlite is None:\n        raise ImportError(\"Run `pip install aiosqlite` to use AsyncSQLiteStorage.\")\n\n    self._lock = asyncio.Lock()\n    self._owns_connection = False\n    self._db: Any = None\n    self._path: str | None = None\n\n    if isinstance(connection_or_path, str):\n        self._path = connection_or_path\n        self._owns_connection = True\n    else:\n        self._db = connection_or_path\n        self._owns_connection = False\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.append_tx","title":"append_tx  <code>async</code>","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        await self._db.execute(\n            \"\"\"\n            INSERT INTO tx_log(uuid, timestamp, data)\n            VALUES (?, ?, ?)\n            \"\"\",\n            (tx_data[\"uuid\"], tx_data[\"ts\"], json.dumps(tx_data, default=str)),\n        )\n        await self._db.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Asynchronously closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Asynchronously closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    if self._db:\n        await self._db.close()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.connect","title":"connect  <code>async</code>","text":"<pre><code>connect() -&gt; None\n</code></pre> <p>Async initialization. Must be called before use.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def connect(self) -&gt; None:\n    \"\"\"\n    Async initialization. Must be called before use.\n\n    Returns:\n        None\n    \"\"\"\n    if self._owns_connection and self._path:\n        self._db = await aiosqlite.connect(self._path)\n\n    if self._db is None:\n        raise ValueError(\"Connection not initialized properly.\")\n\n    self._db.row_factory = aiosqlite.Row\n    await self._init_db()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Asynchronously removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Asynchronously removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        await self._db.execute(\"DELETE FROM facts WHERE id = ?\", (id,))\n        await self._db.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete_session","title":"delete_session  <code>async</code>","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Asynchronously deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Asynchronously deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    async with self._lock:\n        cursor = await self._db.execute(\n            \"DELETE FROM facts WHERE json_extract(data, '$.session_id') = ? RETURNING id\", (session_id,)\n        )\n        rows = await cursor.fetchall()\n        ids = [row[\"id\"] for row in rows]\n        await self._db.commit()\n        return ids\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete_txs","title":"delete_txs  <code>async</code>","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n    async with self._lock:\n        placeholders = \",\".join(\"?\" for _ in tx_uuids)\n        await self._db.execute(f\"DELETE FROM tx_log WHERE uuid IN ({placeholders})\", tuple(tx_uuids))  # nosec B608\n        await self._db.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_session_facts","title":"get_session_facts  <code>async</code>","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    async with self._lock:\n        async with self._db.execute(\n            \"SELECT data FROM facts WHERE json_extract(data, '$.session_id') = ?\", (session_id,)\n        ) as cursor:\n            rows = await cursor.fetchall()\n            return [json.loads(row[\"data\"]) for row in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_tx_log","title":"get_tx_log  <code>async</code>","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    async with self._lock:\n        cursor = await self._db.execute(\n            \"SELECT data FROM tx_log WHERE json_extract(data, '$.session_id') = ? ORDER BY tx_id DESC LIMIT ? OFFSET ?\",\n            (session_id, limit, offset),\n        )\n\n        rows = await cursor.fetchall()\n        return [json.loads(row[\"data\"]) for row in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.load","title":"load  <code>async</code>","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Asynchronously loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Asynchronously loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    async with self._lock:\n        async with self._db.execute(\"SELECT data FROM facts WHERE id = ?\", (id,)) as cursor:\n            row = await cursor.fetchone()\n            return json.loads(row[\"data\"]) if row else None\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.query","title":"query  <code>async</code>","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def query(\n    self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    query = \"SELECT data FROM facts WHERE 1=1\"\n    params = []\n\n    if type_filter:\n        query += \" AND type = ?\"\n        params.append(type_filter)\n\n    if json_filters:\n        for key, value in json_filters.items():\n            if not re.match(r\"^[a-zA-Z0-9_.]+$\", key):\n                raise ValueError(f\"Invalid characters in filter key: {key}\")\n            query += f\" AND json_extract(data, '$.{key}') = ?\"\n            params.append(value)\n\n    async with self._lock:\n        async with self._db.execute(query, tuple(params)) as cursor:\n            rows = await cursor.fetchall()\n            return [json.loads(row[\"data\"]) for row in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.save","title":"save  <code>async</code>","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Asynchronously saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>async def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Asynchronously saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        await self._db.execute(\n            \"\"\"\n            INSERT OR REPLACE INTO facts(id, type, data)\n            VALUES (?, ?, ?)\n            \"\"\",\n            (\n                fact_data[\"id\"],\n                fact_data.get(\"type\", \"unknown\"),\n                json.dumps(fact_data, default=str),\n            ),\n        )\n        await self._db.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.AsyncSQLiteStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage","title":"SQLiteStorage","text":"<pre><code>SQLiteStorage(\n    connection_or_path: str | Connection = \"memory.db\",\n)\n</code></pre> <p>               Bases: <code>StorageBackend</code></p> <p>SQLite-based storage backend for managing structured data and transactional logs.</p> <p>This class provides functionality to persistently store, retrieve, and manipulate data and transaction logs using an SQLite database. It supports thread-safe operations, ensures data integrity, and utilizes SQLite-specific features such as WAL mode and JSON querying.</p> <p>Attributes:     _conn (sqlite3.Connection): SQLite database connection object.     _owns_connection (bool): Specifies whether the SQLiteStorage instance owns the         connection and is responsible for closing it.     _lock (threading.RLock): Threading lock that ensures thread-safe access to the database.</p> <p>Methods:</p> <ul> <li> <code>append_tx</code>             \u2013              <p>Appends a transaction record to the transaction log.</p> </li> <li> <code>close</code>             \u2013              <p>Closes the current open resource or connection.</p> </li> <li> <code>delete</code>             \u2013              <p>Removes an entry from the store based on the provided identifier. If the identifier</p> </li> <li> <code>delete_session</code>             \u2013              <p>Deletes all facts associated with a given session ID from the store.</p> </li> <li> <code>delete_txs</code>             \u2013              <p>Removes a list of transactions from the transaction log whose session IDs match the provided</p> </li> <li> <code>get_session_facts</code>             \u2013              <p>Retrieves all facts associated with a specific session.</p> </li> <li> <code>get_tx_log</code>             \u2013              <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in</p> </li> <li> <code>load</code>             \u2013              <p>Loads an item from the store based on the provided identifier.</p> </li> <li> <code>query</code>             \u2013              <p>Query data from the internal store based on specified filters.</p> </li> <li> <code>save</code>             \u2013              <p>Saves the given fact data into the internal store. The save operation</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def __init__(self, connection_or_path: str | sqlite3.Connection = \"memory.db\") -&gt; None:\n    self._lock = threading.RLock()\n    self._owns_connection = False\n\n    if isinstance(connection_or_path, str):\n        self._conn = sqlite3.connect(connection_or_path, check_same_thread=False)\n        self._conn.row_factory = sqlite3.Row\n        self._owns_connection = True\n    elif isinstance(connection_or_path, sqlite3.Connection):\n        self._conn = connection_or_path\n        self._conn.row_factory = sqlite3.Row\n        self._owns_connection = False\n    else:\n        raise ValueError(f\"Invalid connection type: {type(connection_or_path)}\")\n\n    self._init_db()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.append_tx","title":"append_tx","text":"<pre><code>append_tx(tx_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Appends a transaction record to the transaction log.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def append_tx(self, tx_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Appends a transaction record to the transaction log.\n\n    Args:\n        tx_data (dict[str, Any]): A dictionary containing transaction data to be appended.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(\n            \"\"\"\n                  INSERT INTO tx_log(uuid, timestamp, data)\n                  VALUES (?, ?, ?)\n                  \"\"\",\n            (tx_data[\"uuid\"], tx_data[\"ts\"], json.dumps(tx_data, default=str)),\n        )\n        self._conn.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.append_tx(tx_data)","title":"<code>tx_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing transaction data to be appended.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the current open resource or connection.</p> <p>This method is responsible for cleanup or finalization tasks. It ensures that resources, such as file handles or network connections, are properly released or closed. Once called, the resource cannot be used again unless it is reopened.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Closes the current open resource or connection.\n\n    This method is responsible for cleanup or finalization tasks.\n    It ensures that resources, such as file handles or network connections,\n    are properly released or closed. Once called, the resource cannot\n    be used again unless it is reopened.\n\n    Returns:\n        None\n    \"\"\"\n    if self._owns_connection:\n        self._conn.close()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete","title":"delete","text":"<pre><code>delete(id: str) -&gt; None\n</code></pre> <p>Removes an entry from the store based on the provided identifier. If the identifier does not exist, the method performs no action and completes silently.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def delete(self, id: str) -&gt; None:\n    \"\"\"\n    Removes an entry from the store based on the provided identifier. If the identifier\n    does not exist, the method performs no action and completes silently.\n\n    Args:\n        id (str): The identifier of the entry to be removed from the store. Must be a string.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(\"DELETE FROM facts WHERE id = ?\", (id,))\n        self._conn.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the entry to be removed from the store. Must be a string.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete_session","title":"delete_session","text":"<pre><code>delete_session(session_id: str) -&gt; list[str]\n</code></pre> <p>Deletes all facts associated with a given session ID from the store.</p> <p>This method identifies all fact records in the store that are linked to the specified session ID, removes them, and returns a list of fact identifiers that were deleted.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of fact ids identifiers that were deleted from the store.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def delete_session(self, session_id: str) -&gt; list[str]:\n    \"\"\"\n    Deletes all facts associated with a given session ID from the store.\n\n    This method identifies all fact records in the store that are linked to the specified\n    session ID, removes them, and returns a list of fact identifiers that were deleted.\n\n    Args:\n        session_id (str): The identifier of the session whose associated facts should be removed.\n\n    Returns:\n        A list of fact ids identifiers that were deleted from the store.\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n\n        c.execute(\"DELETE FROM facts WHERE json_extract(data, '$.session_id') = ? RETURNING id\", (session_id,))\n        rows = c.fetchall()\n        ids = [row[\"id\"] for row in rows]\n        self._conn.commit()\n        return ids\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose associated facts should be removed.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete_txs","title":"delete_txs","text":"<pre><code>delete_txs(tx_uuids: list[str]) -&gt; None\n</code></pre> <p>Removes a list of transactions from the transaction log whose session IDs match the provided transaction IDs. If the provided list is empty, no transactions are processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def delete_txs(self, tx_uuids: list[str]) -&gt; None:\n    \"\"\"\n    Removes a list of transactions from the transaction log whose session IDs match the provided\n    transaction IDs. If the provided list is empty, no transactions are processed.\n\n    Args:\n        tx_uuids (list[str]): A list of transaction UUIDs to be removed from the log.\n\n    Returns:\n        None\n    \"\"\"\n    if not tx_uuids:\n        return\n    with self._lock:\n        c = self._conn.cursor()\n        placeholders = \",\".join(\"?\" for _ in tx_uuids)\n        c.execute(f\"DELETE FROM tx_log WHERE uuid IN ({placeholders})\", tuple(tx_uuids))  # nosec B608\n        self._conn.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.delete_txs(tx_uuids)","title":"<code>tx_uuids</code>","text":"(<code>list[str]</code>)           \u2013            <p>A list of transaction UUIDs to be removed from the log.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_session_facts","title":"get_session_facts","text":"<pre><code>get_session_facts(session_id: str) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves all facts associated with a specific session.</p> <p>This method filters and returns a list of all facts from the internal store that match the provided session ID. Each fact is represented as a dictionary, and the list may be empty if no facts match the provided session ID.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries, where each dictionary represents a fact related to the specified session.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def get_session_facts(self, session_id: str) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves all facts associated with a specific session.\n\n    This method filters and returns a list of all facts from the internal store\n    that match the provided session ID. Each fact is represented as a dictionary,\n    and the list may be empty if no facts match the provided session ID.\n\n    Args:\n        session_id (str): The identifier of the session whose facts are to be retrieved.\n\n    Returns:\n        A list of dictionaries, where each dictionary represents a fact related to the specified session.\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(\"SELECT data FROM facts WHERE json_extract(data, '$.session_id') = ?\", (session_id,))\n        return [json.loads(row[\"data\"]) for row in c.fetchall()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_session_facts(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose facts are to be retrieved.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_tx_log","title":"get_tx_log","text":"<pre><code>get_tx_log(\n    session_id: str, limit: int = 100, offset: int = 0\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Retrieves and returns a portion of the transaction log. The transaction log is accessed in reverse order of insertion, i.e., the most recently added item is the first in the result.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries representing the requested subset of the transaction log. The dictionaries contain details of individual transaction log entries.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def get_tx_log(self, session_id: str, limit: int = 100, offset: int = 0) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Retrieves and returns a portion of the transaction log. The transaction log is accessed in\n    reverse order of insertion, i.e., the most recently added item is the first in the result.\n\n    Args:\n        session_id (str): The identifier of the session whose transactions should be retrieved.\n        limit (int): The maximum number of transaction log entries to be retrieved. Default is 100.\n        offset (int): The starting position relative to the most recent entry that determines where to begin\n            retrieving the log entries. Default is 0.\n\n    Returns:\n        A list of dictionaries representing the requested subset of the transaction log. The dictionaries\n            contain details of individual transaction log entries.\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n\n        c.execute(\n            \"SELECT data FROM tx_log WHERE json_extract(data, '$.session_id') = ? ORDER BY tx_id DESC LIMIT ? OFFSET ?\",\n            (session_id, limit, offset),\n        )\n        rows = c.fetchall()\n        return [json.loads(row[\"data\"]) for row in rows]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_tx_log(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The identifier of the session whose transactions should be retrieved.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_tx_log(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The maximum number of transaction log entries to be retrieved. Default is 100.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.get_tx_log(offset)","title":"<code>offset</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The starting position relative to the most recent entry that determines where to begin retrieving the log entries. Default is 0.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.load","title":"load","text":"<pre><code>load(id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Loads an item from the store based on the provided identifier.</p> <p>This method retrieves the item associated with the given <code>id</code> from the internal store. If no item is found for the provided identifier, it returns <code>None</code>.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>The item retrieved from the store or <code>None</code> if the identifier does not exist in the store.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def load(self, id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Loads an item from the store based on the provided identifier.\n\n    This method retrieves the item associated with the given `id`\n    from the internal store. If no item is found for the provided\n    identifier, it returns ``None``.\n\n    Args:\n        id (str): The unique identifier of the item to load.\n\n    Returns:\n        The item retrieved from the store or ``None`` if the identifier does not exist in the store.\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(\"SELECT data FROM facts WHERE id = ?\", (id,))\n        row = c.fetchone()\n        return json.loads(row[\"data\"]) if row else None\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.load(id)","title":"<code>id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the item to load.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.query","title":"query","text":"<pre><code>query(\n    type_filter: str | None = None,\n    json_filters: dict[str, Any] | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Query data from the internal store based on specified filters.</p> <p>This method iterates through the internal store and filters the data based on the provided <code>type_filter</code> and <code>json_filters</code>. The results will include only the entries that match all specified filtering criteria.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing the data entries from the internal store that match the specified filters.</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def query(self, type_filter: str | None = None, json_filters: dict[str, Any] | None = None) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Query data from the internal store based on specified filters.\n\n    This method iterates through the internal store and filters the data based on\n    the provided `type_filter` and `json_filters`. The results will include\n    only the entries that match all specified filtering criteria.\n\n    Args:\n        type_filter (str | None): Optional filter to include only items with a matching \"type\" field.\n            If None, this filter is ignored.\n        json_filters (dict[str, Any] | None): A dictionary where keys represent the path within the JSON\n            data structure, and values represent the required values for inclusion.\n            If None, this filter is ignored.\n\n    Returns:\n        A list of dictionaries containing the data entries from the internal store that match the specified filters.\n    \"\"\"\n    query = \"SELECT data FROM facts WHERE 1=1\"\n    params = []\n\n    if type_filter:\n        query += \" AND type = ?\"\n        params.append(type_filter)\n\n    if json_filters:\n        for key, value in json_filters.items():\n            if not re.match(r\"^[a-zA-Z0-9_.]+$\", key):\n                raise ValueError(f\"Invalid characters in filter key: {key}\")\n            query += f\" AND json_extract(data, '$.{key}') = ?\"\n            params.append(value)\n\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(query, params)\n        return [json.loads(row[\"data\"]) for row in c.fetchall()]\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.query(type_filter)","title":"<code>type_filter</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional filter to include only items with a matching \"type\" field. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.query(json_filters)","title":"<code>json_filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary where keys represent the path within the JSON data structure, and values represent the required values for inclusion. If None, this filter is ignored.</p>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.save","title":"save","text":"<pre><code>save(fact_data: dict[str, Any]) -&gt; None\n</code></pre> <p>Saves the given fact data into the internal store. The save operation and ensures data consistency by utilizing a lock mechanism.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/backends/sqlite.py</code> <pre><code>def save(self, fact_data: dict[str, Any]) -&gt; None:\n    \"\"\"\n    Saves the given fact data into the internal store. The save operation\n    and ensures data consistency by utilizing a lock mechanism.\n\n    Args:\n        fact_data (dict[str, Any]): A dictionary containing fact data to be stored. The dictionary\n            must include an \"id\" key with a corresponding value as a unique identifier.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        c = self._conn.cursor()\n        c.execute(\n            \"\"\"\n            INSERT OR REPLACE INTO facts(id, type, data)\n            VALUES (?, ?, ?)\n            \"\"\",\n            (\n                fact_data[\"id\"],\n                fact_data.get(\"type\", \"unknown\"),\n                json.dumps(fact_data, default=str),\n            ),\n        )\n        self._conn.commit()\n</code></pre>"},{"location":"api/backends/#memstate.backends.sqlite.SQLiteStorage.save(fact_data)","title":"<code>fact_data</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary containing fact data to be stored. The dictionary must include an \"id\" key with a corresponding value as a unique identifier.</p>"},{"location":"api/integrations/","title":"Integrations","text":""},{"location":"api/integrations/#memstate.integrations","title":"integrations","text":"<p>Modules:</p> <ul> <li> <code>chroma</code>           \u2013            <p>Chroma DB integration.</p> </li> <li> <code>langgraph</code>           \u2013            <p>LangGraph Checkpointer.</p> </li> <li> <code>qdrant</code>           \u2013            <p>Qdrant integration.</p> </li> </ul>"},{"location":"api/integrations/#memstate.integrations.chroma","title":"chroma","text":"<p>Chroma DB integration.</p> <p>Classes:</p> <ul> <li> <code>AsyncChromaSyncHook</code>           \u2013            <p>Handles synchronization of memory data with Chroma collections by integrating</p> </li> <li> <code>ChromaSyncHook</code>           \u2013            <p>Handles synchronization of memory data with Chroma collections by integrating</p> </li> </ul>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook","title":"AsyncChromaSyncHook","text":"<pre><code>AsyncChromaSyncHook(\n    client: AsyncClientAPI,\n    collection_name: str,\n    embedding_fn: (\n        EmbeddingFunction[Embeddable] | None\n    ) = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n)\n</code></pre> <p>               Bases: <code>AsyncMemoryHook</code></p> <p>Handles synchronization of memory data with Chroma collections by integrating fact operations and data transformations.</p> <p>This class is responsible for managing connections to a Chroma collection via AsyncClientAPI, extracting and formatting text and metadata as per the provided configuration, and performing operations like deletion or upserting of facts based on various triggers or operations. It also provides flexibility in defining target data types, metadata extraction, text processing, and overall data synchronization rules.</p> Example <pre><code>client = await chromadb.AsyncHttpClient()\nhook = AsyncChromaSyncHook(client, \"my_collection\", text_field=\"content\")\nstore = AsyncMemoryStore(AsyncInMemoryStorage(), hooks=[hook])\nawait store.commit_model(...)\n</code></pre> <p>Attributes:</p> <ul> <li> <code>client</code>               (<code>AsyncClientAPI</code>)           \u2013            <p>The Chroma client instance used for collection access and management.</p> </li> <li> <code>collection_name</code>               (<code>str</code>)           \u2013            <p>The name of the Chroma collection to be synchronized.</p> </li> <li> <code>embedding_fn</code>               (<code>EmbeddingFunction | None</code>)           \u2013            <p>Optional function for generating embeddings from text.</p> </li> <li> <code>target_types</code>               (<code>set[str]</code>)           \u2013            <p>A set of fact types allowed for synchronization. If empty, all types are allowed.</p> </li> <li> <code>text_field</code>               (<code>str | None</code>)           \u2013            <p>Field name of text in fact.</p> </li> <li> <code>text_formatter</code>               (<code>TextFormatter | None</code>)           \u2013            <p>Optional custom function for extracting text. Overrides <code>text_field</code> if provided.</p> </li> <li> <code>metadata_fields</code>               (<code>list[str]</code>)           \u2013            <p>The list of metadata fields to extract from the fact payload. Used if no metadata formatter is provided.</p> </li> <li> <code>metadata_formatter</code>               (<code>MetadataFormatter | None</code>)           \u2013            <p>Optional custom function for extracting metadata. Overrides <code>metadata_fields</code> if provided.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>search</code>             \u2013              <p>Asynchronously searches for results based on a query string, a specified limit, and optional filters.</p> </li> </ul> Source code in <code>memstate/integrations/chroma.py</code> <pre><code>def __init__(\n    self,\n    client: AsyncClientAPI,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction[Embeddable] | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n):\n    self.client = client\n    self.collection_name = collection_name\n    self.embedding_fn = embedding_fn\n\n    self._collection: AsyncCollection | None = None\n\n    self.target_types = target_types or set()\n\n    if text_formatter is not None:\n        self._extract_text = text_formatter\n    elif text_field:\n        self._extract_text = lambda data: str(data.get(text_field, \"\"))\n    else:\n        self._extract_text = lambda data: str(data)\n\n    self.metadata_fields = metadata_fields or []\n    self.metadata_formatter = metadata_formatter\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook.search","title":"search  <code>async</code>","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[SearchResult]\n</code></pre> <p>Asynchronously searches for results based on a query string, a specified limit, and optional filters.</p> <p>This function performs a search and returns a list of results matching the input query. The number of results returned can be limited by the <code>limit</code> parameter. Filters can also be applied to refine the search. If no filters are provided, the search is performed without additional constraints.</p> <p>Parameters:</p> <p>Returns:     A list of <code>SearchResult</code> objects corresponding to the         matches found according to the query, limit, and filters.</p> Source code in <code>memstate/integrations/chroma.py</code> <pre><code>async def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[SearchResult]:\n    \"\"\"\n    Asynchronously searches for results based on a query string, a specified limit, and optional filters.\n\n    This function performs a search and returns a list of results\n    matching the input query. The number of results returned can\n    be limited by the `limit` parameter. Filters can also be applied\n    to refine the search. If no filters are provided, the search is\n    performed without additional constraints.\n\n    Args:\n        query (str): A string representing the search query.\n        limit (int): An integer specifying the maximum number of results to return. Defaults to 5.\n        filters (dict | None): Metadata filters using ChromaDB syntax.\n            This is passed directly to the 'where' parameter.\n            Examples:\n                - Exact match: `{\"role\": \"user\"}`\n                - Comparison: `{\"age\": {\"$gt\": 20}}`\n                - Logic: `{\"$and\": [{\"role\": \"user\"}, {\"active\": true}]}`\n        score_threshold (float | None): Filters out results that are \"too far\" from the query.\n            Since Chroma uses Distance metric:\n            - 0.0 means exact match.\n            - Higher values mean less similar.\n            This parameter sets the **Maximum Distance**.\n            (e.g., set to 1.2 to filter out irrelevant noise).\n    Returns:\n        A list of `SearchResult` objects corresponding to the\n            matches found according to the query, limit, and filters.\n    \"\"\"\n    collection = await self._get_collection()\n\n    results = await collection.query(\n        query_texts=[query],\n        n_results=limit,\n        where=filters,\n        include=[\"distances\"],\n    )\n\n    ids = (results.get(\"ids\") or [[]])[0]\n    distances = (results.get(\"distances\") or [[]])[0]\n\n    if not ids:\n        return []\n\n    search_results = []\n    for fid, dist in zip(ids, distances):\n        val = float(dist)\n\n        if score_threshold is not None and val &gt; score_threshold:\n            continue\n\n        search_results.append(SearchResult(fact_id=fid, score=val))\n\n    return search_results\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the search query.</p>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>An integer specifying the maximum number of results to return. Defaults to 5.</p>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook.search(filters)","title":"<code>filters</code>","text":"(<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>Metadata filters using ChromaDB syntax. This is passed directly to the 'where' parameter. Examples:     - Exact match: <code>{\"role\": \"user\"}</code>     - Comparison: <code>{\"age\": {\"$gt\": 20}}</code>     - Logic: <code>{\"$and\": [{\"role\": \"user\"}, {\"active\": true}]}</code></p>"},{"location":"api/integrations/#memstate.integrations.chroma.AsyncChromaSyncHook.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Filters out results that are \"too far\" from the query. Since Chroma uses Distance metric: - 0.0 means exact match. - Higher values mean less similar. This parameter sets the Maximum Distance. (e.g., set to 1.2 to filter out irrelevant noise).</p>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook","title":"ChromaSyncHook","text":"<pre><code>ChromaSyncHook(\n    client: ClientAPI,\n    collection_name: str,\n    embedding_fn: (\n        EmbeddingFunction[Embeddable] | None\n    ) = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n)\n</code></pre> <p>               Bases: <code>MemoryHook</code></p> <p>Handles synchronization of memory data with Chroma collections by integrating fact operations and data transformations.</p> <p>This class is responsible for managing connections to a Chroma collection via a Chroma client, extracting and formatting text and metadata as per the provided configuration, and performing operations like deletion or upserting of facts based on various triggers or operations. It also provides flexibility in defining target data types, metadata extraction, text processing, and overall data synchronization rules.</p> <p>Attributes:</p> <ul> <li> <code>client</code>               (<code>ClientAPI</code>)           \u2013            <p>The Chroma client instance used for collection access and management.</p> </li> <li> <code>collection_name</code>               (<code>str</code>)           \u2013            <p>The name of the Chroma collection to be synchronized.</p> </li> <li> <code>embedding_fn</code>               (<code>EmbeddingFunction | None</code>)           \u2013            <p>Optional function for generating embeddings from text.</p> </li> <li> <code>target_types</code>               (<code>set[str]</code>)           \u2013            <p>A set of fact types allowed for synchronization. If empty, all types are allowed.</p> </li> <li> <code>text_field</code>               (<code>str | None</code>)           \u2013            <p>Field name of text in fact.</p> </li> <li> <code>text_formatter</code>               (<code>TextFormatter | None</code>)           \u2013            <p>Optional custom function for extracting text. Overrides <code>text_field</code> if provided.</p> </li> <li> <code>metadata_fields</code>               (<code>list[str]</code>)           \u2013            <p>The list of metadata fields to extract from the fact payload. Used if no metadata formatter is provided.</p> </li> <li> <code>metadata_formatter</code>               (<code>MetadataFormatter | None</code>)           \u2013            <p>Optional custom function for extracting metadata. Overrides <code>metadata_fields</code> if provided.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>search</code>             \u2013              <p>Searches for results based on a query string, a specified limit, and optional filters.</p> </li> </ul> Source code in <code>memstate/integrations/chroma.py</code> <pre><code>def __init__(\n    self,\n    client: ClientAPI,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction[Embeddable] | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n):\n    self.client = client\n    self.collection = client.get_or_create_collection(\n        name=collection_name,\n        embedding_function=embedding_fn,\n    )\n    self.target_types = target_types or set()\n\n    if text_formatter is not None:\n        self._extract_text = text_formatter\n    elif text_field:\n        self._extract_text = lambda data: str(data.get(text_field, \"\"))\n    else:\n        self._extract_text = lambda data: str(data)\n\n    self.metadata_fields = metadata_fields or []\n    self.metadata_formatter = metadata_formatter\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook.search","title":"search","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[SearchResult]\n</code></pre> <p>Searches for results based on a query string, a specified limit, and optional filters.</p> <p>This function performs a search and returns a list of results matching the input query. The number of results returned can be limited by the <code>limit</code> parameter. Filters can also be applied to refine the search. If no filters are provided, the search is performed without additional constraints.</p> <p>Parameters:</p> <p>Returns:     A list of <code>SearchResult</code> objects corresponding to the         matches found according to the query, limit, and filters.</p> Source code in <code>memstate/integrations/chroma.py</code> <pre><code>def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[SearchResult]:\n    \"\"\"\n    Searches for results based on a query string, a specified limit, and optional filters.\n\n    This function performs a search and returns a list of results\n    matching the input query. The number of results returned can\n    be limited by the `limit` parameter. Filters can also be applied\n    to refine the search. If no filters are provided, the search is\n    performed without additional constraints.\n\n    Args:\n        query (str): A string representing the search query.\n        limit (int): An integer specifying the maximum number of results to return. Defaults to 5.\n        filters (dict | None): Metadata filters using ChromaDB syntax.\n            This is passed directly to the 'where' parameter.\n            Examples:\n                - Exact match: `{\"role\": \"user\"}`\n                - Comparison: `{\"age\": {\"$gt\": 20}}`\n                - Logic: `{\"$and\": [{\"role\": \"user\"}, {\"active\": true}]}`\n        score_threshold (float | None): Filters out results that are \"too far\" from the query.\n            Since Chroma uses Distance metric:\n            - 0.0 means exact match.\n            - Higher values mean less similar.\n            This parameter sets the **Maximum Distance**.\n            (e.g., set to 1.2 to filter out irrelevant noise).\n    Returns:\n        A list of `SearchResult` objects corresponding to the\n            matches found according to the query, limit, and filters.\n    \"\"\"\n    results = self.collection.query(\n        query_texts=[query],\n        n_results=limit,\n        where=filters,\n        include=[\"distances\"],\n    )\n\n    ids = (results.get(\"ids\") or [[]])[0]\n    distances = (results.get(\"distances\") or [[]])[0]\n\n    if not ids:\n        return []\n\n    search_results = []\n    for fid, dist in zip(ids, distances):\n        val = float(dist)\n\n        if score_threshold is not None and val &gt; score_threshold:\n            continue\n\n        search_results.append(SearchResult(fact_id=fid, score=val))\n\n    return search_results\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the search query.</p>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>An integer specifying the maximum number of results to return. Defaults to 5.</p>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook.search(filters)","title":"<code>filters</code>","text":"(<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>Metadata filters using ChromaDB syntax. This is passed directly to the 'where' parameter. Examples:     - Exact match: <code>{\"role\": \"user\"}</code>     - Comparison: <code>{\"age\": {\"$gt\": 20}}</code>     - Logic: <code>{\"$and\": [{\"role\": \"user\"}, {\"active\": true}]}</code></p>"},{"location":"api/integrations/#memstate.integrations.chroma.ChromaSyncHook.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Filters out results that are \"too far\" from the query. Since Chroma uses Distance metric: - 0.0 means exact match. - Higher values mean less similar. This parameter sets the Maximum Distance. (e.g., set to 1.2 to filter out irrelevant noise).</p>"},{"location":"api/integrations/#memstate.integrations.langgraph","title":"langgraph","text":"<p>LangGraph Checkpointer.</p> <p>Classes:</p> <ul> <li> <code>AsyncMemStateCheckpointer</code>           \u2013            <p>Async manages the storage, retrieval, and deletion of checkpoint data in memory.</p> </li> <li> <code>MemStateCheckpointer</code>           \u2013            <p>Manages the storage, retrieval, and deletion of checkpoint data in memory.</p> </li> </ul>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer","title":"AsyncMemStateCheckpointer","text":"<pre><code>AsyncMemStateCheckpointer(\n    memory: AsyncMemoryStore,\n    serde: SerializerProtocol | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseCheckpointSaver[str]</code></p> <p>Async manages the storage, retrieval, and deletion of checkpoint data in memory.</p> <p>The AsyncMemStateCheckpointer class enables storing checkpoints using an in-memory storage system, facilitating workflows that require checkpointing and versioning mechanisms. It interacts with a memory store to persist checkpoint data and associated metadata, supporting use cases that require checkpointer objects functioning as temporary memory storage.</p> <p>Pro Tip: LangGraph checkpoints can be noisy. To prevent them from cluttering your Vector DB, set <code>target_types</code> in your Sync Hook to include only your semantic fact types (e.g., <code>{\"memory\", \"knowledge\"}</code>), effectively ignoring the technical <code>langgraph_checkpoint</code> type.</p> <p>Attributes:</p> <ul> <li> <code>memory</code>               (<code>AsyncMemoryStore</code>)           \u2013            <p>Reference to the memory store used for storage operations.</p> </li> <li> <code>serde</code>               (<code>SerializerProtocol</code>)           \u2013            <p>Serializer for serializing checkpoint data.</p> </li> <li> <code>fact_type</code>               (<code>str</code>)           \u2013            <p>String identifier for checkpoint facts within the memory store.</p> </li> <li> <code>write_type</code>               (<code>str</code>)           \u2013            <p>String identifier for write facts within the memory store.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adelete_thread</code>             \u2013              <p>Asynchronously deletes a specific thread from memory by its identifier.</p> </li> <li> <code>aget_tuple</code>             \u2013              <p>Asynchronously gets a checkpoint tuple based on the provided configuration.</p> </li> <li> <code>alist</code>             \u2013              <p>Asynchronously list and yield checkpoint tuples based on given configuration and filters.</p> </li> <li> <code>aput</code>             \u2013              <p>Asynchronously updates the state of a process by committing checkpoint metadata into memory</p> </li> <li> <code>aput_writes</code>             \u2013              <p>Asynchronously executes the operation to store a sequence of writes by committing them as facts into memory</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def __init__(self, memory: AsyncMemoryStore, serde: SerializerProtocol | None = None) -&gt; None:\n    super().__init__(serde=serde or JsonPlusSerializer())\n    self.memory = memory\n    self.fact_type = \"langgraph_checkpoint\"\n    self.write_type = \"langgraph_write\"\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.adelete_thread","title":"adelete_thread  <code>async</code>","text":"<pre><code>adelete_thread(thread_id: str) -&gt; None\n</code></pre> <p>Asynchronously deletes a specific thread from memory by its identifier.</p> <p>This method removes the session associated with the given thread ID from the memory, ensuring that it is no longer retained or accessed in the system.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This method does not return any value.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>async def adelete_thread(self, thread_id: str) -&gt; None:\n    \"\"\"\n    Asynchronously deletes a specific thread from memory by its identifier.\n\n    This method removes the session associated with the given thread ID\n    from the memory, ensuring that it is no longer retained or accessed\n    in the system.\n\n    Args:\n        thread_id (str): The unique identifier of the thread to be deleted.\n\n    Returns:\n        This method does not return any value.\n    \"\"\"\n    await self.memory.discard_session(thread_id)\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.adelete_thread(thread_id)","title":"<code>thread_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the thread to be deleted.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aget_tuple","title":"aget_tuple  <code>async</code>","text":"<pre><code>aget_tuple(\n    config: RunnableConfig,\n) -&gt; CheckpointTuple | None\n</code></pre> <p>Asynchronously gets a checkpoint tuple based on the provided configuration.</p> <p>This method queries memory to retrieve facts associated with a specific thread ID from the configuration. Depending on whether a thread timestamp is provided, it selects the most recent fact or the one matching the given timestamp. Finally, it reconstructs the checkpoint tuple based on the retrieved fact's payload.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>CheckpointTuple | None</code>           \u2013            <p>A <code>CheckpointTuple</code> containing the retrieved checkpoint data if a fact is found, otherwise <code>None</code>.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>async def aget_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None:\n    \"\"\"\n    Asynchronously gets a checkpoint tuple based on the provided configuration.\n\n    This method queries memory to retrieve facts associated with a specific thread ID\n    from the configuration. Depending on whether a thread timestamp is provided,\n    it selects the most recent fact or the one matching the given timestamp.\n    Finally, it reconstructs the checkpoint tuple based on the retrieved fact's payload.\n\n    Args:\n        config (RunnableConfig): Configuration object containing thread-specific retrieval\n            data, including `thread_id` and optionally `thread_ts`.\n\n    Returns:\n        A `CheckpointTuple` containing the retrieved checkpoint data if a fact is found, otherwise `None`.\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    thread_ts = config[\"configurable\"].get(\"thread_ts\")\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    facts = await self.memory.storage.query(\n        type_filter=self.fact_type, json_filters={\"session_id\": thread_id, \"payload.checkpoint_ns\": checkpoint_ns}\n    )\n\n    if not facts:\n        return None\n\n    facts.sort(key=lambda x: x[\"ts\"], reverse=True)\n\n    fact = None\n    if thread_ts:\n        for f in facts:\n            if f[\"payload\"].get(\"thread_ts\") == thread_ts:\n                fact = f\n                break\n    else:\n        fact = facts[0]\n\n    if not fact:\n        return None\n\n    payload = fact[\"payload\"]\n    checkpoint = payload[\"checkpoint\"]\n    pending_sends = checkpoint.get(\"pending_sends\") or []\n\n    saved_metadata = payload[\"metadata\"]\n    if config.get(\"metadata\"):\n        saved_metadata = {**saved_metadata, **config[\"metadata\"]}\n\n    return CheckpointTuple(\n        config=config,\n        checkpoint=checkpoint,\n        metadata=saved_metadata,\n        parent_config=None,\n        pending_writes=pending_sends,\n    )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aget_tuple(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>Configuration object containing thread-specific retrieval data, including <code>thread_id</code> and optionally <code>thread_ts</code>.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.alist","title":"alist  <code>async</code>","text":"<pre><code>alist(\n    config: RunnableConfig | None,\n    *,\n    filter: dict[str, Any] | None = None,\n    before: RunnableConfig | None = None,\n    limit: int | None = None\n) -&gt; AsyncIterator[CheckpointTuple]\n</code></pre> <p>Asynchronously list and yield checkpoint tuples based on given configuration and filters.</p> <p>This function retrieves fact data stored in memory, optionally applies filters based on configuration or other specified parameters, and yields checkpoint tuples sorted by timestamp. The functionality includes support for limiting the number of facts processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>AsyncIterator[CheckpointTuple]</code>           \u2013            <p>An iterator over checkpoint tuples derived from the filtered facts.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>async def alist(\n    self,\n    config: RunnableConfig | None,\n    *,\n    filter: dict[str, Any] | None = None,\n    before: RunnableConfig | None = None,\n    limit: int | None = None,\n) -&gt; AsyncIterator[CheckpointTuple]:\n    \"\"\"\n    Asynchronously list and yield checkpoint tuples based on given configuration and filters.\n\n    This function retrieves fact data stored in memory, optionally applies\n    filters based on configuration or other specified parameters, and yields\n    checkpoint tuples sorted by timestamp. The functionality includes support\n    for limiting the number of facts processed.\n\n    Args:\n        config (RunnableConfig | None): Configuration information for filtering facts. Optional.\n        filter (dict[str, Any] | None): Additional criteria for filtering facts based on key-value pairs. Optional.\n        before (RunnableConfig | None): Configuration object to apply filter before a certain criterion. Optional.\n        limit (int | None): Maximum number of facts to process and yield. Optional.\n\n    Returns:\n        An iterator over checkpoint tuples derived from the filtered facts.\n    \"\"\"\n\n    json_filters = {}\n    if config and \"configurable\" in config:\n        thread_id = config[\"configurable\"].get(\"thread_id\")\n        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\")\n        if thread_id:\n            json_filters[\"session_id\"] = thread_id\n        if checkpoint_ns:\n            json_filters[\"payload.checkpoint_ns\"] = checkpoint_ns\n\n    if filter:\n        for key, value in filter.items():\n            json_filters[f\"payload.metadata.{key}\"] = value\n\n    # AWAIT QUERY\n    facts = await self.memory.storage.query(\n        type_filter=self.fact_type, json_filters=json_filters if json_filters else None\n    )\n    facts.sort(key=lambda x: x[\"ts\"], reverse=True)\n\n    if limit:\n        facts = facts[:limit]\n\n    # ASYNC YIELD\n    for fact in facts:\n        payload = fact[\"payload\"]\n        yield CheckpointTuple(\n            {\n                \"configurable\": {\n                    \"thread_id\": payload.get(\"thread_id\") or json_filters.get(\"session_id\"),\n                    \"thread_ts\": payload[\"thread_ts\"],\n                    \"checkpoint_ns\": payload.get(\"checkpoint_ns\"),\n                }\n            },\n            payload[\"checkpoint\"],\n            payload[\"metadata\"],\n            (payload.get(\"checkpoint\") or {}).get(\"pending_sends\", []),\n        )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.alist(config)","title":"<code>config</code>","text":"(<code>RunnableConfig | None</code>)           \u2013            <p>Configuration information for filtering facts. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.alist(filter)","title":"<code>filter</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional criteria for filtering facts based on key-value pairs. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.alist(before)","title":"<code>before</code>","text":"(<code>RunnableConfig | None</code>, default:                   <code>None</code> )           \u2013            <p>Configuration object to apply filter before a certain criterion. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.alist(limit)","title":"<code>limit</code>","text":"(<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of facts to process and yield. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput","title":"aput  <code>async</code>","text":"<pre><code>aput(\n    config: RunnableConfig,\n    checkpoint: Checkpoint,\n    metadata: CheckpointMetadata,\n    new_versions: dict[str, Any],\n) -&gt; RunnableConfig\n</code></pre> <p>Asynchronously updates the state of a process by committing checkpoint metadata into memory and returning an updated configuration object.</p> <p>This method handles storing the provided checkpoint and its associated metadata to facilitate process tracking. It interacts with the memory instance to ensure the relevant details are committed within the appropriate session. After updating memory, it returns a modified configuration containing the updated thread parameters.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>RunnableConfig</code>           \u2013            <p>A modified configuration object reflecting the updated thread parameters after committing the provided checkpoint to memory.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>async def aput(\n    self,\n    config: RunnableConfig,\n    checkpoint: Checkpoint,\n    metadata: CheckpointMetadata,\n    new_versions: dict[str, Any],\n) -&gt; RunnableConfig:\n    \"\"\"\n    Asynchronously updates the state of a process by committing checkpoint metadata into memory\n    and returning an updated configuration object.\n\n    This method handles storing the provided checkpoint and its associated metadata\n    to facilitate process tracking. It interacts with the memory instance to ensure\n    the relevant details are committed within the appropriate session. After updating\n    memory, it returns a modified configuration containing the updated thread\n    parameters.\n\n    Args:\n        config (RunnableConfig): The configuration object for the runnable, which must include a `thread_id` under the `configurable` key.\n        checkpoint (Checkpoint): The checkpoint object containing state information to be stored in memory.\n        metadata (CheckpointMetadata): Additional metadata corresponding to the checkpoint, providing\n            supplementary details about the stored state.\n        new_versions (dict[str, Any]): A mapping of version keys to their new corresponding\n            values, used to track changes in versions during the execution process.\n\n    Returns:\n        A modified configuration object reflecting the updated thread\n            parameters after committing the provided checkpoint to memory.\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    payload = {\n        \"checkpoint\": checkpoint,\n        \"metadata\": metadata,\n        \"new_versions\": new_versions,\n        \"thread_ts\": checkpoint[\"id\"],\n        \"checkpoint_ns\": checkpoint_ns,\n    }\n\n    # AWAIT COMMIT\n    await self.memory.commit(\n        Fact(type=self.fact_type, payload=payload, source=\"langgraph_checkpoint\"), session_id=thread_id\n    )\n\n    return {\n        \"configurable\": {\n            \"thread_id\": thread_id,\n            \"thread_ts\": checkpoint[\"id\"],\n            \"checkpoint_ns\": checkpoint_ns,\n        }\n    }\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>The configuration object for the runnable, which must include a <code>thread_id</code> under the <code>configurable</code> key.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput(checkpoint)","title":"<code>checkpoint</code>","text":"(<code>Checkpoint</code>)           \u2013            <p>The checkpoint object containing state information to be stored in memory.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput(metadata)","title":"<code>metadata</code>","text":"(<code>CheckpointMetadata</code>)           \u2013            <p>Additional metadata corresponding to the checkpoint, providing supplementary details about the stored state.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput(new_versions)","title":"<code>new_versions</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A mapping of version keys to their new corresponding values, used to track changes in versions during the execution process.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput_writes","title":"aput_writes  <code>async</code>","text":"<pre><code>aput_writes(\n    config: RunnableConfig,\n    writes: Sequence[tuple[str, Any]],\n    task_id: str,\n    task_path: str = \"\",\n) -&gt; None\n</code></pre> <p>Asynchronously executes the operation to store a sequence of writes by committing them as facts into memory with associated task and thread information. Each write entry in the sequence is processed with a specific channel, value, and index to generate a payload, which is then committed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>async def aput_writes(\n    self,\n    config: RunnableConfig,\n    writes: Sequence[tuple[str, Any]],\n    task_id: str,\n    task_path: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Asynchronously executes the operation to store a sequence of writes by committing them as facts into memory\n    with associated task and thread information. Each write entry in the sequence is processed\n    with a specific channel, value, and index to generate a payload, which is then committed.\n\n    Args:\n        config (RunnableConfig): The configuration object implementing the `RunnableConfig` interface. It must\n            contain a \"configurable\" dictionary with a thread ID linked under the key \"thread_id\".\n        writes (Sequence[tuple[str, Any]]): A sequence of tuples where each tuple contains a string representing the channel\n            and an associated value of type `Any` to be committed.\n        task_id (str): A string representing the unique identifier for the task that groups all the writes.\n        task_path (str): (optional) A string that represents the path or hierarchy associated with\n            the task. Defaults to an empty string if not provided.\n\n    Returns:\n        None\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    for idx, (channel, value) in enumerate(writes):\n        payload = {\n            \"task_id\": task_id,\n            \"task_path\": task_path,\n            \"channel\": channel,\n            \"value\": value,\n            \"idx\": idx,\n            \"thread_id\": thread_id,\n            \"checkpoint_ns\": checkpoint_ns,\n        }\n\n        # AWAIT COMMIT\n        await self.memory.commit(\n            Fact(type=self.write_type, payload=payload, source=\"langgraph_writes\"), session_id=thread_id\n        )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput_writes(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>The configuration object implementing the <code>RunnableConfig</code> interface. It must contain a \"configurable\" dictionary with a thread ID linked under the key \"thread_id\".</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput_writes(writes)","title":"<code>writes</code>","text":"(<code>Sequence[tuple[str, Any]]</code>)           \u2013            <p>A sequence of tuples where each tuple contains a string representing the channel and an associated value of type <code>Any</code> to be committed.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput_writes(task_id)","title":"<code>task_id</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the unique identifier for the task that groups all the writes.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.AsyncMemStateCheckpointer.aput_writes(task_path)","title":"<code>task_path</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>(optional) A string that represents the path or hierarchy associated with the task. Defaults to an empty string if not provided.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer","title":"MemStateCheckpointer","text":"<pre><code>MemStateCheckpointer(\n    memory: MemoryStore,\n    serde: SerializerProtocol | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseCheckpointSaver[str]</code></p> <p>Manages the storage, retrieval, and deletion of checkpoint data in memory.</p> <p>The MemStateCheckpointer class enables storing checkpoints using an in-memory storage system, facilitating workflows that require checkpointing and versioning mechanisms. It interacts with a memory store to persist checkpoint data and associated metadata, supporting use cases that require checkpointer objects functioning as temporary memory storage.</p> <p>Pro Tip: LangGraph checkpoints can be noisy. To prevent them from cluttering your Vector DB, set <code>target_types</code> in your Sync Hook to include only your semantic fact types (e.g., <code>{\"memory\", \"knowledge\"}</code>), effectively ignoring the technical <code>langgraph_checkpoint</code> type.</p> <p>Attributes:</p> <ul> <li> <code>memory</code>               (<code>MemoryStore</code>)           \u2013            <p>Reference to the memory store used for storage operations.</p> </li> <li> <code>serde</code>               (<code>SerializerProtocol</code>)           \u2013            <p>Serializer for serializing checkpoint data.</p> </li> <li> <code>fact_type</code>               (<code>str</code>)           \u2013            <p>String identifier for checkpoint facts within the memory store.</p> </li> <li> <code>write_type</code>               (<code>str</code>)           \u2013            <p>String identifier for write facts within the memory store.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>delete_thread</code>             \u2013              <p>Deletes a specific thread from memory by its identifier.</p> </li> <li> <code>get_tuple</code>             \u2013              <p>Gets a checkpoint tuple based on the provided configuration.</p> </li> <li> <code>list</code>             \u2013              <p>List and yield checkpoint tuples based on given configuration and filters.</p> </li> <li> <code>put</code>             \u2013              <p>Updates the state of a process by committing checkpoint metadata into memory</p> </li> <li> <code>put_writes</code>             \u2013              <p>Executes the operation to store a sequence of writes by committing them as facts into memory</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def __init__(self, memory: MemoryStore, serde: SerializerProtocol | None = None) -&gt; None:\n    super().__init__(serde=serde or JsonPlusSerializer())\n    self.memory = memory\n    self.fact_type = \"langgraph_checkpoint\"\n    self.write_type = \"langgraph_write\"\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.delete_thread","title":"delete_thread","text":"<pre><code>delete_thread(thread_id: str) -&gt; None\n</code></pre> <p>Deletes a specific thread from memory by its identifier.</p> <p>This method removes the session associated with the given thread ID from the memory, ensuring that it is no longer retained or accessed in the system.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This method does not return any value.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def delete_thread(self, thread_id: str) -&gt; None:\n    \"\"\"\n    Deletes a specific thread from memory by its identifier.\n\n    This method removes the session associated with the given thread ID\n    from the memory, ensuring that it is no longer retained or accessed\n    in the system.\n\n    Args:\n        thread_id (str): The unique identifier of the thread to be deleted.\n\n    Returns:\n        This method does not return any value.\n    \"\"\"\n    self.memory.discard_session(thread_id)\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.delete_thread(thread_id)","title":"<code>thread_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the thread to be deleted.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.get_tuple","title":"get_tuple","text":"<pre><code>get_tuple(config: RunnableConfig) -&gt; CheckpointTuple | None\n</code></pre> <p>Gets a checkpoint tuple based on the provided configuration.</p> <p>This method queries memory to retrieve facts associated with a specific thread ID from the configuration. Depending on whether a thread timestamp is provided, it selects the most recent fact or the one matching the given timestamp. Finally, it reconstructs the checkpoint tuple based on the retrieved fact's payload.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>CheckpointTuple | None</code>           \u2013            <p>A <code>CheckpointTuple</code> containing the retrieved checkpoint data if a fact is found, otherwise <code>None</code>.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def get_tuple(self, config: RunnableConfig) -&gt; CheckpointTuple | None:\n    \"\"\"\n    Gets a checkpoint tuple based on the provided configuration.\n\n    This method queries memory to retrieve facts associated with a specific thread ID\n    from the configuration. Depending on whether a thread timestamp is provided,\n    it selects the most recent fact or the one matching the given timestamp.\n    Finally, it reconstructs the checkpoint tuple based on the retrieved fact's payload.\n\n    Args:\n        config (RunnableConfig): Configuration object containing thread-specific retrieval\n            data, including `thread_id` and optionally `thread_ts`.\n\n    Returns:\n        A `CheckpointTuple` containing the retrieved checkpoint data if a fact is found, otherwise `None`.\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    thread_ts = config[\"configurable\"].get(\"thread_ts\")\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    facts = self.memory.query(\n        typename=self.fact_type, filters={\"session_id\": thread_id, \"payload.checkpoint_ns\": checkpoint_ns}\n    )\n\n    if not facts:\n        return None\n\n    if thread_ts:\n        matching = [f for f in facts if f[\"payload\"].get(\"thread_ts\") == thread_ts]\n        fact = matching[0] if matching else None\n    else:\n        facts.sort(key=lambda x: x[\"ts\"], reverse=True)\n        fact = facts[0]\n\n    if not fact:\n        return None\n\n    payload = fact[\"payload\"]\n    checkpoint = payload[\"checkpoint\"]\n    pending_sends = checkpoint.get(\"pending_sends\") or []\n\n    saved_metadata = payload[\"metadata\"]\n    if config.get(\"metadata\"):\n        saved_metadata = {**saved_metadata, **config[\"metadata\"]}\n\n    return CheckpointTuple(\n        config=config,\n        checkpoint=checkpoint,\n        metadata=saved_metadata,\n        parent_config=None,  #  (optional, skip for now)\n        pending_writes=pending_sends,\n    )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.get_tuple(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>Configuration object containing thread-specific retrieval data, including <code>thread_id</code> and optionally <code>thread_ts</code>.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.list","title":"list","text":"<pre><code>list(\n    config: RunnableConfig | None,\n    *,\n    filter: dict[str, Any] | None = None,\n    before: RunnableConfig | None = None,\n    limit: int | None = None\n) -&gt; Iterator[CheckpointTuple]\n</code></pre> <p>List and yield checkpoint tuples based on given configuration and filters.</p> <p>This function retrieves fact data stored in memory, optionally applies filters based on configuration or other specified parameters, and yields checkpoint tuples sorted by timestamp. The functionality includes support for limiting the number of facts processed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Iterator[CheckpointTuple]</code>           \u2013            <p>An iterator over checkpoint tuples derived from the filtered facts.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def list(\n    self,\n    config: RunnableConfig | None,\n    *,\n    filter: dict[str, Any] | None = None,\n    before: RunnableConfig | None = None,\n    limit: int | None = None,\n) -&gt; Iterator[CheckpointTuple]:\n    \"\"\"\n    List and yield checkpoint tuples based on given configuration and filters.\n\n    This function retrieves fact data stored in memory, optionally applies\n    filters based on configuration or other specified parameters, and yields\n    checkpoint tuples sorted by timestamp. The functionality includes support\n    for limiting the number of facts processed.\n\n    Args:\n        config (RunnableConfig | None): Configuration information for filtering facts. Optional.\n        filter (dict[str, Any] | None): Additional criteria for filtering facts based on key-value pairs. Optional.\n        before (RunnableConfig | None): Configuration object to apply filter before a certain criterion. Optional.\n        limit (int | None): Maximum number of facts to process and yield. Optional.\n\n    Returns:\n        An iterator over checkpoint tuples derived from the filtered facts.\n    \"\"\"\n\n    json_filters = {}\n\n    if config and \"configurable\" in config:\n        thread_id = config[\"configurable\"].get(\"thread_id\")\n        checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\")\n        if thread_id:\n            json_filters[\"session_id\"] = thread_id\n        if checkpoint_ns:\n            json_filters[\"payload.checkpoint_ns\"] = checkpoint_ns\n\n    if filter:\n        for key, value in filter.items():\n            json_filters[f\"payload.metadata.{key}\"] = value\n\n    facts = self.memory.query(typename=self.fact_type, filters=json_filters if json_filters else None)\n\n    facts.sort(key=lambda x: x[\"ts\"], reverse=True)\n\n    if limit:\n        facts = facts[:limit]\n\n    for fact in facts:\n        payload = fact[\"payload\"]\n        yield CheckpointTuple(\n            {\n                \"configurable\": {\n                    \"thread_id\": payload.get(\"thread_id\") or json_filters.get(\"session_id\"),\n                    \"thread_ts\": payload[\"thread_ts\"],\n                    \"checkpoint_ns\": payload.get(\"checkpoint_ns\"),\n                }\n            },\n            payload[\"checkpoint\"],\n            payload[\"metadata\"],\n            (payload.get(\"checkpoint\") or {}).get(\"pending_sends\", []),\n        )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.list(config)","title":"<code>config</code>","text":"(<code>RunnableConfig | None</code>)           \u2013            <p>Configuration information for filtering facts. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.list(filter)","title":"<code>filter</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>Additional criteria for filtering facts based on key-value pairs. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.list(before)","title":"<code>before</code>","text":"(<code>RunnableConfig | None</code>, default:                   <code>None</code> )           \u2013            <p>Configuration object to apply filter before a certain criterion. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.list(limit)","title":"<code>limit</code>","text":"(<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Maximum number of facts to process and yield. Optional.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put","title":"put","text":"<pre><code>put(\n    config: RunnableConfig,\n    checkpoint: Checkpoint,\n    metadata: CheckpointMetadata,\n    new_versions: dict[str, Any],\n) -&gt; RunnableConfig\n</code></pre> <p>Updates the state of a process by committing checkpoint metadata into memory and returning an updated configuration object.</p> <p>This method handles storing the provided checkpoint and its associated metadata to facilitate process tracking. It interacts with the memory instance to ensure the relevant details are committed within the appropriate session. After updating memory, it returns a modified configuration containing the updated thread parameters.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>RunnableConfig</code>           \u2013            <p>A modified configuration object reflecting the updated thread parameters after committing the provided checkpoint to memory.</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def put(\n    self,\n    config: RunnableConfig,\n    checkpoint: Checkpoint,\n    metadata: CheckpointMetadata,\n    new_versions: dict[str, Any],\n) -&gt; RunnableConfig:\n    \"\"\"\n    Updates the state of a process by committing checkpoint metadata into memory\n    and returning an updated configuration object.\n\n    This method handles storing the provided checkpoint and its associated metadata\n    to facilitate process tracking. It interacts with the memory instance to ensure\n    the relevant details are committed within the appropriate session. After updating\n    memory, it returns a modified configuration containing the updated thread\n    parameters.\n\n    Args:\n        config (RunnableConfig): The configuration object for the runnable, which must include a `thread_id` under the `configurable` key.\n        checkpoint (Checkpoint): The checkpoint object containing state information to be stored in memory.\n        metadata (CheckpointMetadata): Additional metadata corresponding to the checkpoint, providing\n            supplementary details about the stored state.\n        new_versions (dict[str, Any]): A mapping of version keys to their new corresponding\n            values, used to track changes in versions during the execution process.\n\n    Returns:\n        A modified configuration object reflecting the updated thread\n            parameters after committing the provided checkpoint to memory.\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    payload = {\n        \"checkpoint\": checkpoint,\n        \"metadata\": metadata,\n        \"new_versions\": new_versions,\n        \"thread_ts\": checkpoint[\"id\"],\n        \"checkpoint_ns\": checkpoint_ns,\n    }\n\n    self.memory.commit(\n        Fact(type=self.fact_type, payload=payload, source=\"langgraph_checkpoint\"), session_id=thread_id\n    )\n\n    return {\n        \"configurable\": {\n            \"thread_id\": thread_id,\n            \"thread_ts\": checkpoint[\"id\"],\n            \"checkpoint_ns\": checkpoint_ns,\n        }\n    }\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>The configuration object for the runnable, which must include a <code>thread_id</code> under the <code>configurable</code> key.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put(checkpoint)","title":"<code>checkpoint</code>","text":"(<code>Checkpoint</code>)           \u2013            <p>The checkpoint object containing state information to be stored in memory.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put(metadata)","title":"<code>metadata</code>","text":"(<code>CheckpointMetadata</code>)           \u2013            <p>Additional metadata corresponding to the checkpoint, providing supplementary details about the stored state.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put(new_versions)","title":"<code>new_versions</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A mapping of version keys to their new corresponding values, used to track changes in versions during the execution process.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put_writes","title":"put_writes","text":"<pre><code>put_writes(\n    config: RunnableConfig,\n    writes: Sequence[tuple[str, Any]],\n    task_id: str,\n    task_path: str = \"\",\n) -&gt; None\n</code></pre> <p>Executes the operation to store a sequence of writes by committing them as facts into memory with associated task and thread information. Each write entry in the sequence is processed with a specific channel, value, and index to generate a payload, which is then committed.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/integrations/langgraph.py</code> <pre><code>def put_writes(\n    self,\n    config: RunnableConfig,\n    writes: Sequence[tuple[str, Any]],\n    task_id: str,\n    task_path: str = \"\",\n) -&gt; None:\n    \"\"\"\n    Executes the operation to store a sequence of writes by committing them as facts into memory\n    with associated task and thread information. Each write entry in the sequence is processed\n    with a specific channel, value, and index to generate a payload, which is then committed.\n\n    Args:\n        config (RunnableConfig): The configuration object implementing the `RunnableConfig` interface. It must\n            contain a \"configurable\" dictionary with a thread ID linked under the key \"thread_id\".\n        writes (Sequence[tuple[str, Any]]): A sequence of tuples where each tuple contains a string representing the channel\n            and an associated value of type `Any` to be committed.\n        task_id (str): A string representing the unique identifier for the task that groups all the writes.\n        task_path (str): (optional) A string that represents the path or hierarchy associated with\n            the task. Defaults to an empty string if not provided.\n\n    Returns:\n        None\n    \"\"\"\n    thread_id = config[\"configurable\"][\"thread_id\"]\n    checkpoint_ns = config[\"configurable\"].get(\"checkpoint_ns\", \"\")\n\n    for idx, (channel, value) in enumerate(writes):\n        payload = {\n            \"task_id\": task_id,\n            \"task_path\": task_path,\n            \"channel\": channel,\n            \"value\": value,\n            \"idx\": idx,\n            \"thread_id\": thread_id,\n            \"checkpoint_ns\": checkpoint_ns,\n        }\n\n        self.memory.commit(\n            Fact(type=self.write_type, payload=payload, source=\"langgraph_writes\"), session_id=thread_id\n        )\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put_writes(config)","title":"<code>config</code>","text":"(<code>RunnableConfig</code>)           \u2013            <p>The configuration object implementing the <code>RunnableConfig</code> interface. It must contain a \"configurable\" dictionary with a thread ID linked under the key \"thread_id\".</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put_writes(writes)","title":"<code>writes</code>","text":"(<code>Sequence[tuple[str, Any]]</code>)           \u2013            <p>A sequence of tuples where each tuple contains a string representing the channel and an associated value of type <code>Any</code> to be committed.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put_writes(task_id)","title":"<code>task_id</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the unique identifier for the task that groups all the writes.</p>"},{"location":"api/integrations/#memstate.integrations.langgraph.MemStateCheckpointer.put_writes(task_path)","title":"<code>task_path</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>(optional) A string that represents the path or hierarchy associated with the task. Defaults to an empty string if not provided.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant","title":"qdrant","text":"<p>Qdrant integration.</p> <p>Classes:</p> <ul> <li> <code>AsyncQdrantSyncHook</code>           \u2013            <p>Handles synchronization of memory updates with a Qdrant collection by managing</p> </li> <li> <code>FastEmbedEncoder</code>           \u2013            <p>Default embedding implementation using FastEmbed.</p> </li> <li> <code>QdrantSyncHook</code>           \u2013            <p>Handles synchronization of memory updates with a Qdrant collection by managing</p> </li> </ul>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook","title":"AsyncQdrantSyncHook","text":"<pre><code>AsyncQdrantSyncHook(\n    client: AsyncQdrantClient,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n    distance: Distance = COSINE,\n)\n</code></pre> <p>               Bases: <code>AsyncMemoryHook</code></p> <p>Handles synchronization of memory updates with a Qdrant collection by managing CRUD operations on vector embeddings and metadata. Designed for real-time updates and integration with Qdrant database collections.</p> <p>The class provides support for maintaining vector embeddings, setting up collection parameters, formatting metadata, and handling various operations such as inserts, updates, deletions, and session discards. Additionally, it supports embedding functions and configurable distance metrics for vector similarity functionality.</p> <p>Attributes:</p> <ul> <li> <code>client</code>               (<code>AsyncQdrantClient</code>)           \u2013            <p>Client instance for interacting with the Qdrant database.</p> </li> <li> <code>collection_name</code>               (<code>str</code>)           \u2013            <p>Name of the Qdrant collection to synchronize with.</p> </li> <li> <code>embedding_fn</code>               (<code>EmbeddingFunction | None</code>)           \u2013            <p>Function responsible for generating vector embeddings, defaulting to FastEmbedEncoder if not provided.</p> </li> <li> <code>target_types</code>               (<code>set[str] | None</code>)           \u2013            <p>Set of target types that define which operations are supported for synchronization. Defaults to an empty set.</p> </li> <li> <code>distance</code>               (<code>Distance</code>)           \u2013            <p>Metric to compute vector similarity in Qdrant, e.g., COSINE, EUCLIDEAN.</p> </li> <li> <code>metadata_fields</code>               (<code>list[str] | None</code>)           \u2013            <p>List of fields to include in the metadata payload.</p> </li> <li> <code>metadata_formatter</code>               (<code>MetadataFormatter | None</code>)           \u2013            <p>Formatter function for structuring metadata. Optional.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>search</code>             \u2013              <p>Asynchronously searches for results based on a query string, a specified limit, and optional filters.</p> </li> </ul> Source code in <code>memstate/integrations/qdrant.py</code> <pre><code>def __init__(\n    self,\n    client: AsyncQdrantClient,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n    distance: models.Distance = models.Distance.COSINE,\n) -&gt; None:\n    self.client = client\n    self.collection_name = collection_name\n    self.embedding_fn = embedding_fn or FastEmbedEncoder()\n    self.target_types = target_types or set()\n    self.distance = distance\n\n    self._collection_checked = False\n\n    if text_formatter is not None:\n        self._extract_text = text_formatter\n    elif text_field:\n        self._extract_text = lambda data: str(data.get(text_field, \"\"))\n    else:\n        self._extract_text = lambda data: str(data)\n\n    self.metadata_fields = metadata_fields or []\n    self.metadata_formatter = metadata_formatter\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook.search","title":"search  <code>async</code>","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[SearchResult]\n</code></pre> <p>Asynchronously searches for results based on a query string, a specified limit, and optional filters.</p> <p>This function performs a search and returns a list of results matching the input query. The number of results returned can be limited by the <code>limit</code> parameter. Filters can also be applied to refine the search. If no filters are provided, the search is performed without additional constraints.</p> <p>Parameters:</p> <p>Returns:     A list of <code>SearchResult</code> objects corresponding to the         matches found according to the query, limit, and filters.</p> Source code in <code>memstate/integrations/qdrant.py</code> <pre><code>async def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[SearchResult]:\n    \"\"\"\n    Asynchronously searches for results based on a query string, a specified limit, and optional filters.\n\n    This function performs a search and returns a list of results\n    matching the input query. The number of results returned can\n    be limited by the `limit` parameter. Filters can also be applied\n    to refine the search. If no filters are provided, the search is\n    performed without additional constraints.\n\n    Args:\n        query (str): A string representing the search query.\n        limit (int): An integer specifying the maximum number of results to return. Defaults to 5.\n        filters (dict | None): Qdrant-compatible filter.\n            You can pass a `qdrant_client.models.Filter` object or a raw dict.\n        score_threshold (float | None): Minimum similarity score.\n            **Note:** Qdrant usually uses Cosine Similarity (higher is better).\n            This acts as a **Minimum Score** filter.\n            Results with score &lt; score_threshold will be excluded.\n    Returns:\n        A list of `SearchResult` objects corresponding to the\n            matches found according to the query, limit, and filters.\n    \"\"\"\n    await self._ensure_collection()\n\n    qdrant_filter = self._build_filter(filters)\n    vector = self.embedding_fn(query)\n\n    resp = await self.client.query_points(\n        collection_name=self.collection_name,\n        query=vector,\n        query_filter=qdrant_filter,\n        limit=limit,\n        score_threshold=score_threshold,\n    )\n    return [SearchResult(fact_id=str(p.id), score=p.score) for p in resp.points]\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the search query.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>An integer specifying the maximum number of results to return. Defaults to 5.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook.search(filters)","title":"<code>filters</code>","text":"(<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>Qdrant-compatible filter. You can pass a <code>qdrant_client.models.Filter</code> object or a raw dict.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.AsyncQdrantSyncHook.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Minimum similarity score. Note: Qdrant usually uses Cosine Similarity (higher is better). This acts as a Minimum Score filter. Results with score &lt; score_threshold will be excluded.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.FastEmbedEncoder","title":"FastEmbedEncoder","text":"<pre><code>FastEmbedEncoder(\n    model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n    options: dict[str, Any] | None = None,\n)\n</code></pre> <p>Default embedding implementation using FastEmbed. Used if no custom embedding_fn is provided.</p> <p>This class provides a lightweight wrapper around the FastEmbed library to generate embeddings for text inputs. The encoder initializes with a specific pre-trained model from FastEmbed and can be invoked to generate a numerical vector representation of the provided text.</p> <p>Attributes:</p> <ul> <li> <code>model</code>               (<code>TextEmbedding</code>)           \u2013            <p>Instance of the FastEmbed TextEmbedding model used to generate embeddings.</p> </li> </ul> <p>If the FastEmbed library is not installed on the system, an ImportError is raised, advising the user to install the library or provide a custom embedding function.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ImportError</code>             \u2013            <p>If the FastEmbed library is not installed on the system, this exception is raised, advising the use of <code>pip install fastembed</code> or providing a custom embedding function.</p> </li> </ul> Source code in <code>memstate/integrations/qdrant.py</code> <pre><code>def __init__(\n    self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\", options: dict[str, Any] | None = None\n):\n    \"\"\"\n    Initializes the embedding model using the specified `model_name` and optional `options`\n    dictionary. The class leverages the FastEmbed library for handling text embeddings.\n\n    If the FastEmbed library is not installed on the system, an ImportError is raised,\n    advising the user to install the library or provide a custom embedding function.\n\n    Args:\n        model_name (str): The name of the model to be used for text embeddings.\n            Defaults to \"sentence-transformers/all-MiniLM-L6-v2\".\n        options (dict[str, Any] | None): A dictionary of options for configuring the embedding model.\n            If not provided, an empty dictionary is used.\n\n    Raises:\n        ImportError: If the FastEmbed library is not installed on the system, this exception\n            is raised, advising the use of `pip install fastembed` or providing a custom embedding function.\n    \"\"\"\n    try:\n        from fastembed import TextEmbedding\n    except ImportError:\n        raise ImportError(\n            \"FastEmbed is not installed. \" \"Install it via `pip install fastembed` or pass a custom `embedding_fn`.\"\n        )\n    self.model = TextEmbedding(model_name, **(options or {}))\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.qdrant.FastEmbedEncoder(model_name)","title":"<code>model_name</code>","text":"(<code>str</code>, default:                   <code>'sentence-transformers/all-MiniLM-L6-v2'</code> )           \u2013            <p>The name of the model to be used for text embeddings. Defaults to \"sentence-transformers/all-MiniLM-L6-v2\".</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.FastEmbedEncoder(options)","title":"<code>options</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary of options for configuring the embedding model. If not provided, an empty dictionary is used.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook","title":"QdrantSyncHook","text":"<pre><code>QdrantSyncHook(\n    client: QdrantClient,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n    distance: Distance = COSINE,\n)\n</code></pre> <p>               Bases: <code>MemoryHook</code></p> <p>Handles synchronization of memory updates with a Qdrant collection by managing CRUD operations on vector embeddings and metadata. Designed for real-time updates and integration with Qdrant database collections.</p> <p>The class provides support for maintaining vector embeddings, setting up collection parameters, formatting metadata, and handling various operations such as inserts, updates, deletions, and session discards. Additionally, it supports embedding functions and configurable distance metrics for vector similarity functionality.</p> Example <pre><code>encoder = FastEmbedEncoder(model_name=\"BAAI/bge-small-en-v1.5\", options={\"cuda\": True})\nhook = QdrantSyncHook(client, \"memory\", embedding_fn=encoder)\nresp = openai.embeddings.create(input=text, model=\"text-embedding-3-small\")\nopenai_embedder = resp.data[0].embedding\nhook = QdrantSyncHook(client, \"memory\", embedding_fn=openai_embedder)\n</code></pre> <p>Attributes:</p> <ul> <li> <code>client</code>               (<code>QdrantClient</code>)           \u2013            <p>Client instance for interacting with the Qdrant database.</p> </li> <li> <code>collection_name</code>               (<code>str</code>)           \u2013            <p>Name of the Qdrant collection to synchronize with.</p> </li> <li> <code>embedding_fn</code>               (<code>EmbeddingFunction | None</code>)           \u2013            <p>Function responsible for generating vector embeddings, defaulting to FastEmbedEncoder if not provided.</p> </li> <li> <code>target_types</code>               (<code>set[str] | None</code>)           \u2013            <p>Set of target types that define which operations are supported for synchronization. Defaults to an empty set.</p> </li> <li> <code>distance</code>               (<code>Distance</code>)           \u2013            <p>Metric to compute vector similarity in Qdrant, e.g., COSINE, EUCLIDEAN.</p> </li> <li> <code>metadata_fields</code>               (<code>list[str] | None</code>)           \u2013            <p>List of fields to include in the metadata payload.</p> </li> <li> <code>metadata_formatter</code>               (<code>MetadataFormatter | None</code>)           \u2013            <p>Formatter function for structuring metadata. Optional.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>search</code>             \u2013              <p>Searches for results based on a query string, a specified limit, and optional filters.</p> </li> </ul> Source code in <code>memstate/integrations/qdrant.py</code> <pre><code>def __init__(\n    self,\n    client: QdrantClient,\n    collection_name: str,\n    embedding_fn: EmbeddingFunction | None = None,\n    target_types: set[str] | None = None,\n    text_field: str | None = None,\n    text_formatter: TextFormatter | None = None,\n    metadata_fields: list[str] | None = None,\n    metadata_formatter: MetadataFormatter | None = None,\n    distance: models.Distance = models.Distance.COSINE,\n) -&gt; None:\n    self.client = client\n    self.collection_name = collection_name\n\n    self.embedding_fn = embedding_fn or FastEmbedEncoder()\n\n    self.target_types = target_types or set()\n    self.distance = distance\n\n    if text_formatter is not None:\n        self._extract_text = text_formatter\n    elif text_field:\n        self._extract_text = lambda data: str(data.get(text_field, \"\"))\n    else:\n        self._extract_text = lambda data: str(data)\n\n    self.metadata_fields = metadata_fields or []\n    self.metadata_formatter = metadata_formatter\n\n    self._ensure_collection()\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook.search","title":"search","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[SearchResult]\n</code></pre> <p>Searches for results based on a query string, a specified limit, and optional filters.</p> <p>This function performs a search and returns a list of results matching the input query. The number of results returned can be limited by the <code>limit</code> parameter. Filters can also be applied to refine the search. If no filters are provided, the search is performed without additional constraints.</p> <p>Parameters:</p> <p>Returns:     A list of <code>SearchResult</code> objects corresponding to the         matches found according to the query, limit, and filters.</p> Source code in <code>memstate/integrations/qdrant.py</code> <pre><code>def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[SearchResult]:\n    \"\"\"\n    Searches for results based on a query string, a specified limit, and optional filters.\n\n    This function performs a search and returns a list of results\n    matching the input query. The number of results returned can\n    be limited by the `limit` parameter. Filters can also be applied\n    to refine the search. If no filters are provided, the search is\n    performed without additional constraints.\n\n    Args:\n        query (str): A string representing the search query.\n        limit (int): An integer specifying the maximum number of results to return. Defaults to 5.\n        filters (dict | None): Qdrant-compatible filter.\n            You can pass a `qdrant_client.models.Filter` object or a raw dict.\n        score_threshold (float | None): Minimum similarity score.\n            **Note:** Qdrant usually uses Cosine Similarity (higher is better).\n            This acts as a **Minimum Score** filter.\n            Results with score &lt; score_threshold will be excluded.\n    Returns:\n        A list of `SearchResult` objects corresponding to the\n            matches found according to the query, limit, and filters.\n    \"\"\"\n    qdrant_filter = self._build_filter(filters)\n    vector = self.embedding_fn(query)\n\n    resp = self.client.query_points(\n        collection_name=self.collection_name,\n        query=vector,\n        query_filter=qdrant_filter,\n        limit=limit,\n        score_threshold=score_threshold,\n    )\n    return [SearchResult(fact_id=str(p.id), score=p.score) for p in resp.points]\n</code></pre>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the search query.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>An integer specifying the maximum number of results to return. Defaults to 5.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook.search(filters)","title":"<code>filters</code>","text":"(<code>dict | None</code>, default:                   <code>None</code> )           \u2013            <p>Qdrant-compatible filter. You can pass a <code>qdrant_client.models.Filter</code> object or a raw dict.</p>"},{"location":"api/integrations/#memstate.integrations.qdrant.QdrantSyncHook.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>Minimum similarity score. Note: Qdrant usually uses Cosine Similarity (higher is better). This acts as a Minimum Score filter. Results with score &lt; score_threshold will be excluded.</p>"},{"location":"api/memstate/","title":"MemState","text":""},{"location":"api/memstate/#memstate.storage","title":"storage","text":"<p>Classes:</p> <ul> <li> <code>AsyncMemoryStore</code>           \u2013            <p>Handles in-memory storage of structured data with schema enforcement, transactional</p> </li> <li> <code>Constraint</code>           \u2013            <p>Represents a constraint with properties for configuration.</p> </li> <li> <code>MemoryStore</code>           \u2013            <p>Handles in-memory storage of structured data with schema enforcement, transactional</p> </li> <li> <code>SchemaRegistry</code>           \u2013            <p>Manages schema registration and validation with a mapping of type names to Pydantic models.</p> </li> </ul>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore","title":"AsyncMemoryStore","text":"<pre><code>AsyncMemoryStore(\n    storage: AsyncStorageBackend,\n    hooks: list[AsyncMemoryHook] | None = None,\n)\n</code></pre> <p>Handles in-memory storage of structured data with schema enforcement, transactional capabilities, and hooks for custom operations.</p> <p>This class provides a structured method to store and retrieve facts with enforced schema validation and constraints. It also supports mechanisms for transactional logging, model validation, and hook execution during operations.</p> <p>Attributes:</p> <ul> <li> <code>storage</code>               (<code>AsyncStorageBackend</code>)           \u2013            <p>Backend storage mechanism for persisting facts and transaction information.</p> </li> <li> <code>hooks</code>               (<code>list[AsyncMemoryHook]</code>)           \u2013            <p>List of hooks to be executed during memory operations.</p> </li> </ul> Used by: <ul> <li> API Reference <code></code>\u00a0integrations <code></code>\u00a0langgraph <code></code>\u00a0AsyncMemStateCheckpointer </li> </ul> <p>Methods:</p> <ul> <li> <code>add_hook</code>             \u2013              <p>Adds a new memory hook to the list of hooks.</p> </li> <li> <code>commit</code>             \u2013              <p>Asynchronously commits a <code>Fact</code> object to the storage, optionally allowing for ephemeral</p> </li> <li> <code>commit_model</code>             \u2013              <p>Asynchronously commits a model to the store using the provided schema registry and additional metadata.</p> </li> <li> <code>delete</code>             \u2013              <p>Asynchronously deletes an existing fact from storage identified by the given fact ID. This operation logs the</p> </li> <li> <code>discard_session</code>             \u2013              <p>Asynchronously discard a session and clear related stored data in the storage.</p> </li> <li> <code>get</code>             \u2013              <p>Asynchronously retrieves a fact from the storage based on the provided fact ID.</p> </li> <li> <code>promote_session</code>             \u2013              <p>Asynchronously promotes session-related facts by modifying the session ID to dissociate</p> </li> <li> <code>query</code>             \u2013              <p>Asynchronously executes a query against the storage with optional type and filter constraints.</p> </li> <li> <code>register_schema</code>             \u2013              <p>Registers a schema in the schema registry and optionally applies a constraint.</p> </li> <li> <code>rollback</code>             \u2013              <p>Asynchronously reverts the state of the storage by rolling back a specified number of transactional</p> </li> <li> <code>search</code>             \u2013              <p>Asynchronously performs a hybrid search operation combining semantic search through Vector DB</p> </li> <li> <code>update</code>             \u2013              <p>Asynchronously updates an existing fact in the store by applying a patch to its contents. The update process</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def __init__(self, storage: AsyncStorageBackend, hooks: list[AsyncMemoryHook] | None = None) -&gt; None:\n    self.storage = storage\n    self._constraints: dict[str, Constraint] = {}\n    self._schema_registry = SchemaRegistry()\n    self._lock = asyncio.Lock()\n    self._seq = 0\n    self._hooks: list[AsyncMemoryHook] = hooks or []\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.add_hook","title":"add_hook","text":"<pre><code>add_hook(hook: AsyncMemoryHook) -&gt; None\n</code></pre> <p>Adds a new memory hook to the list of hooks.</p> <p>This method registers a <code>AsyncMemoryHook</code> instance into the internal hooks list for further processing. A <code>AsyncMemoryHook</code> is an abstraction that can be used to monitor and react to specific memory-related events.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def add_hook(self, hook: AsyncMemoryHook) -&gt; None:\n    \"\"\"\n    Adds a new memory hook to the list of hooks.\n\n    This method registers a `AsyncMemoryHook` instance into the internal hooks\n    list for further processing. A `AsyncMemoryHook` is an abstraction that can\n    be used to monitor and react to specific memory-related events.\n\n    Args:\n        hook (AsyncMemoryHook): The hook instance to be added to the hooks list.\n\n    Returns:\n        None\n    \"\"\"\n    self._hooks.append(hook)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.add_hook(hook)","title":"<code>hook</code>","text":"(<code>AsyncMemoryHook</code>)           \u2013            <p>The hook instance to be added to the hooks list.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit","title":"commit  <code>async</code>","text":"<pre><code>commit(\n    fact: Fact,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Asynchronously commits a <code>Fact</code> object to the storage, optionally allowing for ephemeral storage, and updates existing records if applicable. The operation evaluates constraints such as immutability or uniqueness, handles potential duplicates, and invokes hooks for logging and notifications. Supports rollback of changes in case of errors.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The unique identifier of the committed fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>HookError</code>             \u2013            <p>If an error occurs during hook execution.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def commit(\n    self,\n    fact: Fact,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Asynchronously commits a `Fact` object to the storage, optionally allowing for ephemeral\n    storage, and updates existing records if applicable. The operation evaluates\n    constraints such as immutability or uniqueness, handles potential duplicates,\n    and invokes hooks for logging and notifications. Supports rollback of changes\n    in case of errors.\n\n    Args:\n        fact (Fact): The `Fact` object to be committed. Validates the payload against\n            schema registry and potentially updates or creates a new entry in the\n            storage.\n        session_id (str | None): Optional session identifier associated with the `Fact`.\n        ephemeral (bool): Indicates whether the `Fact` is transient and should not be persisted. Defaults to `False`.\n        actor (str | None): Optional identifier for the individual or system responsible\n            for initiating the commit. Used for logging and auditing purposes.\n        reason (str | None): Optional string describing the purpose of the commit. Used\n            primarily for auditing and logging.\n\n    Returns:\n        The unique identifier of the committed fact.\n\n    Raises:\n        HookError: If an error occurs during hook execution.\n    \"\"\"\n    async with self._lock:\n        validated_payload = self._schema_registry.validate(fact.type, fact.payload)\n        fact.payload = validated_payload\n\n        if session_id:\n            fact.session_id = session_id\n\n        previous_state = None\n        op = Operation.COMMIT\n\n        constraint = self._constraints.get(fact.type)\n\n        if constraint and constraint.singleton_key:\n            key_val = validated_payload.get(constraint.singleton_key)\n            if key_val is not None:\n                search_key = f\"payload.{constraint.singleton_key}\"\n                matches = await self.storage.query(type_filter=fact.type, json_filters={search_key: key_val})\n\n                if matches:\n                    existing_raw = matches[0]\n                    if constraint.immutable:\n                        raise ConflictError(f\"Immutable constraint violation: {fact.type}:{key_val}\")\n\n                    # We found a duplicate, so this is an UPDATE of an existing one\n                    previous_state = copy.deepcopy(existing_raw)\n                    fact.id = existing_raw[\"id\"]  # We replace the ID of the new fact with the old one\n                    op = Operation.UPDATE\n\n        if op != Operation.UPDATE:\n            existing = await self.storage.load(fact.id)\n            if existing:\n                previous_state = copy.deepcopy(existing)\n                op = Operation.UPDATE\n            else:\n                op = Operation.COMMIT_EPHEMERAL if ephemeral else Operation.COMMIT\n\n        try:\n            new_state = fact.model_dump(mode=\"json\")\n            await self.storage.save(new_state)\n            await self._log_tx(op, fact.session_id, fact.id, previous_state, new_state, actor, reason)\n            await self._notify_hooks(op, fact.id, fact)\n\n            return fact.id\n\n        except HookError as e:\n            if op == Operation.UPDATE and previous_state:\n                await self.storage.save(previous_state)\n            else:\n                await self.storage.delete(fact.id)\n\n            raise e\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit(fact)","title":"<code>fact</code>","text":"(<code>Fact</code>)           \u2013            <p>The <code>Fact</code> object to be committed. Validates the payload against schema registry and potentially updates or creates a new entry in the storage.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional session identifier associated with the <code>Fact</code>.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit(ephemeral)","title":"<code>ephemeral</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Indicates whether the <code>Fact</code> is transient and should not be persisted. Defaults to <code>False</code>.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the individual or system responsible for initiating the commit. Used for logging and auditing purposes.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional string describing the purpose of the commit. Used primarily for auditing and logging.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model","title":"commit_model  <code>async</code>","text":"<pre><code>commit_model(\n    model: BaseModel,\n    fact_id: str | None = None,\n    source: str | None = None,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Asynchronously commits a model to the store using the provided schema registry and additional metadata.</p> <p>This method registers a given <code>model</code> object with a schema type derived from its class. Metadata such as <code>fact_id</code>, <code>source</code>, <code>session_id</code>, <code>ephemeral</code>, <code>actor</code>, and <code>reason</code> can be supplied to categorize or provide context for the operation. If the model's schema type is not registered, an error is raised.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The result of the commit operation as a string.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the model's schema type is not registered.</p> </li> <li> <code>HookError</code>             \u2013            <p>If an error occurs during hook execution.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def commit_model(\n    self,\n    model: BaseModel,\n    fact_id: str | None = None,\n    source: str | None = None,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Asynchronously commits a model to the store using the provided schema registry and additional metadata.\n\n    This method registers a given `model` object with a schema type derived from its class. Metadata such\n    as `fact_id`, `source`, `session_id`, `ephemeral`, `actor`, and `reason` can be supplied to categorize\n    or provide context for the operation. If the model's schema type is not registered, an error is raised.\n\n    Args:\n        model (BaseModel): The model instance to commit.\n        fact_id (str | None): Optional unique identifier for the fact. If not provided, a new UUID is generated.\n        source (str | None): Optional source of the operation. Defaults to None.\n        session_id (str | None): Optional identifier for the session in which the commit is performed. Defaults to None.\n        ephemeral (bool): Optional. Determines if the data should be treated as ephemeral. Defaults to False.\n        actor (str | None): Optional identifier for the entity performing the commit. Defaults to None.\n        reason (str | None): Optional description or justification for the commit operation. Defaults to None.\n\n    Returns:\n        The result of the commit operation as a string.\n\n    Raises:\n        MemoryStoreError: If the model's schema type is not registered.\n        HookError: If an error occurs during hook execution.\n    \"\"\"\n    schema_type = self._schema_registry.get_type_by_model(model.__class__)\n\n    if not schema_type:\n        raise MemoryStoreError(\n            f\"Model class '{model.__class__.__name__}' is not registered. \"\n            f\"Please call memory.register_schema('your_type_name', {model.__class__.__name__}) first.\"\n        )\n\n    fact = Fact(\n        id=fact_id or str(uuid.uuid4()), type=schema_type, payload=model.model_dump(mode=\"json\"), source=source\n    )\n\n    return await self.commit(fact, session_id=session_id, ephemeral=ephemeral, actor=actor, reason=reason)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(model)","title":"<code>model</code>","text":"(<code>BaseModel</code>)           \u2013            <p>The model instance to commit.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(fact_id)","title":"<code>fact_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional unique identifier for the fact. If not provided, a new UUID is generated.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(source)","title":"<code>source</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional source of the operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the session in which the commit is performed. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(ephemeral)","title":"<code>ephemeral</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Optional. Determines if the data should be treated as ephemeral. Defaults to False.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the entity performing the commit. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.commit_model(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional description or justification for the commit operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(\n    session_id: str | None,\n    fact_id: str,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Asynchronously deletes an existing fact from storage identified by the given fact ID. This operation logs the deletion, notifies hooks about the operation, and ensures thread safety during execution.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The fact ID of the deleted fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the fact with the given ID is not found in storage.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def delete(\n    self, session_id: str | None, fact_id: str, actor: str | None = None, reason: str | None = None\n) -&gt; str:\n    \"\"\"\n    Asynchronously deletes an existing fact from storage identified by the given fact ID. This operation logs the\n    deletion, notifies hooks about the operation, and ensures thread safety during execution.\n\n    Args:\n        session_id (str | None): Optional identifier for the session associated with the deletion operation. Defaults to None.\n        fact_id (str): The unique identifier of the fact to be deleted.\n        actor (str | None): Optional identifier for the user or system performing the deletion. Defaults to None if not applicable.\n        reason (str | None): Optional reason or context for the deletion operation. Defaults to None.\n\n    Returns:\n        The fact ID of the deleted fact.\n\n    Raises:\n        MemoryStoreError: If the fact with the given ID is not found in storage.\n    \"\"\"\n    async with self._lock:\n        existing = await self.storage.load(fact_id)\n        if not existing:\n            raise MemoryStoreError(\"Fact not found\")\n\n        await self.storage.delete(fact_id)\n        await self._log_tx(Operation.DELETE, session_id, fact_id, existing, None, actor, reason)\n        await self._notify_hooks(Operation.DELETE, fact_id, Fact(**existing))\n        return fact_id\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.delete(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>)           \u2013            <p>Optional identifier for the session associated with the deletion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.delete(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to be deleted.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.delete(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the deletion. Defaults to None if not applicable.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.delete(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the deletion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.discard_session","title":"discard_session  <code>async</code>","text":"<pre><code>discard_session(session_id: str) -&gt; int\n</code></pre> <p>Asynchronously discard a session and clear related stored data in the storage.</p> <p>This method removes all records associated with the given session ID from the storage and logs the operation if any data is cleared.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of records cleared from the storage.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def discard_session(self, session_id: str) -&gt; int:\n    \"\"\"\n    Asynchronously discard a session and clear related stored data in the storage.\n\n    This method removes all records associated with the given session ID\n    from the storage and logs the operation if any data is cleared.\n\n    Args:\n        session_id (str): The unique identifier of the session to discard.\n\n    Returns:\n        The number of records cleared from the storage.\n    \"\"\"\n    async with self._lock:\n        deleted_ids = await self.storage.delete_session(session_id)\n        if deleted_ids:\n            await self._log_tx(\n                Operation.DISCARD_SESSION,\n                session_id,\n                None,\n                None,\n                None,\n                None,\n                f\"Session {session_id} cleared ({len(deleted_ids)} facts)\",\n            )\n            dummy = Fact(id=\"session\", type=\"session\", payload={}, session_id=session_id)\n            await self._notify_hooks(Operation.DISCARD_SESSION, \"\", dummy)\n        return len(deleted_ids)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.discard_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session to discard.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.get","title":"get  <code>async</code>","text":"<pre><code>get(fact_id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Asynchronously retrieves a fact from the storage based on the provided fact ID.</p> <p>This method accesses the underlying storage to load a fact corresponding to the given identifier. If the fact ID does not exist in the storage, the method will return None.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>A dictionary representation of the fact if found, otherwise None.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def get(self, fact_id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Asynchronously retrieves a fact from the storage based on the provided fact ID.\n\n    This method accesses the underlying storage to load a fact corresponding\n    to the given identifier. If the fact ID does not exist in the storage,\n    the method will return None.\n\n    Args:\n        fact_id (str): The unique identifier of the fact to retrieve.\n\n    Returns:\n        A dictionary representation of the fact if found, otherwise None.\n    \"\"\"\n    return await self.storage.load(fact_id)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.get(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to retrieve.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.promote_session","title":"promote_session  <code>async</code>","text":"<pre><code>promote_session(\n    session_id: str,\n    selector: (\n        Callable[[dict[str, Any]], bool] | None\n    ) = None,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; list[str]\n</code></pre> <p>Asynchronously promotes session-related facts by modifying the session ID to dissociate them from the provided session. This is based on the selector criteria (if provided). The promotion operation will be logged and associated hooks will be notified.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of identifiers for the promoted facts.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def promote_session(\n    self,\n    session_id: str,\n    selector: Callable[[dict[str, Any]], bool] | None = None,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; list[str]:\n    \"\"\"\n    Asynchronously promotes session-related facts by modifying the session ID to dissociate\n    them from the provided session. This is based on the selector criteria\n    (if provided). The promotion operation will be logged and associated hooks\n    will be notified.\n\n    Args:\n        session_id (str): The unique identifier of the session whose facts are to be processed for promotion.\n        selector (Callable[[dict[str, Any]], bool] | None): A callable to filter facts based on custom logic. If\n            provided, only facts passing this filter will be promoted. Defaults to None.\n        actor (str | None): Optional identifier for the user or system performing the promotion operation. Defaults to None.\n        reason (str | None): Optional reason or context for the promotion operation. Defaults to None.\n\n    Returns:\n        A list of identifiers for the promoted facts.\n    \"\"\"\n    async with self._lock:\n        candidates = await self.storage.get_session_facts(session_id)\n\n        promoted = []\n        for fact_dict in candidates:\n            if selector and not selector(fact_dict):\n                continue\n\n            before = dict(fact_dict)\n            fact_dict[\"session_id\"] = None\n            await self.storage.save(fact_dict)\n\n            promoted.append(fact_dict[\"id\"])\n            await self._log_tx(Operation.PROMOTE, session_id, fact_dict[\"id\"], before, fact_dict, actor, reason)\n            await self._notify_hooks(Operation.PROMOTE, fact_dict[\"id\"], Fact(**fact_dict))\n\n        return promoted\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.promote_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session whose facts are to be processed for promotion.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.promote_session(selector)","title":"<code>selector</code>","text":"(<code>Callable[[dict[str, Any]], bool] | None</code>, default:                   <code>None</code> )           \u2013            <p>A callable to filter facts based on custom logic. If provided, only facts passing this filter will be promoted. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.promote_session(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the promotion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.promote_session(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the promotion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.query","title":"query  <code>async</code>","text":"<pre><code>query(\n    typename: str | None = None,\n    filters: dict[str, Any] | None = None,\n    session_id: str | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Asynchronously executes a query against the storage with optional type and filter constraints.</p> <p>This method interacts with the underlying storage to filter and retrieve data based on the provided type and filtering criteria. The <code>typename</code> allows for filtering objects of a specific type, whereas <code>filters</code> enables more fine-grained queries by applying a JSON-based filter.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing query results that match the given filters and type constraints.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def query(\n    self, typename: str | None = None, filters: dict[str, Any] | None = None, session_id: str | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Asynchronously executes a query against the storage with optional type and filter constraints.\n\n    This method interacts with the underlying storage to filter and retrieve data\n    based on the provided type and filtering criteria. The `typename` allows for\n    filtering objects of a specific type, whereas `filters` enables more fine-grained\n    queries by applying a JSON-based filter.\n\n    Args:\n        typename (str | None): A string that specifies the type of objects to query. If set\n            to None, no type filtering is applied.\n        filters (dict[str, Any] | None): A dictionary representing JSON-style filter constraints to\n            apply to the query. If set to None, no filter constraints are applied.\n        session_id (str | None): Optional identifier for the session associated with the query. Defaults to None.\n\n    Returns:\n        A list of dictionaries containing query results that match the given filters and type constraints.\n    \"\"\"\n    final_filters = (filters or {}).copy()\n\n    if session_id:\n        final_filters[\"session_id\"] = session_id\n\n    return await self.storage.query(type_filter=typename, json_filters=final_filters)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.query(typename)","title":"<code>typename</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>A string that specifies the type of objects to query. If set to None, no type filtering is applied.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.query(filters)","title":"<code>filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary representing JSON-style filter constraints to apply to the query. If set to None, no filter constraints are applied.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.query(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the session associated with the query. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.register_schema","title":"register_schema","text":"<pre><code>register_schema(\n    typename: str,\n    model: type[BaseModel],\n    constraint: Constraint | None = None,\n) -&gt; None\n</code></pre> <p>Registers a schema in the schema registry and optionally applies a constraint.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def register_schema(self, typename: str, model: type[BaseModel], constraint: Constraint | None = None) -&gt; None:\n    \"\"\"\n    Registers a schema in the schema registry and optionally applies a constraint.\n\n    Args:\n        typename (str): The unique identifier for the model being registered.\n        model (type[BaseModel]): The Pydantic model class to register.\n        constraint (Constraint | None): Optional constraint to associate with the type.\n\n    Returns:\n        None\n    \"\"\"\n    self._schema_registry.register(typename, model)\n    if constraint:\n        self._constraints[typename] = constraint\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.register_schema(typename)","title":"<code>typename</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier for the model being registered.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.register_schema(model)","title":"<code>model</code>","text":"(<code>type[BaseModel]</code>)           \u2013            <p>The Pydantic model class to register.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.register_schema(constraint)","title":"<code>constraint</code>","text":"(<code>Constraint | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional constraint to associate with the type.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.rollback","title":"rollback  <code>async</code>","text":"<pre><code>rollback(session_id: str, steps: int = 1) -&gt; None\n</code></pre> <p>Asynchronously reverts the state of the storage by rolling back a specified number of transactional operations. Each operation is extracted from the transaction log and reversed based on its type (e.g., CREATE, UPDATE, DELETE).</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def rollback(self, session_id: str, steps: int = 1) -&gt; None:\n    \"\"\"\n    Asynchronously reverts the state of the storage by rolling back a specified number of transactional\n    operations. Each operation is extracted from the transaction log and reversed based on\n    its type (e.g., CREATE, UPDATE, DELETE).\n\n    Args:\n        session_id (str): The unique identifier of the session to roll back.\n        steps (int): The number of transactional steps to roll back. Defaults to 1. Must be a positive integer.\n\n    Returns:\n        None\n    \"\"\"\n    async with self._lock:\n        if steps &lt;= 0:\n            return\n\n        logs = await self.storage.get_tx_log(session_id=session_id, limit=steps)\n\n        for entry in logs:\n            op = entry[\"op\"]\n            fid = entry[\"fact_id\"]\n\n            if op in (\"COMMIT\", \"COMMIT_EPHEMERAL\", \"UPDATE\", \"PROMOTE\"):\n                if entry[\"fact_before\"]:\n                    await self.storage.save(entry[\"fact_before\"])\n                    await self._notify_hooks(Operation.UPDATE, fid, Fact(**entry[\"fact_before\"]))\n                else:\n                    if fid:\n                        await self.storage.delete(fid)\n                        await self._notify_hooks(Operation.DELETE, fid, None)\n\n            elif op == \"DELETE\":\n                if entry[\"fact_before\"]:\n                    await self.storage.save(entry[\"fact_before\"])\n                    await self._notify_hooks(Operation.COMMIT, fid, Fact(**entry[\"fact_before\"]))\n\n        tx_uuids = [entry[\"uuid\"] for entry in logs]\n        await self.storage.delete_txs(tx_uuids)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.rollback(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session to roll back.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.rollback(steps)","title":"<code>steps</code>","text":"(<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The number of transactional steps to roll back. Defaults to 1. Must be a positive integer.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.search","title":"search  <code>async</code>","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[ScoredFact]\n</code></pre> <p>Asynchronously performs a hybrid search operation combining semantic search through Vector DB with data retrieval from a storage system. This function enables the execution of both fuzzy and precise search queries and supports filtering. The semantic search retrieves relevant IDs and scores, while the storage system augments these results with the most recent data associated with those IDs.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[ScoredFact]</code>           \u2013            <p>A list of <code>ScoredFact</code> objects containing facts retrieved and their associated scores.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[ScoredFact]:\n    \"\"\"\n    Asynchronously performs a hybrid search operation combining semantic search through Vector DB\n    with data retrieval from a storage system. This function enables the execution\n    of both fuzzy and precise search queries and supports filtering. The semantic\n    search retrieves relevant IDs and scores, while the storage system augments\n    these results with the most recent data associated with those IDs.\n\n    Args:\n        query (str): The search term to use when querying both the vector database and the storage system.\n        limit (int): The maximum number of results to return. Optional, with a default value of 5.\n        filters (dict[str, Any] | None): A dictionary of filter conditions to apply during the search.\n            The filters argument supports simple key-value matching {\"key\": \"value\"} across all backends.\n            For complex queries (ranges, OR-logic), you must use the syntax specific to your active Vector DB.\n        score_threshold (float | None): A numeric threshold to exclude results with scores\n            below this value. Optional, defaults to None.\n\n    Returns:\n        A list of `ScoredFact` objects containing facts retrieved and their associated scores.\n    \"\"\"\n    search_results: list[SearchResult] = []\n    for hook in self._hooks:\n        results = await hook.search(query, limit, filters, score_threshold)\n        search_results.extend(results)\n\n    if not search_results:\n        return []\n\n    unique_hits = {res.fact_id: res.score for res in search_results}\n    final_results = []\n\n    for fid, score in unique_hits.items():\n        data = await self.storage.load(fid)\n        if data:\n            fact = Fact(**data)\n            final_results.append(ScoredFact(score=score, fact=fact))\n\n    return final_results\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>The search term to use when querying both the vector database and the storage system.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The maximum number of results to return. Optional, with a default value of 5.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.search(filters)","title":"<code>filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary of filter conditions to apply during the search. The filters argument supports simple key-value matching {\"key\": \"value\"} across all backends. For complex queries (ranges, OR-logic), you must use the syntax specific to your active Vector DB.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>A numeric threshold to exclude results with scores below this value. Optional, defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.update","title":"update  <code>async</code>","text":"<pre><code>update(\n    fact_id: str,\n    patch: dict[str, Any],\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Asynchronously updates an existing fact in the store by applying a patch to its contents. The update process validates the resulting payload using the schema registry and manages concurrent modifications with locking. If the update fails during hook notification, the operation is rolled back to its previous state.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The unique identifier of the updated fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the fact with the specified identifier is not found in the store.</p> </li> <li> <code>HookError</code>             \u2013            <p>If an error occurs during the hook notification process.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>async def update(\n    self, fact_id: str, patch: dict[str, Any], actor: str | None = None, reason: str | None = None\n) -&gt; str:\n    \"\"\"\n    Asynchronously updates an existing fact in the store by applying a patch to its contents. The update process\n    validates the resulting payload using the schema registry and manages concurrent modifications\n    with locking. If the update fails during hook notification, the operation is rolled back\n    to its previous state.\n\n    Args:\n        fact_id (str): The unique identifier of the fact to be updated.\n        patch (dict[str, Any]): A dictionary representing the modifications to be applied to the current fact's payload.\n        actor (str | None): Optional identifier for the user or system performing the update. Defaults to None if not applicable.\n        reason (str | None): Optional reason or context for the update operation. Defaults to None.\n\n    Returns:\n        The unique identifier of the updated fact.\n\n    Raises:\n        MemoryStoreError: If the fact with the specified identifier is not found in the store.\n        HookError: If an error occurs during the hook notification process.\n    \"\"\"\n    async with self._lock:\n        existing = await self.storage.load(fact_id)\n        if not existing:\n            raise MemoryStoreError(\"Fact not found\")\n\n        before = copy.deepcopy(existing)\n        draft = copy.deepcopy(existing)\n\n        current_payload = draft.get(\"payload\", {})\n        patch_payload = patch.get(\"payload\", {})\n        current_payload.update(patch_payload)\n\n        fact_type = draft[\"type\"]\n        validated_payload = self._schema_registry.validate(fact_type, current_payload)\n\n        draft[\"payload\"] = validated_payload\n        draft[\"ts\"] = datetime.now(timezone.utc).isoformat()\n\n        try:\n            await self.storage.save(draft)\n            await self._log_tx(Operation.UPDATE, draft[\"session_id\"], fact_id, before, draft, actor, reason)\n            await self._notify_hooks(Operation.UPDATE, fact_id, Fact(**draft))\n        except HookError as e:\n            await self.storage.save(before)\n            raise e\n\n        return fact_id\n</code></pre>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.update(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to be updated.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.update(patch)","title":"<code>patch</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary representing the modifications to be applied to the current fact's payload.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.update(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the update. Defaults to None if not applicable.</p>"},{"location":"api/memstate/#memstate.storage.AsyncMemoryStore.update(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the update operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.Constraint","title":"Constraint","text":"<pre><code>Constraint(\n    singleton_key: str | None = None,\n    immutable: bool = False,\n)\n</code></pre> <p>Represents a constraint with properties for configuration.</p> <p>This class is used to define constraints with options for a singleton key and immutability. It provides a structure to manage these constraint properties for further processing or validation.</p> <p>Attributes:</p> <ul> <li> <code>singleton_key</code>               (<code>str | None</code>)           \u2013            <p>Optional key used to identify a singleton behavior. If set, it implies uniqueness based on the value of the key.</p> </li> <li> <code>immutable</code>               (<code>bool</code>)           \u2013            <p>Indicates if the constraint is immutable. If True, the constraint cannot be modified after its creation.</p> </li> </ul> Used by: <ul> <li> API Reference <code></code>\u00a0storage <ul> <li> <code></code>\u00a0AsyncMemoryStore <code></code>\u00a0register_schema </li> <li> <code></code>\u00a0MemoryStore <code></code>\u00a0register_schema </li> </ul> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def __init__(self, singleton_key: str | None = None, immutable: bool = False) -&gt; None:\n    self.singleton_key = singleton_key\n    self.immutable = immutable\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore","title":"MemoryStore","text":"<pre><code>MemoryStore(\n    storage: StorageBackend,\n    hooks: list[MemoryHook] | None = None,\n)\n</code></pre> <p>Handles in-memory storage of structured data with schema enforcement, transactional capabilities, and hooks for custom operations.</p> <p>This class provides a structured method to store and retrieve facts with enforced schema validation and constraints. It also supports mechanisms for transactional logging, model validation, and hook execution during operations.</p> <p>Attributes:</p> <ul> <li> <code>storage</code>               (<code>StorageBackend</code>)           \u2013            <p>Backend storage mechanism for persisting facts and transaction information.</p> </li> <li> <code>hooks</code>               (<code>list[MemoryHook]</code>)           \u2013            <p>List of hooks to be executed during memory operations.</p> </li> </ul> Used by: <ul> <li> API Reference <code></code>\u00a0integrations <code></code>\u00a0langgraph <code></code>\u00a0MemStateCheckpointer </li> </ul> <p>Methods:</p> <ul> <li> <code>add_hook</code>             \u2013              <p>Adds a new memory hook to the list of hooks.</p> </li> <li> <code>commit</code>             \u2013              <p>Commits a <code>Fact</code> object to the storage, optionally allowing for ephemeral</p> </li> <li> <code>commit_model</code>             \u2013              <p>Commits a model to the store using the provided schema registry and additional metadata.</p> </li> <li> <code>delete</code>             \u2013              <p>Deletes an existing fact from storage identified by the given fact ID. This operation logs the</p> </li> <li> <code>discard_session</code>             \u2013              <p>Discard a session and clear related stored data in the storage.</p> </li> <li> <code>get</code>             \u2013              <p>Retrieves a fact from the storage based on the provided fact ID.</p> </li> <li> <code>promote_session</code>             \u2013              <p>Promotes session-related facts by modifying the session ID to dissociate</p> </li> <li> <code>query</code>             \u2013              <p>Executes a query against the storage with optional type and filter constraints.</p> </li> <li> <code>register_schema</code>             \u2013              <p>Registers a schema in the schema registry and optionally applies a constraint.</p> </li> <li> <code>rollback</code>             \u2013              <p>Reverts the state of the storage by rolling back a specified number of transactional</p> </li> <li> <code>search</code>             \u2013              <p>Performs a hybrid search operation combining semantic search through Vector DB</p> </li> <li> <code>update</code>             \u2013              <p>Updates an existing fact in the store by applying a patch to its contents. The update process</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def __init__(self, storage: StorageBackend, hooks: list[MemoryHook] | None = None) -&gt; None:\n    self.storage = storage\n    self._constraints: dict[str, Constraint] = {}\n    self._schema_registry = SchemaRegistry()\n    self._lock = threading.RLock()\n    self._seq = 0\n    self._hooks: list[MemoryHook] = hooks or []\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.add_hook","title":"add_hook","text":"<pre><code>add_hook(hook: MemoryHook) -&gt; None\n</code></pre> <p>Adds a new memory hook to the list of hooks.</p> <p>This method registers a <code>MemoryHook</code> instance into the internal hooks list for further processing. A <code>MemoryHook</code> is an abstraction that can be used to monitor and react to specific memory-related events.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def add_hook(self, hook: MemoryHook) -&gt; None:\n    \"\"\"\n    Adds a new memory hook to the list of hooks.\n\n    This method registers a `MemoryHook` instance into the internal hooks\n    list for further processing. A `MemoryHook` is an abstraction that can\n    be used to monitor and react to specific memory-related events.\n\n    Args:\n        hook (MemoryHook): The hook instance to be added to the hooks list.\n\n    Returns:\n        None\n    \"\"\"\n    self._hooks.append(hook)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.add_hook(hook)","title":"<code>hook</code>","text":"(<code>MemoryHook</code>)           \u2013            <p>The hook instance to be added to the hooks list.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit","title":"commit","text":"<pre><code>commit(\n    fact: Fact,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Commits a <code>Fact</code> object to the storage, optionally allowing for ephemeral storage, and updates existing records if applicable. The operation evaluates constraints such as immutability or uniqueness, handles potential duplicates, and invokes hooks for logging and notifications. Supports rollback of changes in case of errors.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The unique identifier of the committed fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>HookError</code>             \u2013            <p>If an error occurs during hook execution.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def commit(\n    self,\n    fact: Fact,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Commits a `Fact` object to the storage, optionally allowing for ephemeral\n    storage, and updates existing records if applicable. The operation evaluates\n    constraints such as immutability or uniqueness, handles potential duplicates,\n    and invokes hooks for logging and notifications. Supports rollback of changes\n    in case of errors.\n\n    Args:\n        fact (Fact): The `Fact` object to be committed. Validates the payload against\n            schema registry and potentially updates or creates a new entry in the\n            storage.\n        session_id (str | None): Optional session identifier associated with the `Fact`.\n        ephemeral (bool): Indicates whether the `Fact` is transient and should not be persisted. Defaults to `False`.\n        actor (str | None): Optional identifier for the individual or system responsible\n            for initiating the commit. Used for logging and auditing purposes.\n        reason (str | None): Optional string describing the purpose of the commit. Used\n            primarily for auditing and logging.\n\n    Returns:\n        The unique identifier of the committed fact.\n\n    Raises:\n        HookError: If an error occurs during hook execution.\n    \"\"\"\n    with self._lock:\n        validated_payload = self._schema_registry.validate(fact.type, fact.payload)\n        fact.payload = validated_payload\n\n        if session_id:\n            fact.session_id = session_id\n\n        previous_state = None\n        op = Operation.COMMIT\n\n        constraint = self._constraints.get(fact.type)\n\n        if constraint and constraint.singleton_key:\n            key_val = validated_payload.get(constraint.singleton_key)\n            if key_val is not None:\n                search_key = f\"payload.{constraint.singleton_key}\"\n                matches = self.storage.query(type_filter=fact.type, json_filters={search_key: key_val})\n\n                if matches:\n                    existing_raw = matches[0]\n                    if constraint.immutable:\n                        raise ConflictError(f\"Immutable constraint violation: {fact.type}:{key_val}\")\n\n                    # We found a duplicate, so this is an UPDATE of an existing one\n                    previous_state = copy.deepcopy(existing_raw)\n                    fact.id = existing_raw[\"id\"]  # We replace the ID of the new fact with the old one\n                    op = Operation.UPDATE\n\n        if op != Operation.UPDATE:\n            existing = self.storage.load(fact.id)\n            if existing:\n                previous_state = copy.deepcopy(existing)\n                op = Operation.UPDATE\n            else:\n                op = Operation.COMMIT_EPHEMERAL if ephemeral else Operation.COMMIT\n\n        try:\n            new_state = fact.model_dump(mode=\"json\")\n            self.storage.save(new_state)\n            self._log_tx(op, fact.session_id, fact.id, previous_state, new_state, actor, reason)\n            self._notify_hooks(op, fact.id, fact)\n\n            return fact.id\n\n        except HookError as e:\n            if op == Operation.UPDATE and previous_state:\n                self.storage.save(previous_state)\n            else:\n                self.storage.delete(fact.id)\n\n            raise e\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit(fact)","title":"<code>fact</code>","text":"(<code>Fact</code>)           \u2013            <p>The <code>Fact</code> object to be committed. Validates the payload against schema registry and potentially updates or creates a new entry in the storage.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional session identifier associated with the <code>Fact</code>.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit(ephemeral)","title":"<code>ephemeral</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Indicates whether the <code>Fact</code> is transient and should not be persisted. Defaults to <code>False</code>.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the individual or system responsible for initiating the commit. Used for logging and auditing purposes.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional string describing the purpose of the commit. Used primarily for auditing and logging.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model","title":"commit_model","text":"<pre><code>commit_model(\n    model: BaseModel,\n    fact_id: str | None = None,\n    source: str | None = None,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Commits a model to the store using the provided schema registry and additional metadata.</p> <p>This method registers a given <code>model</code> object with a schema type derived from its class. Metadata such as <code>fact_id</code>, <code>source</code>, <code>session_id</code>, <code>ephemeral</code>, <code>actor</code>, and <code>reason</code> can be supplied to categorize or provide context for the operation. If the model's schema type is not registered, an error is raised.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The result of the commit operation as a string.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the model's schema type is not registered.</p> </li> <li> <code>HookError</code>             \u2013            <p>If an error occurs during hook execution.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def commit_model(\n    self,\n    model: BaseModel,\n    fact_id: str | None = None,\n    source: str | None = None,\n    session_id: str | None = None,\n    ephemeral: bool = False,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str:\n    \"\"\"\n    Commits a model to the store using the provided schema registry and additional metadata.\n\n    This method registers a given `model` object with a schema type derived from its class. Metadata such\n    as `fact_id`, `source`, `session_id`, `ephemeral`, `actor`, and `reason` can be supplied to categorize\n    or provide context for the operation. If the model's schema type is not registered, an error is raised.\n\n    Args:\n        model (BaseModel): The model instance to commit.\n        fact_id (str | None): Optional unique identifier for the fact. If not provided, a new UUID is generated.\n        source (str | None): Optional source of the operation. Defaults to None.\n        session_id (str | None): Optional identifier for the session in which the commit is performed. Defaults to None.\n        ephemeral (bool): Optional. Determines if the data should be treated as ephemeral. Defaults to False.\n        actor (str | None): Optional identifier for the entity performing the commit. Defaults to None.\n        reason (str | None): Optional description or justification for the commit operation. Defaults to None.\n\n    Returns:\n        The result of the commit operation as a string.\n\n    Raises:\n        MemoryStoreError: If the model's schema type is not registered.\n        HookError: If an error occurs during hook execution.\n    \"\"\"\n    schema_type = self._schema_registry.get_type_by_model(model.__class__)\n\n    if not schema_type:\n        raise MemoryStoreError(\n            f\"Model class '{model.__class__.__name__}' is not registered. \"\n            f\"Please call memory.register_schema('your_type_name', {model.__class__.__name__}) first.\"\n        )\n\n    fact = Fact(\n        id=fact_id or str(uuid.uuid4()), type=schema_type, payload=model.model_dump(mode=\"json\"), source=source\n    )\n\n    return self.commit(fact, session_id=session_id, ephemeral=ephemeral, actor=actor, reason=reason)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(model)","title":"<code>model</code>","text":"(<code>BaseModel</code>)           \u2013            <p>The model instance to commit.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(fact_id)","title":"<code>fact_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional unique identifier for the fact. If not provided, a new UUID is generated.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(source)","title":"<code>source</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional source of the operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the session in which the commit is performed. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(ephemeral)","title":"<code>ephemeral</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Optional. Determines if the data should be treated as ephemeral. Defaults to False.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the entity performing the commit. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.commit_model(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional description or justification for the commit operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.delete","title":"delete","text":"<pre><code>delete(\n    session_id: str | None,\n    fact_id: str,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Deletes an existing fact from storage identified by the given fact ID. This operation logs the deletion, notifies hooks about the operation, and ensures thread safety during execution.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The fact ID of the deleted fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the fact with the given ID is not found in storage.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def delete(self, session_id: str | None, fact_id: str, actor: str | None = None, reason: str | None = None) -&gt; str:\n    \"\"\"\n    Deletes an existing fact from storage identified by the given fact ID. This operation logs the\n    deletion, notifies hooks about the operation, and ensures thread safety during execution.\n\n    Args:\n        session_id (str | None): Optional identifier for the session in which the deletion is performed. Defaults to None.\n        fact_id (str): The unique identifier of the fact to be deleted.\n        actor (str | None): Optional identifier for the user or system performing the deletion. Defaults to None if not applicable.\n        reason (str | None): Optional reason or context for the deletion operation. Defaults to None.\n\n    Returns:\n        The fact ID of the deleted fact.\n\n    Raises:\n        MemoryStoreError: If the fact with the given ID is not found in storage.\n    \"\"\"\n    with self._lock:\n        existing = self.storage.load(fact_id)\n        if not existing:\n            raise MemoryStoreError(\"Fact not found\")\n\n        self.storage.delete(fact_id)\n        self._log_tx(Operation.DELETE, session_id, fact_id, existing, None, actor, reason)\n        self._notify_hooks(Operation.DELETE, fact_id, Fact(**existing))\n        return fact_id\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.delete(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>)           \u2013            <p>Optional identifier for the session in which the deletion is performed. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.delete(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to be deleted.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.delete(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the deletion. Defaults to None if not applicable.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.delete(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the deletion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.discard_session","title":"discard_session","text":"<pre><code>discard_session(session_id: str) -&gt; int\n</code></pre> <p>Discard a session and clear related stored data in the storage.</p> <p>This method removes all records associated with the given session ID from the storage and logs the operation if any data is cleared.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The number of records cleared from the storage.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def discard_session(self, session_id: str) -&gt; int:\n    \"\"\"\n    Discard a session and clear related stored data in the storage.\n\n    This method removes all records associated with the given session ID\n    from the storage and logs the operation if any data is cleared.\n\n    Args:\n        session_id (str): The unique identifier of the session to discard.\n\n    Returns:\n        The number of records cleared from the storage.\n    \"\"\"\n    deleted_ids = self.storage.delete_session(session_id)\n    if deleted_ids:\n        self._log_tx(\n            Operation.DISCARD_SESSION,\n            session_id,\n            None,\n            None,\n            None,\n            None,\n            f\"Session {session_id} cleared ({len(deleted_ids)} facts)\",\n        )\n    return len(deleted_ids)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.discard_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session to discard.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.get","title":"get","text":"<pre><code>get(fact_id: str) -&gt; dict[str, Any] | None\n</code></pre> <p>Retrieves a fact from the storage based on the provided fact ID.</p> <p>This method accesses the underlying storage to load a fact corresponding to the given identifier. If the fact ID does not exist in the storage, the method will return None.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any] | None</code>           \u2013            <p>A dictionary representation of the fact if found, otherwise None.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def get(self, fact_id: str) -&gt; dict[str, Any] | None:\n    \"\"\"\n    Retrieves a fact from the storage based on the provided fact ID.\n\n    This method accesses the underlying storage to load a fact corresponding\n    to the given identifier. If the fact ID does not exist in the storage,\n    the method will return None.\n\n    Args:\n        fact_id (str): The unique identifier of the fact to retrieve.\n\n    Returns:\n        A dictionary representation of the fact if found, otherwise None.\n    \"\"\"\n    return self.storage.load(fact_id)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.get(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to retrieve.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.promote_session","title":"promote_session","text":"<pre><code>promote_session(\n    session_id: str,\n    selector: (\n        Callable[[dict[str, Any]], bool] | None\n    ) = None,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; list[str]\n</code></pre> <p>Promotes session-related facts by modifying the session ID to dissociate them from the provided session. This is based on the selector criteria (if provided). The promotion operation will be logged and associated hooks will be notified.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>A list of identifiers for the promoted facts.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def promote_session(\n    self,\n    session_id: str,\n    selector: Callable[[dict[str, Any]], bool] | None = None,\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; list[str]:\n    \"\"\"\n    Promotes session-related facts by modifying the session ID to dissociate\n    them from the provided session. This is based on the selector criteria\n    (if provided). The promotion operation will be logged and associated hooks\n    will be notified.\n\n    Args:\n        session_id (str): The unique identifier of the session whose facts are to be processed for promotion.\n        selector (Callable[[dict[str, Any]], bool] | None): A callable to filter facts based on custom logic. If\n            provided, only facts passing this filter will be promoted. Defaults to None.\n        actor (str | None): Optional identifier for the user or system performing the promotion operation. Defaults to None.\n        reason (str | None): Optional reason or context for the promotion operation. Defaults to None.\n\n    Returns:\n        A list of identifiers for the promoted facts.\n    \"\"\"\n    with self._lock:\n        candidates = self.storage.get_session_facts(session_id)\n\n        promoted = []\n        for fact_dict in candidates:\n            if selector and not selector(fact_dict):\n                continue\n\n            before = dict(fact_dict)\n            fact_dict[\"session_id\"] = None\n            self.storage.save(fact_dict)\n\n            promoted.append(fact_dict[\"id\"])\n            self._log_tx(Operation.PROMOTE, session_id, fact_dict[\"id\"], before, fact_dict, actor, reason)\n            self._notify_hooks(Operation.PROMOTE, fact_dict[\"id\"], Fact(**fact_dict))\n\n        return promoted\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.promote_session(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session whose facts are to be processed for promotion.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.promote_session(selector)","title":"<code>selector</code>","text":"(<code>Callable[[dict[str, Any]], bool] | None</code>, default:                   <code>None</code> )           \u2013            <p>A callable to filter facts based on custom logic. If provided, only facts passing this filter will be promoted. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.promote_session(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the promotion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.promote_session(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the promotion operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.query","title":"query","text":"<pre><code>query(\n    typename: str | None = None,\n    filters: dict[str, Any] | None = None,\n    session_id: str | None = None,\n) -&gt; list[dict[str, Any]]\n</code></pre> <p>Executes a query against the storage with optional type and filter constraints.</p> <p>This method interacts with the underlying storage to filter and retrieve data based on the provided type and filtering criteria. The <code>typename</code> allows for filtering objects of a specific type, whereas <code>filters</code> enables more fine-grained queries by applying a JSON-based filter.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[dict[str, Any]]</code>           \u2013            <p>A list of dictionaries containing query results that match the given filters and type constraints.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def query(\n    self, typename: str | None = None, filters: dict[str, Any] | None = None, session_id: str | None = None\n) -&gt; list[dict[str, Any]]:\n    \"\"\"\n    Executes a query against the storage with optional type and filter constraints.\n\n    This method interacts with the underlying storage to filter and retrieve data\n    based on the provided type and filtering criteria. The `typename` allows for\n    filtering objects of a specific type, whereas `filters` enables more fine-grained\n    queries by applying a JSON-based filter.\n\n    Args:\n        typename (str | None): A string that specifies the type of objects to query. If set\n            to None, no type filtering is applied.\n        filters (dict[str, Any] | None): A dictionary representing JSON-style filter constraints to\n            apply to the query. If set to None, no filter constraints are applied.\n        session_id (str | None): Optional identifier for the session associated with the query. Defaults to None.\n\n    Returns:\n        A list of dictionaries containing query results that match the given filters and type constraints.\n    \"\"\"\n    final_filters = (filters or {}).copy()\n\n    if session_id:\n        final_filters[\"session_id\"] = session_id\n\n    return self.storage.query(type_filter=typename, json_filters=final_filters)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.query(typename)","title":"<code>typename</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>A string that specifies the type of objects to query. If set to None, no type filtering is applied.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.query(filters)","title":"<code>filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary representing JSON-style filter constraints to apply to the query. If set to None, no filter constraints are applied.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.query(session_id)","title":"<code>session_id</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the session associated with the query. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.register_schema","title":"register_schema","text":"<pre><code>register_schema(\n    typename: str,\n    model: type[BaseModel],\n    constraint: Constraint | None = None,\n) -&gt; None\n</code></pre> <p>Registers a schema in the schema registry and optionally applies a constraint.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def register_schema(self, typename: str, model: type[BaseModel], constraint: Constraint | None = None) -&gt; None:\n    \"\"\"\n    Registers a schema in the schema registry and optionally applies a constraint.\n\n    Args:\n        typename (str): The unique identifier for the model being registered.\n        model (type[BaseModel]): The Pydantic model class to register.\n        constraint (Constraint | None): Optional constraint to associate with the type.\n\n    Returns:\n        None\n    \"\"\"\n    self._schema_registry.register(typename, model)\n    if constraint:\n        self._constraints[typename] = constraint\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.register_schema(typename)","title":"<code>typename</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier for the model being registered.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.register_schema(model)","title":"<code>model</code>","text":"(<code>type[BaseModel]</code>)           \u2013            <p>The Pydantic model class to register.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.register_schema(constraint)","title":"<code>constraint</code>","text":"(<code>Constraint | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional constraint to associate with the type.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.rollback","title":"rollback","text":"<pre><code>rollback(session_id: str, steps: int = 1) -&gt; None\n</code></pre> <p>Reverts the state of the storage by rolling back a specified number of transactional operations. Each operation is extracted from the transaction log and reversed based on its type (e.g., CREATE, UPDATE, DELETE).</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def rollback(self, session_id: str, steps: int = 1) -&gt; None:\n    \"\"\"\n    Reverts the state of the storage by rolling back a specified number of transactional\n    operations. Each operation is extracted from the transaction log and reversed based on\n    its type (e.g., CREATE, UPDATE, DELETE).\n\n    Args:\n        session_id (str): The unique identifier of the session to roll back.\n        steps (int): The number of transactional steps to roll back. Defaults to 1. Must be a positive integer.\n\n    Returns:\n        None\n    \"\"\"\n    with self._lock:\n        if steps &lt;= 0:\n            return\n\n        logs = self.storage.get_tx_log(session_id=session_id, limit=steps)\n\n        for entry in logs:\n            op = entry[\"op\"]\n            fid = entry[\"fact_id\"]\n\n            if op in (\"COMMIT\", \"COMMIT_EPHEMERAL\", \"UPDATE\", \"PROMOTE\"):\n                if entry[\"fact_before\"]:\n                    self.storage.save(entry[\"fact_before\"])\n                    self._notify_hooks(Operation.UPDATE, fid, Fact(**entry[\"fact_before\"]))\n                else:\n                    if fid:\n                        self.storage.delete(fid)\n                        self._notify_hooks(Operation.DELETE, fid, None)\n\n            elif op == \"DELETE\":\n                if entry[\"fact_before\"]:\n                    self.storage.save(entry[\"fact_before\"])\n                    self._notify_hooks(Operation.COMMIT, fid, Fact(**entry[\"fact_before\"]))\n\n        tx_uuids = [entry[\"uuid\"] for entry in logs]\n        self.storage.delete_txs(tx_uuids)\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.rollback(session_id)","title":"<code>session_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the session to roll back.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.rollback(steps)","title":"<code>steps</code>","text":"(<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The number of transactional steps to roll back. Defaults to 1. Must be a positive integer.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.search","title":"search","text":"<pre><code>search(\n    query: str,\n    limit: int = 5,\n    filters: dict[str, Any] | None = None,\n    score_threshold: float | None = None,\n) -&gt; list[ScoredFact]\n</code></pre> <p>Performs a hybrid search operation combining semantic search through Vector DB with data retrieval from a storage system. This function enables the execution of both fuzzy and precise search queries and supports filtering. The semantic search retrieves relevant IDs and scores, while the storage system augments these results with the most recent data associated with those IDs.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[ScoredFact]</code>           \u2013            <p>A list of <code>ScoredFact</code> objects containing facts retrieved and their associated scores.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def search(\n    self, query: str, limit: int = 5, filters: dict[str, Any] | None = None, score_threshold: float | None = None\n) -&gt; list[ScoredFact]:\n    \"\"\"\n    Performs a hybrid search operation combining semantic search through Vector DB\n    with data retrieval from a storage system. This function enables the execution\n    of both fuzzy and precise search queries and supports filtering. The semantic\n    search retrieves relevant IDs and scores, while the storage system augments\n    these results with the most recent data associated with those IDs.\n\n    Args:\n        query (str): The search term to use when querying both the vector database and the storage system.\n        limit (int): The maximum number of results to return. Optional, with a default value of 5.\n        filters (dict[str, Any] | None): A dictionary of filter conditions to apply during the search.\n            The filters argument supports simple key-value matching {\"key\": \"value\"} across all backends.\n            For complex queries (ranges, OR-logic), you must use the syntax specific to your active Vector DB.\n        score_threshold (float | None): A numeric threshold to exclude results with scores\n            below this value. Optional, defaults to None.\n\n    Returns:\n        A list of `ScoredFact` objects containing facts retrieved and their associated scores.\n    \"\"\"\n    search_results: list[SearchResult] = []\n    for hook in self._hooks:\n        results = hook.search(query, limit, filters, score_threshold)\n        search_results.extend(results)\n\n    if not search_results:\n        return []\n\n    unique_hits = {res.fact_id: res.score for res in search_results}\n    final_results = []\n\n    for fid, score in unique_hits.items():\n        data = self.storage.load(fid)\n        if data:\n            fact = Fact(**data)\n            final_results.append(ScoredFact(score=score, fact=fact))\n\n    return final_results\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.search(query)","title":"<code>query</code>","text":"(<code>str</code>)           \u2013            <p>The search term to use when querying both the vector database and the storage system.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.search(limit)","title":"<code>limit</code>","text":"(<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The maximum number of results to return. Optional, with a default value of 5.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.search(filters)","title":"<code>filters</code>","text":"(<code>dict[str, Any] | None</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary of filter conditions to apply during the search. The filters argument supports simple key-value matching {\"key\": \"value\"} across all backends. For complex queries (ranges, OR-logic), you must use the syntax specific to your active Vector DB.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.search(score_threshold)","title":"<code>score_threshold</code>","text":"(<code>float | None</code>, default:                   <code>None</code> )           \u2013            <p>A numeric threshold to exclude results with scores below this value. Optional, defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.update","title":"update","text":"<pre><code>update(\n    fact_id: str,\n    patch: dict[str, Any],\n    actor: str | None = None,\n    reason: str | None = None,\n) -&gt; str\n</code></pre> <p>Updates an existing fact in the store by applying a patch to its contents. The update process validates the resulting payload using the schema registry and manages concurrent modifications with locking. If the update fails during hook notification, the operation is rolled back to its previous state.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The unique identifier of the updated fact.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>MemoryStoreError</code>             \u2013            <p>If the fact with the specified identifier is not found in the store.</p> </li> <li> <code>HookError</code>             \u2013            <p>If an error occurs during the hook notification process.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def update(self, fact_id: str, patch: dict[str, Any], actor: str | None = None, reason: str | None = None) -&gt; str:\n    \"\"\"\n    Updates an existing fact in the store by applying a patch to its contents. The update process\n    validates the resulting payload using the schema registry and manages concurrent modifications\n    with locking. If the update fails during hook notification, the operation is rolled back\n    to its previous state.\n\n    Args:\n        fact_id (str): The unique identifier of the fact to be updated.\n        patch (dict[str, Any]): A dictionary representing the modifications to be applied to the current fact's payload.\n        actor (str | None): Optional identifier for the user or system performing the update. Defaults to None if not applicable.\n        reason (str | None): Optional reason or context for the update operation. Defaults to None.\n\n    Returns:\n        The unique identifier of the updated fact.\n\n    Raises:\n        MemoryStoreError: If the fact with the specified identifier is not found in the store.\n        HookError: If an error occurs during the hook notification process.\n    \"\"\"\n    with self._lock:\n        existing = self.storage.load(fact_id)\n        if not existing:\n            raise MemoryStoreError(\"Fact not found\")\n\n        before = copy.deepcopy(existing)\n        draft = copy.deepcopy(existing)\n\n        current_payload = draft.get(\"payload\", {})\n        patch_payload = patch.get(\"payload\", {})\n        current_payload.update(patch_payload)\n\n        fact_type = draft[\"type\"]\n        validated_payload = self._schema_registry.validate(fact_type, current_payload)\n\n        draft[\"payload\"] = validated_payload\n        draft[\"ts\"] = datetime.now(timezone.utc).isoformat()\n\n        try:\n            self.storage.save(draft)\n            self._log_tx(Operation.UPDATE, draft[\"session_id\"], fact_id, before, draft, actor, reason)\n            self._notify_hooks(Operation.UPDATE, fact_id, Fact(**draft))\n        except HookError as e:\n            self.storage.save(before)\n            raise e\n\n        return fact_id\n</code></pre>"},{"location":"api/memstate/#memstate.storage.MemoryStore.update(fact_id)","title":"<code>fact_id</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier of the fact to be updated.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.update(patch)","title":"<code>patch</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>A dictionary representing the modifications to be applied to the current fact's payload.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.update(actor)","title":"<code>actor</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional identifier for the user or system performing the update. Defaults to None if not applicable.</p>"},{"location":"api/memstate/#memstate.storage.MemoryStore.update(reason)","title":"<code>reason</code>","text":"(<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional reason or context for the update operation. Defaults to None.</p>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry","title":"SchemaRegistry","text":"<pre><code>SchemaRegistry()\n</code></pre> <p>Manages schema registration and validation with a mapping of type names to Pydantic models.</p> <p>The SchemaRegistry class allows for the registration of Pydantic models with associated type names. It provides functionality for validating payloads against the registered schemas and for reverse- looking up type names by model classes.</p> <p>Attributes:</p> <ul> <li> <code>schemas</code>               (<code>dict[str, type[BaseModel]]</code>)           \u2013            <p>A mapping of type names to their registered Pydantic models.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>get_type_by_model</code>             \u2013              <p>Retrieve the type name associated with a given model class.</p> </li> <li> <code>register</code>             \u2013              <p>Registers a model under a specific type name within the schema registry.</p> </li> <li> <code>validate</code>             \u2013              <p>Validates the given payload against the model schema for the specified type name. If no schema</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._schemas: dict[str, type[BaseModel]] = {}\n</code></pre>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.get_type_by_model","title":"get_type_by_model","text":"<pre><code>get_type_by_model(\n    model_class: type[BaseModel],\n) -&gt; str | None\n</code></pre> <p>Retrieve the type name associated with a given model class.</p> <p>This method iterates through a dictionary of schemas and checks if the provided model class matches any value in the dictionary. If a match is found, the corresponding type name is returned. If no match is found, it returns None.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str | None</code>           \u2013            <p>The type name associated with the provided model class, or None if no match is found.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def get_type_by_model(self, model_class: type[BaseModel]) -&gt; str | None:\n    \"\"\"\n    Retrieve the type name associated with a given model class.\n\n    This method iterates through a dictionary of schemas and checks if the\n    provided model class matches any value in the dictionary. If a match is\n    found, the corresponding type name is returned. If no match is found, it\n    returns None.\n\n    Args:\n        model_class (type[BaseModel]): The Pydantic model class to find the corresponding type name for.\n\n    Returns:\n        The type name associated with the provided model class, or None if no match is found.\n    \"\"\"\n    for type_name, cls in self._schemas.items():\n        if cls == model_class:\n            return type_name\n    return None\n</code></pre>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.get_type_by_model(model_class)","title":"<code>model_class</code>","text":"(<code>type[BaseModel]</code>)           \u2013            <p>The Pydantic model class to find the corresponding type name for.</p>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.register","title":"register","text":"<pre><code>register(typename: str, model: type[BaseModel]) -&gt; None\n</code></pre> <p>Registers a model under a specific type name within the schema registry.</p> <p>This method associates a given model with a unique type name in the internal schema registry. The registered type name and model can later be retrieved or used for validation or other processing purposes.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>None</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def register(self, typename: str, model: type[BaseModel]) -&gt; None:\n    \"\"\"\n    Registers a model under a specific type name within the schema registry.\n\n    This method associates a given model with a unique type name in the internal\n    schema registry. The registered type name and model can later be retrieved or\n    used for validation or other processing purposes.\n\n    Args:\n        typename (str): The unique identifier for the model being registered.\n        model (type[BaseModel]): The Pydantic model class to register.\n\n    Returns:\n        None\n    \"\"\"\n    self._schemas[typename] = model\n</code></pre>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.register(typename)","title":"<code>typename</code>","text":"(<code>str</code>)           \u2013            <p>The unique identifier for the model being registered.</p>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.register(model)","title":"<code>model</code>","text":"(<code>type[BaseModel]</code>)           \u2013            <p>The Pydantic model class to register.</p>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.validate","title":"validate","text":"<pre><code>validate(\n    typename: str, payload: dict[str, Any]\n) -&gt; dict[str, Any]\n</code></pre> <p>Validates the given payload against the model schema for the specified type name. If no schema exists for the provided type name, the payload is returned unmodified. If validation fails, an exception containing the details of the validation failure is raised.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>           \u2013            <p>A dictionary containing the validated payload in JSON-serializable format.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValidationFailed</code>             \u2013            <p>If the input payload fails validation against the schema.</p> </li> </ul> Source code in <code>memstate/storage.py</code> <pre><code>def validate(self, typename: str, payload: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"\n    Validates the given payload against the model schema for the specified type name. If no schema\n    exists for the provided type name, the payload is returned unmodified. If validation fails, an\n    exception containing the details of the validation failure is raised.\n\n    Args:\n        typename (str): The type name for which the payload is to be validated.\n        payload (dict[str, Any]): The dictionary payload to be validated against the corresponding model schema.\n\n    Returns:\n        A dictionary containing the validated payload in JSON-serializable format.\n\n    Raises:\n        ValidationFailed: If the input payload fails validation against the schema.\n    \"\"\"\n    model_cls = self._schemas.get(typename)\n    if not model_cls:\n        return payload\n    try:\n        instance = model_cls.model_validate(payload)\n        return instance.model_dump(mode=\"json\")\n    except ValidationError as e:\n        raise ValidationFailed(str(e))\n</code></pre>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.validate(typename)","title":"<code>typename</code>","text":"(<code>str</code>)           \u2013            <p>The type name for which the payload is to be validated.</p>"},{"location":"api/memstate/#memstate.storage.SchemaRegistry.validate(payload)","title":"<code>payload</code>","text":"(<code>dict[str, Any]</code>)           \u2013            <p>The dictionary payload to be validated against the corresponding model schema.</p>"},{"location":"documentation/","title":"Core concept","text":""},{"location":"documentation/#storage","title":"Storage","text":"<p>MemState separates the logic from the storage. It supports several backends: In-memory (for testing), SQLite, Redis, and PostgreSQL.</p> <p>To learn how to configure specific backends, please refer to the backends documentation</p> <p>You must initialize a storage backend before creating the <code>MemoryStore</code>.</p> syncasync <pre><code>from memstate import MemoryStore, InMemoryStorage\n\nstore = MemoryStore(storage=InMemoryStorage())\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\n\nasync def main():\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#schema-registry","title":"Schema registry","text":"<p>MemState enforces Type Safety. You must register Pydantic models to define what your agent is allowed to remember. This prevents the agent from storing \"hallucinated\" structures or malformed JSON.</p> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nstore = MemoryStore(storage=InMemoryStorage())\nstore.register_schema(typename=\"preference\", model=UserPref)\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n    store.register_schema(typename=\"preference\", model=UserPref)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#constraint-the-magic-layer","title":"Constraint (The \"Magic\" Layer)","text":"<p>This is one of the most powerful features of MemState.</p> <p>Why do we need this?</p> <p>LLMs are stateless and often forget context. An agent might try to create a \"User Profile\" fact, forgetting that one already exists.</p> <ul> <li>Without Constraints: You end up with 5 duplicate profiles in your DB.</li> <li>With Constraints: MemState detects the duplicate and automatically converts the Insert into an Update.</li> </ul> <p>You can define:</p> <ol> <li><code>singleton_key</code>: A field that must be unique (e.g., <code>user_id</code> or <code>role</code>). If a fact with this key exists, MemState updates it instead of creating a new one.</li> <li><code>immutable</code>: If <code>True</code>, forbids changes to this fact. Useful for audit logs or system prompts.</li> </ol> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nstore = MemoryStore(storage=InMemoryStorage())\nstore.register_schema(\n    typename=\"preference\",\n    model=UserPref,\n    constraint=Constraint(singleton_key=\"role\", immutable=False),\n)\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n    store.register_schema(\n        typename=\"preference\",\n        model=UserPref,\n        constraint=Constraint(singleton_key=\"role\", immutable=False),\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#commit","title":"Commit","text":"<p>When your agent generates data, you commit it. Thanks to the <code>commit_model</code> helper, you can pass Pydantic objects directly.</p> <p>If a <code>singleton_key</code> constraint is active, MemState checks if the fact exists:</p> <ul> <li>Not found: Creates a new ID (INSERT).</li> <li>Found: Preserves the old ID and updates the payload (UPDATE).</li> </ul> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nstore = MemoryStore(storage=InMemoryStorage())\nstore.register_schema(\n    typename=\"preference\",\n    model=UserPref,\n    constraint=Constraint(singleton_key=\"role\", immutable=False),\n)\n\nfact_id = store.commit_model(\n    model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n    session_id=\"session_1\",\n)\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n    store.register_schema(\n        typename=\"preference\",\n        model=UserPref,\n        constraint=Constraint(singleton_key=\"role\", immutable=False),\n    )\n\n    fact_id = await store.commit_model(\n        model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n        session_id=\"session_1\",\n    )\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#rollback-time-travel","title":"Rollback (Time Travel)","text":"<p>This is the ACID guarantee. If an agent makes a mistake, or a user changes their mind, you can revert the state to a previous point in time.</p> <p>What happens during rollback:</p> <ol> <li>SQL/Storage: The data is reverted to the previous state (or deleted if it was new).</li> <li>Vector DB: The hooks are notified to update/delete embeddings to match the restored state.</li> </ol> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nstore = MemoryStore(storage=InMemoryStorage())\nstore.register_schema(\n    typename=\"preference\",\n    model=UserPref,\n    constraint=Constraint(singleton_key=\"role\", immutable=False),\n)\n\nfact_id = store.commit_model(\n    model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n    session_id=\"session_1\",\n)\n\nstore.rollback(steps=1, session_id=\"session_1\")\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage, Constraint\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage())\n    store.register_schema(\n        typename=\"preference\",\n        model=UserPref,\n        constraint=Constraint(singleton_key=\"role\", immutable=False),\n    )\n\n    fact_id = await store.commit_model(\n        model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n        session_id=\"session_1\",\n    )\n\n    await store.rollback(steps=1, session_id=\"session_1\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#hooks","title":"Hooks","text":"<p>Hooks connect MemState to external systems like Vector Databases (Chroma, Qdrant).</p> <p>They are part of the transaction: if a hook fails (e.g., network error), MemState rolls back the SQL change to prevent data drift.</p> <p>To read more about integrations please refer to the integrations documentation</p> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage, Constraint, HookError\nfrom memstate.integrations.chroma import ChromaSyncHook\nimport chromadb\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nclient = chromadb.Client()\n\nhook = ChromaSyncHook(\n    client=client,\n    collection_name=\"agent_memory\",\n    text_field=\"content\",\n    metadata_fields=[\"role\"],\n)\n\nstore = MemoryStore(storage=InMemoryStorage(), hooks=[hook])\nstore.register_schema(\n    typename=\"preference\",\n    model=UserPref,\n    constraint=Constraint(singleton_key=\"role\", immutable=False),\n)\n\ntry:\n    fact_id = store.commit_model(\n        model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n        session_id=\"session_1\",\n    )\nexcept HookError as e:\n    print(\"Commit failed, operation rolled back automatically:\", e)\n\nstore.rollback(steps=1, session_id=\"session_1\")\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage, Constraint, HookError\nfrom memstate.integrations.chroma import AsyncChromaSyncHook\nimport chromadb\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    client = await chromadb.AsyncHttpClient()\n\n    hook = AsyncChromaSyncHook(\n        client=client,\n        collection_name=\"agent_memory\",\n        text_field=\"content\",\n        metadata_fields=[\"role\"],\n    )\n\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage(), hooks=[hook])\n    store.register_schema(\n        typename=\"preference\",\n        model=UserPref,\n        constraint=Constraint(singleton_key=\"role\", immutable=False),\n    )\n\n    try:\n        fact_id = await store.commit_model(\n            model=UserPref(content=\"I am vegetarian\", role=\"preference\"),\n            session_id=\"session_1\",\n        )\n    except HookError as e:\n        print(\"Commit failed, operation rolled back automatically:\", e)\n\n    await store.rollback(steps=1, session_id=\"session_1\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/#hybrid-search-structured-semantic","title":"Hybrid Search (Structured-Semantic)","text":"<p>MemState implements a Structured-Semantic Search pattern. This is safer than standard RAG.</p> <p>How it works:</p> <ol> <li>Semantic Discovery: The Vector DB (via Hook) finds relevant records based on meaning (query) and strict metadata (filters).</li> <li>Hydration: MemState takes the returned IDs and loads the fresh data from the main Storage (SQL/Redis).</li> </ol> <p>Why is this better? In standard RAG, if you update a record, the Vector DB might return the old text (stale embedding) until re-indexing is complete. In MemState, you always get the latest committed version from the Source of Truth, even if the vector search found it via an older embedding.</p> syncasync <pre><code>from pydantic import BaseModel\nfrom memstate import MemoryStore, InMemoryStorage, Constraint\nfrom memstate.integrations.chroma import ChromaSyncHook\nimport chromadb\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nclient = chromadb.Client()\n\nhook = ChromaSyncHook(\n    client=client,\n    collection_name=\"agent_memory\",\n    text_field=\"content\",\n    metadata_fields=[\"role\"],\n)\n\nstore = MemoryStore(storage=InMemoryStorage(), hooks=[hook])\nstore.register_schema(\n    typename=\"preference\",\n    model=UserPref,\n    constraint=Constraint(singleton_key=\"role\", immutable=False),\n)\n\nstore.commit_model(\n    model=UserPref(content=\"I love spicy food\", role=\"preference\"),\n    session_id=\"session_1\",\n)\n\nresults = store.search(\n    query=\"What food does the user like?\",\n    filters={\"role\": \"preference\"},\n    limit=5\n)\n\nfor item in results:\n    print(f\"Score: {item.score}\")\n    print(f\"Data: {item.fact.payload}\")\n</code></pre> <pre><code>import asyncio\nfrom pydantic import BaseModel\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage, Constraint, HookError\nfrom memstate.integrations.chroma import AsyncChromaSyncHook\nimport chromadb\n\nclass UserPref(BaseModel):\n    content: str\n    role: str\n\nasync def main():\n    client = await chromadb.AsyncHttpClient()\n\n    hook = AsyncChromaSyncHook(\n        client=client,\n        collection_name=\"agent_memory\",\n        text_field=\"content\",\n        metadata_fields=[\"role\"],\n    )\n\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage(), hooks=[hook])\n    store.register_schema(\n        typename=\"preference\",\n        model=UserPref,\n        constraint=Constraint(singleton_key=\"role\", immutable=False),\n    )\n\n    await store.commit_model(\n        model=UserPref(content=\"I love spicy food\", role=\"preference\"),\n        session_id=\"session_1\",\n    )\n\n    results = await store.search(\n        query=\"What food does the user like?\",\n        filters={\"role\": \"preference\"},\n        limit=5\n    )\n\n    for item in results:\n        print(f\"Score: {item.score}\")\n        print(f\"Data: {item.fact.payload}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>Note: The syntax for <code>filters</code> depends on the Vector Hook you are using. By default, simple key-value pairs like <code>{\"role\": \"user\"}</code> are supported across all integrations. Complex operators (like <code>$gt</code>, <code>$in</code>) depend on the specific vector database dialect.</p>"},{"location":"documentation/backends/","title":"Backends","text":"<p>MemState separates logic from storage. You can start with <code>InMemoryStorage</code> for testing and switch to <code>PostgresStorage</code> or <code>RedisStorage</code> for production without changing your agent logic.</p> <p>Pro Tip: Dependency Injection</p> <p>MemState fully supports Dependency Injection. For all backends (Postgres, Redis, SQLite), you can pass an existing connection object instead of a connection string.</p>"},{"location":"documentation/backends/#postgresql","title":"PostgreSQL","text":"<p>Uses <code>SQLAlchemy</code> + <code>psycopg</code>. It supports JSONB for efficient querying.</p>"},{"location":"documentation/backends/#install-the-requirements","title":"Install the requirements","text":"uvpip <pre><code>uv add memstate[postgres]\n</code></pre> <pre><code>pip install memstate[postgres]\n</code></pre>"},{"location":"documentation/backends/#initialize-the-storage","title":"Initialize the storage","text":"syncasync <pre><code>from memstate import MemoryStore\nfrom memstate.backends.postgres import PostgresStorage\n\nurl = \"postgresql+psycopg://user:pass@localhost:5432/db_name\"\nstorage = PostgresStorage(url)\nstore = MemoryStore(storage=storage)\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore\nfrom memstate.backends.postgres import AsyncPostgresStorage\n\nasync def main():\n    url = \"postgresql+psycopg://user:pass@localhost:5432/db_name\"\n    storage = AsyncPostgresStorage(url)\n    # Important: You must create tables explicitly in async mode\n    await store.create_tables()\n\n    store = AsyncMemoryStore(storage=storage)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/backends/#redis","title":"Redis","text":"<p>Stores facts as JSON strings and maintains sets for efficient indexing.</p>"},{"location":"documentation/backends/#install-the-requirements_1","title":"Install the requirements","text":"uvpip <pre><code>uv add memstate[redis]\n</code></pre> <pre><code>pip install memstate[redis]\n</code></pre>"},{"location":"documentation/backends/#initialize-the-storage_1","title":"Initialize the storage","text":"syncasync <pre><code>from memstate import MemoryStore\nfrom memstate.backends.redis import RedisStorage\n\nstorage = RedisStorage(\"redis://localhost:6379/0\")\nstore = MemoryStore(storage=storage)\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore\nfrom memstate.backends.redis import AsyncRedisStorage\n\nasync def main():\n    storage = AsyncRedisStorage(\"redis://localhost:6379/0\")\n    store = AsyncMemoryStore(storage=storage)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/backends/#sqlite","title":"SQLite","text":"<p>The default, zero-config backend. Uses the JSON1 extension for querying.</p>"},{"location":"documentation/backends/#install-the-requirements_2","title":"Install the requirements","text":"<p>For synchronous use, SQLite is built-in.</p> <p>For async use, you need <code>aiosqlite</code>.</p> uvpip <pre><code>uv add memstate[sqlite-async]\n</code></pre> <pre><code>pip install memstate[sqlite-async]\n</code></pre>"},{"location":"documentation/backends/#initialize-the-storage_2","title":"Initialize the storage","text":"syncasync <pre><code>from memstate import MemoryStore, SQLiteStorage\n\nstorage = SQLiteStorage(\"memory.db\")\nstore = MemoryStore(storage=storage)\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore, AsyncSQLiteStorage\n\nasync def main():\n    storage = AsyncSQLiteStorage(\"memory.db\")\n    # Important: Connect explicitly\n    await storage.connect()\n\n    store = AsyncMemoryStore(storage=storage)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/backends/#in-memory","title":"In-memory","text":"<p>Non-persistent storage. Best for testing and prototyping.</p>"},{"location":"documentation/backends/#initialize-the-storage_3","title":"Initialize the storage","text":"syncasync <pre><code>from memstate import MemoryStore, InMemoryStorage\n\nstorage = InMemoryStorage()\nstore = MemoryStore(storage=storage)\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\n\nasync def main():\n    storage = AsyncInMemoryStorage()\n    store = AsyncMemoryStore(storage=storage)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/exceptions/","title":"Exceptions &amp; Error Handling","text":"<p>MemState uses a hierarchy of custom exceptions to help you handle failures gracefully. All exceptions inherit from <code>MemStateError</code>.</p>"},{"location":"documentation/exceptions/#hierarchy","title":"Hierarchy","text":"<pre><code>MemStateError\n\u251c\u2500\u2500 ValidationFailed    (Schema mismatch)\n\u251c\u2500\u2500 ConflictError       (Constraint violation)\n\u251c\u2500\u2500 HookError           (Vector DB sync failure)\n\u2514\u2500\u2500 MemoryStoreError    (Storage issues, not found, etc.)\n</code></pre>"},{"location":"documentation/exceptions/#hookerror-the-acid-signal","title":"HookError (The ACID Signal)","text":"<p>This is the most important exception in MemState. It is raised when a Sync Hook (e.g., ChromaDB, Qdrant) fails during a commit.</p> <p>What it means:</p> <ul> <li>The Vector DB write failed (network timeout, auth error).</li> <li>Crucial: MemState has already automatically rolled back the SQL change.</li> <li>Your data is consistent (nothing saved), but the operation failed.</li> </ul> <p>How to handle:</p> SyncAsync <pre><code>from memstate import HookError\n\ntry:\n    store.commit_model(user_pref)\nexcept HookError as e:\n    # The transaction was rolled back.\n    # You can retry, or ask the user to try again.\n    print(f\"Sync failed: {e}. Changes rolled back.\")\n</code></pre> <pre><code>from memstate import HookError\n\ntry:\n    await store.commit_model(user_pref)\nexcept HookError as e:\n    print(f\"Sync failed: {e}. Changes rolled back.\")\n</code></pre>"},{"location":"documentation/exceptions/#validationfailed","title":"ValidationFailed","text":"<p>Raised when the data provided (usually from an LLM) does not match the registered Pydantic schema.</p> <p>What it means:</p> <ul> <li>The LLM generated a string for an <code>int</code> field, or missed a required field.</li> <li>The transaction was rejected before touching the database.</li> </ul> <p>How to handle: Usually, you catch this and feed the error message back to the LLM so it can \"Self-Correct\".</p> <pre><code>from memstate import ValidationFailed\n\ntry:\n    store.commit_model(model_from_llm)\nexcept ValidationFailed as e:\n    # Feedback loop for the Agent\n    prompt_to_llm = f\"You provided invalid data: {e}. Please fix and retry.\"\n    retry_llm(prompt_to_llm)\n</code></pre>"},{"location":"documentation/exceptions/#conflicterror","title":"ConflictError","text":"<p>Raised when a write violates a defined <code>Constraint</code> (specifically <code>immutable=True</code>).</p> <p>What it means:</p> <ul> <li>You tried to update a fact that was marked as immutable.</li> <li>Example: Trying to change a signed \"User Agreement\" fact.</li> </ul> <pre><code>from memstate import Constraint, ConflictError\n\nstore.register_schema(\"policy\", PolicyModel, constraint=Constraint(singleton_key=\"id\", immutable=True))\n\ntry:\n    store.commit_model(new_policy)\nexcept ConflictError:\n    print(\"Cannot overwrite immutable policy!\")\n</code></pre>"},{"location":"documentation/integrations/","title":"Integrations","text":""},{"location":"documentation/integrations/#langchain-langgraph-checkpointer","title":"LangChain / LangGraph checkpointer","text":"<p>MemState provides a drop-in persistence layer for LangGraph agents. It replaces the default checkpointer to ensure state is stored transactionally and synchronized with your Vector DB.</p>"},{"location":"documentation/integrations/#install-the-requirements","title":"Install the requirements","text":"uvpip <pre><code>uv add memstate[langgraph]\n</code></pre> <pre><code>pip install memstate[langgraph]\n</code></pre>"},{"location":"documentation/integrations/#usage","title":"Usage","text":"syncasync <pre><code>from memstate.integrations.langgraph import MemStateCheckpointer\n\ncheckpointer = MemStateCheckpointer(memory=mem)\napp = workflow.compile(checkpointer=checkpointer)\n</code></pre> <pre><code>from memstate.integrations.langgraph import AsyncMemStateCheckpointer\n\ncheckpointer = AsyncMemStateCheckpointer(memory=mem)\napp = workflow.compile(checkpointer=checkpointer)\n</code></pre>"},{"location":"documentation/integrations/#qdrant-hook","title":"Qdrant Hook","text":"<p>Automatically syncs committed facts to a Qdrant collection. Supports FastEmbed out of the box for local embeddings.</p>"},{"location":"documentation/integrations/#install-the-requirements_1","title":"Install the requirements","text":"uvpip <pre><code>uv add memstate[qdrant]\n</code></pre> <pre><code>pip install memstate[qdrant]\n</code></pre>"},{"location":"documentation/integrations/#usage_1","title":"Usage","text":"syncasync <pre><code>from memstate import MemoryStore, InMemoryStorage\nfrom memstate.integrations.qdrant import QdrantSyncHook\nimport qdrant_client\n\nclient = qdrant_client.QdrantClient(\":memory:\")\n\nhook = QdrantSyncHook(\n    client=client,\n    collection_name=\"agent_memory\",\n    text_field=\"content\",\n    metadata_fields=[\"role\"],\n)\n\nstore = MemoryStore(storage=InMemoryStorage(), hooks=[hook])\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\nfrom memstate.integrations.qdrant import AsyncQdrantSyncHook\nimport qdrant_client\n\nasync def main():\n    client = qdrant_client.AsyncQdrantClient(\":memory:\")\n\n    hook = AsyncQdrantSyncHook(\n        client=client,\n        collection_name=\"agent_memory\",\n        text_field=\"content\",\n        metadata_fields=[\"role\"],\n    )\n\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage(), hooks=[hook])\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"documentation/integrations/#chroma-hook","title":"Chroma Hook","text":"<p>Automatically syncs committed facts to a ChromaDB collection.</p>"},{"location":"documentation/integrations/#install-the-requirements_2","title":"Install the requirements","text":"uvpip <pre><code>uv add memstate[chromadb]\n</code></pre> <pre><code>pip install memstate[chromadb]\n</code></pre>"},{"location":"documentation/integrations/#usage_2","title":"Usage","text":"syncasync <pre><code>from memstate import MemoryStore, InMemoryStorage\nfrom memstate.integrations.chroma import ChromaSyncHook\nimport chromadb\n\nclient = chromadb.Client()\n\nhook = ChromaSyncHook(\n    client=client,\n    collection_name=\"agent_memory\",\n    text_field=\"content\",\n    metadata_fields=[\"role\"],\n)\n\nstore = MemoryStore(storage=InMemoryStorage(), hooks=[hook])\n</code></pre> <pre><code>import asyncio\nfrom memstate import AsyncMemoryStore, AsyncInMemoryStorage\nfrom memstate.integrations.chroma import AsyncChromaSyncHook\nimport chromadb\n\nasync def main():\n    client = await chromadb.AsyncHttpClient()\n\n    hook = AsyncChromaSyncHook(\n        client=client,\n        collection_name=\"agent_memory\",\n        text_field=\"content\",\n        metadata_fields=[\"role\"],\n    )\n\n    store = AsyncMemoryStore(storage=AsyncInMemoryStorage(), hooks=[hook])\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>All examples can be found in the examples folder.</p>"},{"location":"examples/agent/","title":"Pizza agent demo","text":"<pre><code>import os\nimport sys\n\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nfrom typing import Annotated, TypedDict\n\nfrom langchain_core.language_models.fake_chat_models import FakeMessagesListChatModel\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage\nfrom langchain_core.tools import tool\nfrom langgraph.graph import END, START, StateGraph\nfrom langgraph.graph.message import add_messages\nfrom langgraph.prebuilt import ToolNode\n\nfrom memstate import InMemoryStorage, MemoryStore\nfrom memstate.integrations.langgraph import MemStateCheckpointer\n\n# --- 1. Business Logic (Tools) ---\n# Note: These functions don't know anything about LLM. They simply modify data.\n\n\n@tool\ndef create_order(pizza_type: str):\n    \"\"\"Start a new pizza order.\"\"\"\n    return {\"status\": \"created\", \"type\": pizza_type, \"toppings\": []}\n\n\n@tool\ndef add_topping(topping: str):\n    \"\"\"Add a topping to the current order.\"\"\"\n    return f\"Added {topping}\"\n\n\n@tool\ndef cancel_order():\n    \"\"\"Cancel the order.\"\"\"\n    return \"Order cancelled\"\n\n\ntools = [create_order, add_topping, cancel_order]\n\n\n# --- 2. State Definition ---\n\n\nclass AgentState(TypedDict):\n    # Message history (standard for chat)\n    messages: Annotated[list[BaseMessage], add_messages]\n    # !!! IMPORTANT: Structured business state!!!\n    # LangGraph will store this state, and MemState will persist it in SQL.\n    current_order: dict | None\n\n\n# --- 3. Mock Model ---\n\n\nclass FakeModelWithTools(FakeMessagesListChatModel):\n    def bind_tools(self, tools, **kwargs):\n        return self\n\n\n# Dialogue Script:\n# 1. User: \"I want Pepperoni\" -&gt; AI calls create_order\nresponse_1_tool = AIMessage(\n    content=\"\", tool_calls=[{\"name\": \"create_order\", \"args\": {\"pizza_type\": \"Pepperoni\"}, \"id\": \"call_1\"}]\n)\n# 2. Tool works -&gt; AI confirms\nresponse_1_final = AIMessage(content=\"I've started a Pepperoni order for you.\")\n\n# 3. User: \"Add mushrooms\" -&gt; AI calls add_topping\nresponse_2_tool = AIMessage(\n    content=\"\", tool_calls=[{\"name\": \"add_topping\", \"args\": {\"topping\": \"mushrooms\"}, \"id\": \"call_2\"}]\n)\n# 4. Tool works -&gt; AI confirms\nresponse_2_final = AIMessage(content=\"Added mushrooms to your Pepperoni pizza.\")\n\nmodel = FakeModelWithTools(responses=[response_1_tool, response_1_final, response_2_tool, response_2_final]).bind_tools(\n    tools\n)\n\n\n# --- 4. Nodes Logic ---\n\n\ndef agent_node(state: AgentState):\n    response = model.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n\n\ndef tool_node_wrapper(state: AgentState):\n    \"\"\"\n    A wrapper around ToolNode.\n    Here we intercept the tool's execution result and update the 'current_order' in the state.\n    \"\"\"\n    last_msg = state[\"messages\"][-1]\n    tool_calls = last_msg.tool_calls\n\n    # First, we make the tools in the standard way\n    tool_executor = ToolNode(tools)\n    tool_result = tool_executor.invoke(state)\n\n    # NOW THE MAGIC: Updating a structured state based on actions\n    new_order_state = state.get(\"current_order\", {}) or {}\n\n    for call in tool_calls:\n        if call[\"name\"] == \"create_order\":\n            # Initialize the order\n            new_order_state = {\"id\": 1, \"type\": call[\"args\"][\"pizza_type\"], \"toppings\": [], \"status\": \"active\"}\n        elif call[\"name\"] == \"add_topping\":\n            # Modifying the order\n            if new_order_state:\n                new_order_state[\"toppings\"].append(call[\"args\"][\"topping\"])\n\n    # Return updated messages AND updated business state\n    return {\"messages\": tool_result[\"messages\"], \"current_order\": new_order_state}\n\n\ndef should_continue(state: AgentState):\n    if state[\"messages\"][-1].tool_calls:\n        return \"tools\"\n    return END\n\n\n# --- 5. Assembly and Persistence ---\n\n# Connect MemState\nstorage = InMemoryStorage()\nmemory = MemoryStore(storage)\ncheckpointer = MemStateCheckpointer(memory=memory)\n\nworkflow = StateGraph(AgentState)\nworkflow.add_node(\"agent\", agent_node)\nworkflow.add_node(\"tools\", tool_node_wrapper)  # Use our smart wrapper\n\nworkflow.add_edge(START, \"agent\")\nworkflow.add_conditional_edges(\"agent\", should_continue)\nworkflow.add_edge(\"tools\", \"agent\")\n\napp = workflow.compile(checkpointer=checkpointer)\n\n# --- 6. RUN DEMO ---\n\nconfig = {\"configurable\": {\"thread_id\": \"user_session_1\"}}\n\nprint(\"\ud83c\udf55 Pizza Agent Started (backed by MemState)\\n\")\n\n# --- STEP 1: Creating an order ---\nprint(\"&gt;&gt;&gt; User: I want a Pepperoni pizza.\")\n# Launch the graph\nfor update in app.stream({\"messages\": [HumanMessage(content=\"I want a Pepperoni pizza.\")]}, config=config):\n    pass  # Just scroll through the graph\n\n# Get the final state from MemState\nstate_v1 = app.get_state(config)\nprint(f\"\ud83e\udd16 AI: {state_v1.values['messages'][-1]['content']}\")\nprint(f\"\ud83d\udce6 DB STATE (Current Order): {state_v1.values.get('current_order')}\")\n# Expected: type=Pepperoni, toppings=[]\n\n\nprint(\"\\n... (Simulating server restart / user coffee break) ...\\n\")\n\n# --- STEP 2: Change Order (Context Saved!) ---\nprint(\"&gt;&gt;&gt; User: Actually, add mushrooms.\")\n\n# LangGraph will automatically load the state from MemState by thread_id\nfor update in app.stream({\"messages\": [HumanMessage(content=\"Actually, add mushrooms.\")]}, config=config):\n    pass\n\nstate_v2 = app.get_state(config)\nprint(f\"\ud83e\udd16 AI: {state_v2.values['messages'][-1]['content']}\")\nprint(f\"\ud83d\udce6 DB STATE (Current Order): {state_v2.values.get('current_order')}\")\n# Expected: type=Pepperoni, toppings=['mushrooms']\n\n\nprint(\"\\n--- \ud83d\udd75\ufe0f\u200d\u2640\ufe0f MEMSTATE AUDIT ---\")\n# Now let's show off its \"power\": we can view the order change history via SQL.\n# LangGraph stores checkpoints.\ncheckpoints = memory.query(typename=\"langgraph_checkpoint\")\nprint(f\"Total transaction steps saved: {len(checkpoints)}\")\n\n# Let's find the moment when the order was created and when it was updated\nfor cp in checkpoints:\n    # Payload in MemState stores the LangGraph checkpoint structure\n    order_snapshot = cp[\"payload\"][\"checkpoint\"][\"channel_values\"].get(\"current_order\")\n    if order_snapshot:\n        ts = cp[\"ts\"]\n        print(f\"\ud83d\udd52 [{ts}] Order State: {order_snapshot}\")\n\nprint(\"\\n\u2705 Power Demo: State was persisted, modified transactionally, and is fully auditable via SQL.\")\n</code></pre>"},{"location":"examples/langgraph/","title":"Langgraph checkpoint demo","text":"<pre><code>import os\nimport sys\n\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nfrom langchain_core.language_models.fake_chat_models import FakeMessagesListChatModel\nfrom langchain_core.messages import AIMessage\nfrom langchain_core.tools import tool\nfrom langgraph.graph import END, START, MessagesState, StateGraph\nfrom langgraph.prebuilt import ToolNode\n\nfrom memstate import InMemoryStorage, MemoryStore\nfrom memstate.integrations.langgraph import MemStateCheckpointer\n\nstorage = InMemoryStorage()\nmemory = MemoryStore(storage)\ncheckpointer = MemStateCheckpointer(memory=memory)\n\n\n# --- 1. Create Fake Model with bind tools ---\n\n\nclass FakeModelWithTools(FakeMessagesListChatModel):\n    def bind_tools(self, tools, **kwargs):\n        return self\n\n\n# --- 2. Agent Setup (Fake Model) ---\n\n\n@tool\ndef get_weather(city: str):\n    \"\"\"Get the weather for a city.\"\"\"\n    if \"sf\" in city.lower() or \"san francisco\" in city.lower():\n        return \"It's 60 degrees and foggy.\"\n    return \"It's 90 degrees and sunny.\"\n\n\ntools = [get_weather]\n\n# --- THE MAGIC IS HERE ---\n# We pre-program the model's responses.\n# LangGraph runs in a loop: Model -&gt; Tool -&gt; Model -&gt; End\n# We need 2 responses for the first run and 1 response for the second.\n\n# Scenario for Run 1:\n# 1. The model decides to call the tool (returns tool_calls)\nresponse_1_call_tool = AIMessage(\n    content=\"\", tool_calls=[{\"name\": \"get_weather\", \"args\": {\"city\": \"SF\"}, \"id\": \"call_123\"}]\n)\n# 2. After executing the tool, the model receives the result and gives an answer\nresponse_1_final = AIMessage(content=\"The weather in SF is 60 degrees and foggy.\")\n\n# Scenario for Run 2 (Memory Test):\n# 1. The model answers a question about NY using context (simulate this)\nresponse_2_final = AIMessage(content=\"Yes, usually 90 degrees in NY is hotter than 60 in SF.\")\n\nmodel = FakeModelWithTools(responses=[response_1_call_tool, response_1_final, response_2_final]).bind_tools(tools)\n\n# -------------------\n\n\ndef call_model(state: MessagesState):\n    response = model.invoke(state[\"messages\"])\n    return {\"messages\": [response]}\n\n\ndef should_continue(state: MessagesState):\n    last_message = state[\"messages\"][-1]\n    if last_message.tool_calls:\n        return \"tools\"\n    return END\n\n\n# Building a graph\nworkflow = StateGraph(MessagesState)\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", ToolNode(tools))\n\nworkflow.add_edge(START, \"agent\")\nworkflow.add_conditional_edges(\"agent\", should_continue)\nworkflow.add_edge(\"tools\", \"agent\")\n\n# Connect our checkpointer\napp = workflow.compile(checkpointer=checkpointer)\n\n\n# --- 3. Launch ---\n\nthread_config = {\"configurable\": {\"thread_id\": \"session_1\"}}\n\nprint(\"\\n--- Run 1: Asking about weather (Triggering Tool) ---\")\n# User asks about the weather\nresult = app.invoke({\"messages\": [(\"user\", \"What's the weather in SF?\")]}, config=thread_config)\nprint(\"AI:\", result[\"messages\"][-1].content)\n\n\nprint(\"\\n--- Run 2: Continuing context (Memory Test) ---\")\n# We continue the same thread.\nresult_2 = app.invoke({\"messages\": [(\"user\", \"Is it hotter there than in NY?\")]}, config=thread_config)\nprint(\"AI:\", result_2[\"messages\"][-1].content)\n\n\nprint(\"\\n--- Audit ---\")\ncheckpoints = memory.query(typename=\"langgraph_checkpoint\")\nprint(f\"Total checkpoints stored: {len(checkpoints)}\")\n\nif len(checkpoints) &gt; 0:\n    last_cp = checkpoints[-1]\n    print(f\"Latest checkpoint ID: {last_cp['payload']['thread_ts']}\")\n    print(\"\u2705 Demo finished successfully!\")\n</code></pre>"},{"location":"examples/rag/","title":"RAG hook demo","text":"<pre><code>import os\nimport sys\nfrom typing import Dict, List\n\nsys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\")))\n\nfrom pydantic import BaseModel\n\nfrom memstate import Fact, InMemoryStorage, MemoryStore\n\n\nclass KnowledgeBase(BaseModel):\n    content: str\n\n\nclass UserPref(BaseModel):\n    theme: str\n\n\n# --- Simulated Vector Store ---\n# In real life, this would use OpenAI Embeddings and Qdrant/Chroma\n\n\nclass MockVectorDB:\n    def __init__(self):\n        self.index: Dict[str, str] = {}  # id -&gt; text content\n        print(\"\ud83d\udd35 [VectorDB] Initialized (Empty)\")\n\n    def upsert(self, doc_id: str, text: str):\n        # Here we would do: vector = openai.embed(text) -&gt; pinecone.upsert(vector)\n        self.index[doc_id] = text.lower()\n        print(f\"\ud83d\udd35 [VectorDB] Indexed doc {doc_id}: '{text[:30]}...'\")\n\n    def delete(self, doc_id: str):\n        if doc_id in self.index:\n            del self.index[doc_id]\n            print(f\"\ud83d\udd35 [VectorDB] Deleted doc {doc_id}\")\n\n    def search(self, query: str) -&gt; List[str]:\n        # Emulating semantic search (dumb substring search)\n        print(f\"\ud83d\udd0e [VectorDB] Searching for: '{query}'...\")\n        results = []\n        q = query.lower()\n        for doc_id, text in self.index.items():\n            if q in text:\n                results.append(doc_id)\n        return results\n\n\n# --- 2. The Hook (The glue Between SQL and Vectors) ---\n\n\nclass RAGSyncHook:\n    def __init__(self, vector_db: MockVectorDB):\n        self.vector_db = vector_db\n        # We are only interested in facts of the \"knowledge_base\" type.\n        self.target_types = {\"knowledge_base\", \"chat_log\"}\n\n    def __call__(self, op: str, fact_id: str, data: Fact | None):\n        # data is the state of the fact. If DELETE, this is the state BEFORE deletion.\n\n        # Type checking (do not vectorize system data)\n        if not data or data.type not in self.target_types:\n            return\n\n        # Processing of deletion\n        if op == \"DELETE\":\n            self.vector_db.delete(fact_id)\n            return\n\n        # Text extraction for vectorization\n        payload = data.payload\n        # Trying to find a text field\n        text_content = payload.get(\"content\") or payload.get(\"message\") or payload.get(\"summary\")\n\n        if not text_content:\n            return\n\n        # Upsert (Insert or Update - for a vector database, this is the same thing)\n        if op in (\"COMMIT\", \"UPDATE\", \"COMMIT_EPHEMERAL\"):\n            self.vector_db.upsert(fact_id, text_content)\n\n\n# --- 3. Main scenario ---\n\n\ndef main():\n    # Initialization\n    vector_db = MockVectorDB()  # Our \"Pinecone\"\n    hook = RAGSyncHook(vector_db)  # Our \"Synchronizer\"\n\n    storage = InMemoryStorage()  # Our \"Postgres\"\n    memory = MemoryStore(storage)  # Our \"Brain\"\n    memory.register_schema(\"knowledge_base\", KnowledgeBase)\n    memory.register_schema(\"user_pref\", UserPref)\n\n    # Add hook\n    memory.add_hook(hook)\n\n    print(\"\\n--- Phase 1: Ingestion ---\")\n    # We simply commit the facts to MemState. The hook will automatically transfer them to Vectors.\n\n    doc1 = KnowledgeBase(content=\"The moon is made of rock and dust.\")\n    doc2 = KnowledgeBase(content=\"Mars is known as the Red Planet due to iron oxide.\")\n    doc3 = UserPref(theme=\"dark\")  # This should NOT be in vectors (filter by type)\n\n    memory.commit_model(model=doc1, session_id=\"session_1\")\n    doc2_id = memory.commit_model(model=doc2, session_id=\"session_1\")\n    memory.commit_model(model=doc3, session_id=\"session_1\")\n\n    print(\"\\n--- Phase 2: RAG Search (Emulation) ---\")\n    # User asks: \"Tell me about the red planet\"\n    user_query = \"Red Planet\"\n\n    # Searching for IDs in a vector database\n    found_ids = vector_db.search(user_query)\n\n    if found_ids:\n        print(f\"\u2705 Found relevant IDs: {found_ids}\")\n        # Loading complete, reliable data from MemState (SQL)\n        # A vector database may return old garbage, but SQL will always return what is relevant.\n        for fid in found_ids:\n            fact = memory.get(fid)\n            print(f\"   -&gt; Retrieved content: {fact['payload']['content']}\")\n            print(f\"   -&gt; Metadata (Timestamp): {fact['ts']}\")\n    else:\n        print(\"\u274c Nothing found.\")\n\n    print(\"\\n--- Phase 3: Data Correction (Correction of facts) ---\")\n    # Let's say we realized that the information about Mars is incomplete.\n    # We update ONLY MemState.\n\n    print(\"\ud83d\udee0 Updating Mars fact in SQL...\")\n    memory.update(doc2_id, {\"payload\": {\"content\": \"Mars is the Red Planet and has two moons: Phobos and Deimos.\"}})\n\n    # Check if the vector index has been updated AUTOMATICALLY?\n    print(\"\ud83d\udd0e Searching again for 'Phobos'...\")\n    found_ids = vector_db.search(\"Phobos\")  # This word didn't exist before.\n\n    if found_ids:\n        print(f\"\u2705 Magic! Found ID via new keyword: {found_ids[0]}\")\n    else:\n        print(f\"\u274c Sync failed.\")\n\n    print(\"\\n--- Phase 4: Forgetting (Deletion) ---\")\n    # Deleting a fact from the database\n    print(\"\ud83d\uddd1 Deleting Mars fact...\")\n    memory.delete(session_id=\"session_1\", fact_id=doc2_id)\n\n    # Checking the search\n    found_ids = vector_db.search(\"Mars\")\n    if not found_ids:\n        print(\"\u2705 Clean. Fact removed from Vector DB automatically.\")\n    else:\n        print(\"\u274c Ghost data remains!\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"}]}